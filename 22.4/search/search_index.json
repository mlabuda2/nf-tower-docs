{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"<p>Nextflow Tower is the centralized command post for the management of Nextflow data pipelines. It brings monitoring, logging, and observability to distributed workflows and simplifies the deployment of pipelines on any cloud, cluster, or laptop.</p> <p>Users can launch pre-configured pipelines with ease, while the flexible API provides programmatic integration to meet the needs of organizations building on Nextflow Tower. Workflow developers can publish pipelines to shared workspaces and administrators can set up and manage the infrastructure required to run data analysis at scale.</p> <p></p>","title":"Home"},{"location":"#what-is-nextflow","text":"<p>Nextflow is a framework for the development of data workflows. It enables engineers and data scientists to create and securely deploy custom, parallel data applications to the cloud or traditional on-premises infrastructure. Nextflow is characterized by its powerful dataflow programming paradigm and execution engines that allow for transparent deployment.</p> <p>Nextflow is both a programming workflow language and an execution runtime that supports a wide range of execution platforms, including popular traditional grid scheduling systems such as Slurm and IBM LSF, and cloud services such as AWS Batch and Google Cloud Life Sciences.</p> <p></p>","title":"What is Nextflow?"},{"location":"#why-nextflow-tower","text":"<p>We created Nextflow in 2013 to deliver the most seamless experience for executing data workflows at scale. Tower is the continuation of that mission. Using the latest technologies, we have built the solution to easily execute and monitor pipelines across every stage. Tower brings the cloud closer than ever before with automated resource provisioning and role-based access control (RBAC).</p> <p>Tower is designed to be easily configurable in any environment \u2014 data and compute never leave your organization's security boundary. It has been extensively tested with over 500 million jobs, achieving 99.99% uptime.</p> <p>As mandated by healthcare industries to ensure compliance, the Tower platform is regularly submitted to penetration tests and security scanning. These tests meet the compliance standards set by ISO-27001, HIPAA, and HITRUST.</p>   <p>Tip</p> <p>Sign up to try Tower for free, or request a demo for deployments in your own on-premises or cloud environment.</p>","title":"Why Nextflow Tower?"},{"location":"_todo/","text":"<p>FAQ TO DOs:</p>","title":"todo"},{"location":"_todo/#general","text":"<ul> <li>$TOWER_AGENT_WORKDIR</li> <li>What does <code>NXF_PLUGINS_DEFAULT</code> environment variable do?</li> <li>Where is the analysis running?</li> <li>What about security of my data?</li> <li>Identity via LDAP/Active Directory</li> <li>Difference between free and paid Tower?</li> <li>Can I have Service-Account-type and Agent-type credentials in the same Workspace?<ul> <li>Not right now. Must choose. https://github.com/seqeralabs/nf-tower-cloud/issues/2879#issuecomment-1072646557</li> </ul> </li> </ul>","title":"GENERAL"},{"location":"_todo/#amazon","text":"<ul> <li>Can I have Nextflow automatically retry Tasks that fail due to Spot instance reclamation?</li> <li> <p>Can I have Nextflow automatically retry Tasks that fail due to Spot instance reclamation? </p> <p>Yes. As of Tower version ?????, any Spot-based AWS Batch Compute Environment created by Tower Forge will be automatically configured to retry each process 3 times. ??? If a retry policy is not defined???</p> <p>Given that Spots can be reclaimed during the execution of a job, it is a recommended practice that pipeline authors always include retry logic in their logic. ???See HERE for examples??? https://github.com/seqeralabs/nf-tower-cloud/pull/2820/files</p> <ul> <li>Why won't Secrets work with my legacy Tower Forge-created AWS Batch Compute Environment?</li> <li>Why won't Secrets work with my legacy Tower Forge-created AWS Batch Compute Environment? </li> </ul> <p>The Secrets feature requires new permissions to be added to existing IAM Roles: * The User/Role used by your Tower implementation must have the <code>secretsmanager:CreateSecret</code>. * Your Batch EC2 Instance Role must have ??? execution role ??? * Added details from here: https://github.com/seqeralabs/nf-tower-cloud/pull/2820</p> <p>Add Tower Agent blurb re: Rijkzwaan as per https://git.seqera.io/rijkzwaan/nf-support/issues/15#issuecomment-8438</p> <p>Meeting summary for 31-03-2021</p> </li> </ul> <p>Adding quick summary for the meeting today, please feel free to add/correct anything I might have missed.</p> <pre>1\n2\n3\n4\n5\n6\n7</pre><pre><code>With Jordi's guidance, the $TW_USER_AGENT was successfully used on an agent running in Kim's account to launch a pipeline from Daniel's user on Tower UI\n\nThe slight nuance on the RKZ cluster was that the home directories seem to be following a non-standard pattern i.e. with all-caps usernames (for example /home/DCR) and we had to append USER=DCR tw-agent ... to enable the agent.\n\nAn upgrade to the latest version of Tower would enable the use of $TW_AGENT_WORK variable with the agent\n\nWe also discussed the usage of pipeline reports feature\n</code></pre> <p>Follow-ups</p> <pre>1\n2\n3</pre><pre><code>@daniel-cruz-rijkzwaan to follow up here with an independent experiment to get up and running with tw-agent\n\nAbhinav to request the addition of Daniel's account in the community/showcase workspace in tower.nf\n</code></pre> <p>Warmly, Abhinav</p> <p>AZURE Batch - SSL problem as per https://git.seqera.io/eagle/nf-support/issues/10#issuecomment-8523</p>","title":"Amazon"},{"location":"_todo/#determine-if-this-is-relevant-to-google-faq-section","text":"<p>https://github.com/nf-core/configs/blob/master/conf/google.config as per this ticket: https://git.seqera.io/pluto/nf-support/issues/6</p> <p>TO DO: As per Ben, document profile injection behaviour into Tower docs (e.g. nf-core automagically injecting google profile if executing on GLS)</p>","title":"Determine if this is relevant to Google FAQ section:"},{"location":"agent/","text":"","title":"Tower Agent"},{"location":"agent/#overview","text":"<p>Tower Agent enables Tower to launch pipelines on HPC clusters that do not allow direct access through an SSH client.</p> <p>Tower Agent is a standalone process that runs on a node that can submit jobs to the cluster (e.g. login node). It establishes an authenticated secure reverse connection with Tower, allowing Tower to submit and monitor new jobs. The jobs are submitted on behalf of the user running the agent.</p>","title":"Overview"},{"location":"agent/#installation","text":"<p>Tower Agent is distributed as a single executable file to simply download and execute.</p> <ol> <li>Download the latest release from Github:</li> </ol> <pre>1</pre><pre><code>curl -fSL https://github.com/seqeralabs/tower-agent/releases/latest/download/tw-agent-linux-x86_64 &gt; tw-agent\n</code></pre> <ol> <li>Make it executable:</li> </ol> <pre>1</pre><pre><code>chmod +x ./tw-agent\n</code></pre> <ol> <li>(Optional) Move it into a folder that is in your path.</li> </ol>","title":"Installation"},{"location":"agent/#quickstart","text":"<p>Before running the Agent:</p> <ol> <li> <p>Create a personal access token in Tower.</p> </li> <li> <p>Create Tower Agent credentials in a Tower workspace. See here for more instructions.</p> </li> </ol>   <p>Tower Agent sharing</p> <p>To share a single Tower Agent instance with all members of a workspace, create a Tower Agent credential with Shared agent enabled.</p>  <p>When you create the credentials you'll get an Agent Connection ID. You can use the default ID or enter a custom ID \u2014 the connection ID in the workspace credentials must match the ID entered when you run the agent.</p> <p></p> <p>The agent should always be running in order to accept incoming requests from Tower. We recommend that you use a terminal multiplexer like tmux or GNU Screen, so that it keeps running even if you close your SSH session.</p> <pre>1\n2</pre><pre><code>export TOWER_ACCESS_TOKEN=&lt;YOUR TOKEN&gt;\n./tw-agent &lt;YOUR CONNECTION ID&gt;\n</code></pre> <p></p>","title":"Quickstart"},{"location":"agent/#tips","text":"<ul> <li>If you are using the agent with Tower Enterprise (on-prem) you can set the API url using the <code>TOWER_API_ENDPOINT</code> environment variable or the <code>--url</code> option.</li> <li>By default, the Agent uses the folder <code>${HOME}/work</code> as the Nextflow work directory. You can change it using the <code>--work-dir</code> option.</li> <li>The work directory must exist before running the agent.</li> <li>You can also change the work directory in Tower when you create a compute environment or launch a pipeline.</li> </ul>","title":"Tips"},{"location":"agent/#usage","text":"<pre> 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13</pre><pre><code>Usage: tw-agent [OPTIONS] AGENT_CONNECTION_ID\n\nNextflow Tower Agent\n\nParameters:\n*     AGENT_CONNECTION_ID    Agent connection ID to identify this agent.\n\nOptions:\n* -t, --access-token=&lt;token&gt; Tower personal access token. If not provided TOWER_ACCESS_TOKEN variable will be used.\n  -u, --url=&lt;url&gt;            Tower server API endpoint URL. If not provided TOWER_API_ENDPOINT variable will be used [default: https://api.tower.nf].\n  -w, --work-dir=&lt;workDir&gt;   Default path where the pipeline scratch data is stored. It can be changed when launching a pipeline from Tower [default: ~/work].\n  -h, --help                 Show this help message and exit.\n  -V, --version              Print version information and exit.\n</code></pre>","title":"Usage"},{"location":"cli/","text":"<p><code>tw</code> is Tower on the command line. It brings Tower concepts including Pipelines, Actions and Compute Environments to the terminal.</p> <p>Tower is a full-stack application for the management of data pipelines and compute resources. It enables collaborative data analysis at scale, on-premises or in any cloud.</p> <p>The Tower CLI interacts with Tower, providing an interface to launch pipelines, manage cloud resources and administer your analysis.</p> <p></p>","title":"Nextflow Tower CLI"},{"location":"cli/#key-features","text":"<ul> <li> <p>A Nextflow-like experience: Tower CLI provides a developer-friendly environment. Pipelines can be launched with the CLI similar to Nextflow but with the benefits of Tower such as monitoring, logging, resource provisioning, dataset management, and collaborative sharing.</p> </li> <li> <p>Infrastructure as Code: All Tower resources including Pipelines and Compute Environments can be described in a declarative manner. This allows a complete definition of an analysis environment that can be versioned and treated as code. It greatly simplifies sharing and re-use of configuration as well as routine administration.</p> </li> <li> <p>Built on OpenAPI: Tower CLI interacts with Tower via the Tower API which is created using the latest OpenAPI 3.0 specification. Tower CLI provides full control of the Tower application allowing users to get maximum insights into their pipeline submissions and execution environments.</p> </li> </ul>","title":"Key features"},{"location":"cli/#availability","text":"<p>Tower CLI can be installed on macOS, Windows, and Linux.</p> <p>Visit the Tower CLI page on GitHub for installation and configuration details.</p>","title":"Availability"},{"location":"faqs/","text":"","title":"FAQs and troubleshooting"},{"location":"faqs/#general-questions","text":"","title":"General Questions"},{"location":"faqs/#administration-console","text":"<p><p>Q: How do I access the Administration Console?</p></p> <p>The Administration Console allows Tower instance administrators to interact with all users and organizations registered with the platform. Administrators must be identified in your Tower instance configuration files prior to instantiation of the application.</p> <ol> <li>Create a <code>TOWER_ROOT_USERS</code> environment variable (e.g. via tower.env or Kubernetes ConfigMap).</li> <li>Populate the variable with a sequence of comma-delimited email addresses (no spaces).Example: <code>TOWER_ROOT_USERS=foo@foo.com,bar@bar.com</code></li> <li>If using a Tower version earlier than 21.12:<ol> <li>Add the following configuration to tower.yml: <pre>1\n2\n3</pre><pre><code>tower:\n    admin:\n        root-users: \"${TOWER_ROOT_USERS:[]}\"\n</code></pre></li> </ol> </li> <li>Restart the <code>cron</code> and <code>backend</code> containers/Deployments.</li> <li>The console will now be available via your Profile drop-down menu.</li> </ol>","title":"Administration Console"},{"location":"faqs/#api","text":"<p><p>Q:I am trying to query more results than the maximum return size allows. Can I do pagination?</p></p> <p>Yes. We recommend using pagination to fetch the results in smaller chunks through multiple API calls with the help of <code>max</code> and subsequent <code>offset</code> parameters. You will receive an error like below if you run into the maximum result limit.</p> <p><code>{object} length parameter cannot be greater than 100 (current value={value_sent})</code></p> <p>We have laid out an example below using the workflow endpoint.</p> <pre>1\n2\n3\n4\n5\n6\n7</pre><pre><code>curl -X GET \"https://$TOWER_SERVER_URL/workflow/$WORKFLOW_ID/tasks?workspaceId=$WORKSPACE_ID&amp;max=100\" \\\n    -H \"Accept: application/json\" \\\n    -H \"Authorization: Bearer $TOWER_ACCESS_TOKEN\"\n\ncurl -X GET \"https://$TOWER_SERVER_URL/workflow/$WORKFLOW_ID/tasks?workspaceId=$WORKSPACE_ID&amp;max=100&amp;offset=100\" \\\n    -H \"Accept: application/json\" \\\n    -H \"Authorization: Bearer $TOWER_ACCESS_TOKEN\"\n</code></pre> <p><p>Q: Why am I receiving a 403 HTTP Response when trying to launch a pipeline via the <code>/workflow/launch</code> API endpoint?</p></p> <p>Launch users have more restricted permissions within a Workspace than Power users. While both can launch pipelines via API calls, Launch users must specify additional values that are optional for a Power user.</p> <p>One such value is <code>launch.id</code>; attempting to launch a pipeline without specifying a <code>launch.id</code> in the API payload is equivalent to using the \"Start Quick Launch\" button within a workspace (a feature only available to Power users).</p> <p>If you have encountered the 403 error as a result of being a Launch user who did not provide a <code>launch.id</code>, please try resolving the problem as follows:</p> <ol> <li> <p>Provide the launch ID to the payload sent to the tower using the same endpoint. To do this;</p> <ol> <li>Query the list of pipelines via the <code>/pipelines</code> endpoint. Find the <code>pipelineId</code> of the pipeline you intend to launch.</li> <li>Once you have the <code>pipelineId</code>, call the <code>/pipelines/{pipelineId}/launch</code> API to retrieve the pipeline's <code>launch.id</code>.</li> <li>Include the <code>launch.id</code> in your call to the <code>/workflow/launch</code> API endpoint (see example below).     <pre> 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10</pre><pre><code>{\n    \"launch\": {\n        \"id\": \"Q2kVavFZNVCBkC78foTvf\",\n        \"computeEnvId\": \"4nqF77d6N1JoJrVrrgB8pH\",\n        \"runName\": \"sample-run\",\n        \"pipeline\": \"https://github.com/sample-repo/project\",\n        \"workDir\": \"s3://myBucketName\",\n        \"revision\": \"main\"\n    }\n}\n</code></pre></li> </ol> </li> <li> <p>If a launch id remains unavailable to you, upgrade your user role to 'Maintain' or higher. This will allow you to execute quick launch-type pipeline invocations.</p> </li> </ol>","title":"API"},{"location":"faqs/#common-errors","text":"<p><p>Q: After following the log-in link, why is my screen frozen at <code>/auth?success=true</code>?</p></p> <p>Starting with v22.1, Tower Enterprise implements stricter cookie security by default and will only send an auth cookie if the client is connected via HTTPS. The lack of an auth token will cause HTTP-only log-in attempts to fail (thereby causing the frozen screen).</p> <p>To remediate this problem, set the following environment variable <code>TOWER_ENABLE_UNSAFE_MODE=true</code>.</p> <p><p>Q: \"Unknown pipeline repository or missing credentials\" error when pulling from a public Github repository?</p></p> <p>Github imposes rate limits on repository pulls (including public repositories), where unauthenticated requests are capped at 60 requests/hour and authenticated requests are capped at 5000/hour. Tower users tend to encounter this error due to the 60 request/hour cap.</p> <p>To resolve the problem, please try the following:</p> <ol> <li>Ensure there is at least one Github credential in your Workspace's Credentials tab.</li> <li>Ensure that the Access token field of all Github Credential objects is populated with a Personal Access Token value, NOT a user password. (_Github PATs are typically several dozen characters long and begin with a <code>ghp_</code>prefix; example:<code>ghp*IqIMNOZH6zOwIEB4T9A2g4EHMy8Ji42q4HA</code>*)</li> <li> <p>Confirm that your PAT is providing the elevated threshold and transactions are being charged against it:</p> <p><code>curl -H \"Authorization: token ghp_LONG_ALPHANUMERIC_PAT\" -H \"Accept: application/vnd.github.v3+json\" https://api.github.com/rate_limit</code></p> </li> </ol> <p><p>Q: \"Row was updated or deleted by another transaction (or unsaved-value mapping was incorrect)\" error.</p> <p>This error can occur if incorrect configuration values are assigned to the <code>backend</code> and <code>cron</code> containers' <code>MICRONAUT_ENVIRONMENTS</code> environment variable. You may see other unexpected system behaviour like two exact copies of the same Nextflow job be submitted to the Executor for scheduling.</p> <p>Please verify the following:</p> <ol> <li>The <code>MICRONAUT_ENVIRONMENTS</code> environment variable associated with the <code>backend</code> container:<ul> <li>Contains <code>prod,redis,ha</code></li> <li>Does not contain <code>cron</code></li> </ul> </li> <li>The <code>MICRONAUT_ENVIRONMENTS</code> environment variable associated with the <code>cron</code> container:<ul> <li>Contains <code>prod,redis,cron</code></li> <li>Does not contain <code>ha</code></li> </ul> </li> <li>You do not have another copy of the <code>MICRONAUT_ENVIRONMENTS</code> environment variable defined elsewhere in your application (e.g. a tower.env file or Kubernetes ConfigMap).</li> <li>If you are using a separate container/pod to execute migrate-db.sh, there is no <code>MICRONAUT_ENVIRONMENTS</code> environment variable assigned to it.</li> </ol> <p><p>Q: Why do I get a <code>chmod: cannot access PATH/TO/bin/*: No such file or directory</code> exception?</p></p> <p>This error will be thrown if you attempt to run <code>chmod</code> against an S3/fusion-backed workdir which contains only hidden files.</p> <p>The behaviour is patched in Nextflow v22.09.7-edge. If you are unable to upgrade please see the original bug report for alternative workarounds.</p> <p><p>Q: \"No such variable\" error.</p></p> <p>This error can occur if you execute a DSL 1-based Nextflow workflow using Nextflow 22.03.0-edge or later.</p> <p><p>Q: Does the sleep command work the same way across my entire script?</p></p> <p>The <code>sleep</code> commands within your Nextflow workflows may differ in behaviour depending on where they are:</p> <ul> <li>If used within an <code>errorStrategy</code> block, the Groovy sleep function will be used (which takes its value in milliseconds).</li> <li>If used within a process script block, that language's sleep binary/method will be used. Example: this BASH script uses the BASH sleep binary, which takes its value in seconds.</li> </ul> <p><p>Q: Why does re-launching/resuming a run fail with <code>field revision is not writable</code>?</p></p> <p>A known issue with Tower versions prior to 22.3 caused resuming runs to fail for users with the launch role. This issue was fixed in Tower 22.3. Upgrade to the latest version of Tower to allow launch users to resume runs.</p>","title":"Common Errors"},{"location":"faqs/#compute-environments","text":"<p><p>Q: Can the name of a Compute Environment created in Tower contain special characters?</p> <p>No. Tower version 21.12 and later do not support the inclusion of special characters in the name of Compute Environment objects.</p> <p><p>Q: How do I set NXF_OPTS values for a Compute Environment?</p> <p>This depends on your Tower version:</p> <ul> <li>For v22.1.1+, specify the values via the Environment variables section of the \"Add Compute Environment\" screen.</li> <li> <p>For versions earlier than v22.1.1, specify the values via the Staging options &gt; Pre-run script textbox on the \"Add Compute Environment\" screen. Example:</p> <p><code>export NXF_OPTS=\"-Xms64m -Xmx512m\"</code></p> </li> </ul>","title":"Compute Environments"},{"location":"faqs/#containers","text":"<p><p>Q: Can I use rootless containers in my Nextflow pipelines?</p></p> <p>Most containers use the root user by default. However, some users prefer to define a non-root user in the container in order to minimize the risk of privilege escalation. Because Nextflow and its tasks use a shared work directory to manage input and output data, using rootless containers can lead to file permissions errors in some environments:</p> <pre>1</pre><pre><code>touch: cannot touch '/fsx/work/ab/27d78d2b9b17ee895b88fcee794226/.command.begin': Permission denied\n</code></pre> <p>As of Tower 22.1.0 or later, this issue should not occur when using AWS Batch. In other situations, you can avoid this issue by forcing all task containers to run as root. To do so, add one of the following snippets to your Nextflow configuration:</p> <pre>1\n2\n3\n4\n5\n6\n7\n8</pre><pre><code>// cloud executors\nprocess.containerOptions = \"--user 0:0\"\n\n// Kubernetes\nk8s.securityContext = [\n  \"runAsUser\": 0,\n  \"runAsGroup\": 0\n]\n</code></pre>","title":"Containers"},{"location":"faqs/#databases","text":"<p><p>Q: Help! I upgraded to Tower Enterprise 22.2.0 and now my database connect is failing.</p></p> <p>Tower Enterprise 22.2.0 introduced a breaking change whereby the <code>TOWER_DB_DRIVER</code> is now required to be <code>org.mariadb.jdbc.Driver</code>.</p> <p>Clients who use Amazon Aurora as their database solution may encounter a <code>java.sql.SQLNonTransientConnectionException: ... could not load system variables</code> error, likely due to a known error tracked within the MariaDB project.</p> <p>Please modify Tower Enterprise configuration as follows to try resolving the problem:</p> <ol> <li>Ensure your <code>TOWER_DB_DRIVER</code> uses the specified MariaDB URI.</li> <li>Modify your <code>TOWER_DB_URL</code> to: <code>TOWER_DB_URL=jdbc:mysql://YOUR_DOMAIN:YOUR_PORT/YOUR_TOWER_DB?usePipelineAuth=false&amp;useBatchMultiSend=false</code></li> </ol>","title":"Databases"},{"location":"faqs/#datasets","text":"<p><p>Q: Why are uploads of Datasets via direct calls to the Tower API failing?</p></p> <p>When uploading Datasets via the Tower UI or CLI, some steps are automatically done on your behalf. To upload Datasets via the TOwer API, additional steps are required:</p> <ol> <li>Explicitly define the MIME type of the file being uploaded.</li> <li>Make two calls to the API:<ol> <li>Create a Dataset object</li> <li>Upload the samplesheet to the Dataset object.</li> </ol> </li> </ol> <p>Example:</p> <pre>1\n2\n3\n4\n5</pre><pre><code># Step 1: Create the Dataset object\n$ curl -X POST \"https://api.tower.nf/workspaces/$WORKSPACE_ID/datasets/\" -H \"Content-Type: application/json\" -H \"Authorization: Bearer $TOWER_ACCESS_TOKEN\" --data '{\"name\":\"placeholder\", \"description\":\"A placeholder for the data we will submit in the next call\"}'\n\n# Step 2: Upload the datasheet into the Dataset object\n$ curl -X POST \"https://api.tower.nf/workspaces/$WORKSPACE_ID/datasets/$DATASET_ID/upload\"  -H \"Accept: application/json\"  -H \"Authorization: Bearer $TOWER_ACCESS_TOKEN\"  -H \"Content-Type: multipart/form-data\" -F \"file=@samplesheet_full.csv; type=text/csv\"\n</code></pre>   <p>Tip</p>  <p>You can also use the tower-cli to upload the dataset to a particular workspace.</p> <pre>1\n2\n3</pre><pre><code>```console\ntw datasets add --name \"cli_uploaded_samplesheet\" ./samplesheet_full.csv\n```\n</code></pre> <p><p>Q: Why is my uploaded Dataset not showing in the Tower Launch screen input field drop-down?</p></p> <p>When launching a Nextflow workflow from the Tower GUI, the <code>input</code> field drop-down will only show Datasets whose mimetypes match the rules specified in the associated <code>nextflow_schema.json</code> file. If your Dataset has a different mimetype than specified in the pipeline schema, Tower will not present the file.</p> <p>Note that a known issue in Tower 22.2 which caused TSV datasets to be unavailable in the drop-down has been fixed in version 22.4.1.</p> <p>Example: The default nf-core RNASeq pipeline specifies that only files with a <code>csv</code> mimetype should be provided as an input file. If you created a Dataset of mimetype <code>tsv</code>, it would not appear as an input filed dropdown option.</p> <p><p>Q: Can an input file mimetype restriction be added to the nextflow_schema.json file generated by the nf-core pipeline schema builder tool?</p></p> <p>As of August 2022, it is possible to add a mimetype restriction to the nextflow_schema.json file generated by the nf-core schema builder tool but this must occur manually after generation, not during. Please refer to this RNASeq example to see how the <code>mimetype</code> key-value pair should be specified.</p> <p><p>Q: Why are my datasets converted to 'application/vnd.ms-excel' data type when uploading on a browser using Windows OS?</p></p> <p>This is a known issue when using Firefox browser with the Tower version prior to 22.2.0. You can either (a) upgrade the Tower version to 22.2.0 or higher or (b) use Chrome.</p> <p>For context, the Tower will prompt the message below if you encountered this issue.</p> <pre>1</pre><pre><code>\"Given file is not a dataset file. Detected media type: 'application/vnd.ms-excel'. Allowed types: 'text/csv, text/tab-separated-values'\"\n</code></pre> <p><p>Q: Why are TSV-formatted datasets not shown in the Tower launch screen input field drop-down menu?</p></p> <p>An issue was identified in Tower version 22.2 which caused TSV datasets to be unavailable in the input data drop-down menu on the launch screen. This has been fixed in Tower version 22.4.1.</p>","title":"Datasets"},{"location":"faqs/#email-and-tls","text":"<p><p>Q: How do I solve TLS errors when attempting to send email? </p></p> <p>Nextflow and Nextflow Tower both have the ability to interact with email providers on your behalf. These providers often require TLS connections, with many now requiring at least TLSv1.2.</p> <p>TLS connection errors can occur due to variability in the default TLS version specified by your underlying JDK distribution. If you encounter any of the following errors, there is likely a mismatch between your default TLS version and what is expected by the email provider:</p> <ul> <li><code>Unexpected error sending mail ... TLS 1.0 and 1.1 are not supported. Please upgrade/update your client to support TLS 1.2\" error</code></li> <li><code>ERROR nextflow.script.WorkflowMetadata - Failed to invoke 'workflow.onComplete' event handler ... javax.net.ssl.SSLHandshakeException: No appropriate protocol (protocol is disabled or cipher suites are inappropriate)</code></li> </ul> <p>To fix the problem, you can either:</p> <ol> <li>Set a JDK environment variable to force Nextflow and/or the Tower containers to use TLSv1.2 by default:</li> </ol> <pre>1</pre><pre><code>export JAVA_OPTIONS=\"-Dmail.smtp.ssl.protocols=TLSv1.2\"\n</code></pre> <ol> <li>Add the following parameter to your nextflow.config file:</li> </ol> <pre>1\n2\n3</pre><pre><code>mail {\n    smtp.ssl.protocols = 'TLSv1.2'\n}\n</code></pre> <p>In both cases, please ensure these values are also set for Nextflow and/or Tower:</p> <ul> <li><code>mail.smtp.starttls.enable=true</code></li> <li><code>mail.smtp.starttls.required=true</code></li> </ul>","title":"Email and TLS"},{"location":"faqs/#git-integration","text":"<p><p>Q: Tower authentication to BitBucket fails, with the Tower backend log containing a warning: \"Can't retrieve revisions for pipeline - https://my.bitbucketserver.com/path/to/pipeline/repo - Cause: Get branches operation not support by BitbucketServerRepositoryProvider provider\"</p></p> <p>If you have supplied correct BitBucket credentials and URL details in your tower.yml, but experience this error, update your Tower version to at least v22.3.0. This version addresses SCM provider authentication issues and is likely to resolve the retrieval failure described here.</p>","title":"Git integration"},{"location":"faqs/#healthcheck","text":"<p><p>Q: Does Tower offer a healthcheck API endpoint?</p></p> <p>Yes. Customers wishing to implement automated healtcheck functionality should use Tower's <code>service-info</code> endpoint.</p> <p>Example:</p> <pre>1\n2\n3</pre><pre><code># Run a healthcheck and extract the HTTP response code:\n$ curl -o /dev/null -s -w \"%{http_code}\\n\" --connect-timeout 2  \"https://api.tower.nf/service-info\"  -H \"Accept: application/json\"\n200\n</code></pre>","title":"Healthcheck"},{"location":"faqs/#logging","text":"<p><p>Q: Can Tower enable detailed logging related to sign-in activity?</p></p> <p>Yes. For more detailed logging related to login events, set the following environment variable: <code>TOWER_SECURITY_LOGLEVEL=DEBUG</code>.</p> <p><p>Q: Can Tower enable detailed logging related to application activites?</p></p> <p>Yes. For more detailed logging related to application activities, set the following environment variable: <code>TOWER_LOG_LEVEL=TRACE</code>.</p> <p><p>Q: Version 22.3.1: My downloaded Nextflow log file is broken.</p></p> <p>A Tower Launcher issue has been identified which affects the Nextflow log file download in Tower version 22.3.1. A patch was released in version 22.3.2 that addresses this behavior. Update Tower to version 22.3.2 or later.</p>","title":"Logging"},{"location":"faqs/#login","text":"<p><p>Q: Can I completely disable Tower's email login feature?</p></p> <p>The email login feature cannot be completely removed from the Tower login screen.</p> <p><p>Q: How can I restrict Tower access to only a subset of email addresses?</p></p> <p>You can restrict which emails are allowed to have automatic access to your Tower implementation via a configuration in tower.yml.</p> <p>Users without automatic access will receive an acknowledgment of their login request but be unable to access the platform until approved by a Tower administration via the Administrator Console.</p> <pre>1\n2\n3\n4\n5</pre><pre><code># This any email address that matches a pattern here will have automatic access.\ntower:\n  trustedEmails:\n    - '*@seqera.io`\n    - 'named_user@example.com'\n</code></pre> <p><p>Q: Why am I receiving login errors stating that admin approval is required when using Azure AD OIDC?</p></p> <p>The Azure AD app integrated with Tower must have user consent settings configured to \"Allow user consent for apps\" to ensure that admin approval is not required for each application login. See User consent settings.</p> <p><p>Q: Why is my OIDC redirect_url set to http instead of https?</p></p> <p>This can occur for several reasons. Please verify the following:</p> <ol> <li>Your <code>TOWER_SERVER_URL</code> environment variable uses the <code>https://</code> prefix.</li> <li>Your <code>tower.yml</code> has <code>micronaut.ssl.enabled</code> set to <code>true</code>.</li> <li>Any Load Balancer instance that sends traffic to the Tower application is configured to use HTTPS as its backend protocol rather than TCP.</li> </ol> <p><p>Q: Why isn't my OIDC callback working?</p></p> <p>Callbacks could fail for many reasons. To more effectively investigate the problem:</p> <ol> <li>Set the Tower environment variable to <code>TOWER_SECURITY_LOGLEVEL=DEBUG</code>.</li> <li>Ensure your <code>TOWER_OIDC_CLIENT</code>, <code>TOWER_OIDC_SECRET</code>, and <code>TOWER_OIDC_ISSUER</code> environment variables all match the values specified in your OIDC provider's corresponding application.</li> <li>Ensure your network infrastructure allow necessary egress and ingress traffic.</li> </ol> <p><p>Q: Why did Google SMTP start returning <code>Username and Password not accepted</code> errors?</p> Previously functioning Tower Enterprise email integration with Google SMTP are likely to encounter errors as of May 30, 2022 due to a security posture change implemented by Google.</p> <p>To reestablish email connectivity, please follow the instructions at https://support.google.com/accounts/answer/3466521 to provision an app password. Update your <code>TOWER_SMTP_PASSWORD</code> environment variable with the app password, and restart the application.</p>","title":"Login"},{"location":"faqs/#logging_1","text":"<p><p>Q: Can Tower enable detailed logging related to sign-in activity?</p></p> <p>Yes. For more detailed logging related to login events, set the following environment variable: <code>TOWER_SECURITY_LOGLEVEL=DEBUG</code>.</p> <p><p>Q: Can Tower enable detailed logging related to application activities?</p></p> <p>Yes. For more detailed logging related to application activities, set the following environment variable: <code>TOWER_LOG_LEVEL=TRACE</code>.</p>","title":"Logging"},{"location":"faqs/#miscellaneous","text":"<p><p>Q: Is my data safe?</p></p> <p>Yes, your data stays strictly within your infrastructure itself. When you launch a workflow through Tower, you need to connect your infrastructure (HPC/VMs/K8s) by creating the appropriate credentials and compute environment in a workspace.</p> <p>Tower then uses this configuration to trigger a Nextflow workflow within your infrastructure similar to what is done via the Nextflow CLI, therefore Tower does not manipulate any data itself and no data is transferred to the infrastructure where Tower is running.</p>","title":"Miscellaneous"},{"location":"faqs/#monitoring","text":"<p><p>Q: Can Tower integrate with 3rd party Java-based Application Performance Monitoring (APM) solutions?</p></p> <p>Yes. You can mount the APM solution's JAR file in the <code>backend</code> container and set the agent JVM option via the <code>JAVA_OPTS</code> env variable.</p> <p><p>Q: Is it possible to retrieve the trace file for a Tower-based workflow run?</p> Yes. Although it is not possible to directly download the file via Tower, you can configure your workflow to export the file to persistent storage:</p> <ol> <li>Set the following block in your <code>nextflow.config</code>:</li> </ol> <pre>1\n2\n3</pre><pre><code>trace {\n    enabled = true\n}\n</code></pre> <ol> <li>Add a copy command to your pipeline's Advanced options &gt; Post-run script field:</li> </ol> <pre>1\n2\n3</pre><pre><code># Example: Export the generated trace file to an S3 bucket\n# Ensure that your Nextflow head job has the necessary permissions to interact with the target storage medium!\naws s3 cp ./trace.txt s3://MY_BUCKET/trace/trace.txt\n</code></pre> <p><p>Q: When monitoring pipeline execution via the Runs tab, why do I occasionally see Tower reporting \"Live events sync offline\"?</p></p> <p>Nextflow Tower uses server-sent events to push real-time updates to your browser. The client must establish a connection to the Nextflow Tower server's <code>/api/live</code> endpoint to initiate the stream of data, and this connection can occasionally fail due to factors like network latency.</p> <p>To resolve the issue, please try reloading the UI to reinitiate the client's connection to the server. If reloading fails to resolve the problem, please contact Seqera Support for assistance with webserver timeout settings adjustments.</p>","title":"Monitoring"},{"location":"faqs/#nextflow-configuration","text":"<p><p>Q: How can I specify Nextflow CLI run arguments when launching from Tower?</p></p> <p>As of Nextflow v22.09.1-edge, when invoking a pipeline from Tower, you can specify Nextflow CLI run arguments by setting the <code>NXF_CLI_OPTS</code> environment variable via pre-run script:</p> <pre>1\n2</pre><pre><code># Example:\nexport NXF_CLI_OPTS='-dump-hashes'\n</code></pre> <p><p>Q: Can a repository's <code>nextflow_schema.json</code> support multiple input file mimetypes?</p></p> <p>No. As of April 2022, it is not possible to configure an input field (example) to support different mime types (e.g. a <code>text/csv</code>-type file during one execution, and a <code>text/tab-separated-values</code> file in a subsequent run).</p> <p><p>Q: Why are my <code>--outdir</code> artefacts not available when executing runs in a cloud environment?</p></p> <p>As of April 2022, Nextflow resolves relative paths against the current working directory. In a classic grid HPC, this normally corresponds to a subdirectory of the user's $HOME directory. In a cloud execution environment, however, the path will be resolved relative to the container file system meaning files will be lost when the container is termination. See here for more details.</p> <p>Tower Users can avoid this problem by specifying the following configuration in the Advanced options &gt; Nextflow config file configuration textbox: <code>params.outdir = workDir + '/results</code>. This will ensure the output files are written to your stateful storage rather than ephemeral container storage.</p> <p><p>Q: Can Nextflow be configured to ignore a Singularity cache?</p></p> <p>Yes. To ignore the Singularity cache, add the following configuration item to your workflow: <code>process.container = 'file:///some/singularity/image.sif'</code>.</p> <p><p>Q: Why does Nextflow fail with a <code>WARN: Cannot read project manifest ... path=nextflow.config</code> error message?</p></p> <p>This error can occur when executing a pipeline where the source git repository's default branch is not populated with <code>main.nf</code> and <code>nextflow.config</code> files, regardless of whether the invoked pipeline is using a non-default revision/branch (e.g. <code>dev</code>).</p> <p>Current as of May 16, 2022, there is no solution for this problem other than to create blank <code>main.nf</code> and <code>nextflow.config</code> files in the default branch. This will allow the pipeline to run, using the content of the <code>main.nf</code> and <code>nextflow.config</code> in your target revision.</p> <p><p>Q: Is it possible to maintain different Nextflow configuration files for different environments?</p></p> <p>Yes. The main <code>nextflow.config</code> file will always be imported by default. Instead of managing multiple <code>nextflow.config</code> files (each customized for an environment), you can create unique environment config files and import them as their own profile in the main <code>nextflow.config</code>.</p> <p>Example:</p> <pre> 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11</pre><pre><code>// nextflow.config\n\n&lt;truncated&gt;\n\nprofiles {\n    test { includeConfig 'conf/test.config' }\n    prod { includeConfig 'conf/prod.config' }\n    uat  { includeConfig 'conf/uat.config'  }\n}\n\n&lt;truncated&gt;\n</code></pre> <p><p>Q: Is there a limitation to the size of the BAM files that can be uploaded to the S3 bucket?</p></p> <p>You will see this on your log file if you encountered an error related to this: <code>WARN: Failed to publish file: s3://[bucket-name]</code></p> <p>AWS have a limitation on the size of the object that can be uploaded to S3 when using the multipart upload feature. You may refer to this documentation for more information. For this specific instance, it is hitting the maximum number of parts per upload.</p> <p>The following configuration are suggested to work with the above stated AWS limitation:</p> <ul> <li>Head Job CPUs = 16</li> <li>Head Job Memory = 60000</li> <li>Pre-run script = export NXF_OPTS=\"-Xms20G -Xmx40G\"</li> <li>Update the <code>nextflow.config</code> to increase the chunk size and slow down the number of transfers.     <pre> 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15</pre><pre><code>aws {\n  batch {\n      maxParallelTransfers = 5\n      maxTransferAttempts = 3\n      delayBetweenAttempts = 30\n  }\n  client {\n      uploadChunkSize = '200MB'\n      maxConnections = 10\n      maxErrorRetry = 10\n      uploadMaxThreads = 10\n      uploadMaxAttempts = 10\n      uploadRetrySleep = '10 sec'\n  }\n}\n</code></pre></li> </ul> <p><p>Q: Why is Nextflow forbidden to retrieve a params file from Nextflow Tower? </p></p> <p>Ephemeral endpoints can only be consumed once. Nextflow versions older than <code>22.04</code> may try to call the same endpoint more than once, resulting in an error similar to the following: <code>Cannot parse params file: /ephemeral/example.json - Cause: Server returned HTTP response code: 403 for URL: https://api.tower.nf/ephemeral/example.json</code>.</p> <p>To resolve this problem, please upgrade your Nextflow version to version <code>22.04.x</code> or later.</p> <p><p>Q: How can I prevent Nextflow from uploading intermediate files from local scratch to my S3 work directory? </p></p> <p>Nextflow will only unstage files/folders that have been explicitly defined as process outputs. If your workflow has processes that generate folder-type outputs, please ensure that the process also purges any intermediate files that reside within. Failure to do so will result in the intermediate files being copied as part of the task unstaging process, resulting in additional storage costs and lengthened pipeline execution times.</p> <p><p>Q: Why do some values specified in my git repository's nextflow.config change when the pipeline is launched via Tower? </p> You may notice that some values specified in your pipeline repository's nextflow.config have changed when the pipeline is invoked via Tower. This occurs because Tower is configured with a set of default values that are superimposed on the pipeline configuration (with the Tower defaults winning).</p> <p>Example: The following code block is specified in your nextflow.config:</p> <pre>1\n2\n3\n4\n5\n6\n7</pre><pre><code>aws {\n  region = 'us-east-1'\n  client {\n    uploadChunkSize = 209715200 // 200 MB\n  }\n  ...\n}\n</code></pre> <p>When the job instantiates on the AWS Batch Compute Environment, you will see that the <code>uploadChunkSize</code> changed:</p> <pre>1\n2\n3\n4\n5\n6\n7</pre><pre><code>aws {\n   region = 'us-east-1'\n   client {\n      uploadChunkSize = 10485760 // 10 MB\n   }\n   ...\n}\n</code></pre> <p>This change occurred because Tower superimposes its 10 MB default value rather than using the value specified in the nextflow.config file.</p> <p>To force the Tower-invoked job to use your desired value, please add the configuration setting in the Tower Workspace Launch screen's Advanced options &gt; Nextflow config file textbox. In the case of our example above, you would simply need to add <code>aws.client.uploadChunkSize = 209715200 // 200 MB</code> .</p> <p>Nextflow configuration values that are affected by this behaviour include:</p> <ul> <li>aws.client.uploadChunkSize</li> <li>aws.client.storageEncryption</li> </ul> <p><p>Q: <code>Missing output file(s) [X] expected by process [Y]</code> error during task execution in an environment using Fusion v1 </p></p> <p>Fusion v1 has a limitation which causes tasks that run for less than 60 seconds to fail as the output file generated by the task is not yet detected by Nextflow. This is a limitation inherited from a Goofys driver used by the Fusion v1 implementation. Fusion v2 (to be made available to Tower Enterprise users during Q1 of 2023) resolves this issue.</p> <p>If Fusion v2 is not yet available, or updating to v2 is not feasible, this issue can be addressed by instructing Nextflow to wait for 60 seconds after the task completes.</p> <p>From Advanced options &gt; Nextflow config file in Pipeline settings, add the following line to your Nextflow configuration:</p> <pre>1</pre><pre><code>process.afterScript = 'sleep 60'\n</code></pre> <p><p>Q: Why are jobs in RUNNING status not terminated when my pipeline run is canceled?</p></p> <p>The behavior of Tower when canceling a run depends on the <code>errorStrategy</code> defined in your process script. If the process <code>errorStrategy</code> is set to <code>finish</code>, an orderly pipeline shutdown is initiated when you cancel (or otherwise interrupt) a run. This instructs Nextflow to wait for the completion of any submitted jobs. To ensure that all jobs are terminated when your run is canceled, set <code>errorStrategy</code> to <code>terminate</code> in your Nextflow config. For example:</p> <pre>1\n2\n3\n4\n5\n6</pre><pre><code>process ignoreAnyError {\n  errorStrategy 'ignore'\n\n  script:\n  &lt;your command string here&gt;\n}\n</code></pre> <p><p>Q: Why do some cached tasks run from scratch when I re-launch a pipeline?</p></p> <p>When re-launching a pipeline, Tower relies on Nextflow's <code>resume</code> functionality for the continuation of a workflow execution. This skips previously completed tasks and uses a cached result in downstream tasks, rather than running the completed tasks again. The unique ID (hash) of the task is calculated using a composition of the task's:</p> <ul> <li>Input values</li> <li>Input files</li> <li>Command line string</li> <li>Container ID</li> <li>Conda environment</li> <li>Environment modules</li> <li>Any executed scripts in the bin directory</li> </ul> <p>A change in any of these values results in a changed task hash. Changing the task hash value means that the task will be run again when the pipeline is re-launched. To aid debugging efforts when a re-launch behaves unexpectedly, run the pipeline twice with <code>dumpHashes=true</code> set in your Nextflow config file (from Advanced options -&gt; Nextflow config file in the Pipeline settings). This will instruct Nextflow to dump the task hashes for both executions in the <code>nextflow.log</code> file. You can compare the log files to determine the point at which the hashes diverge in your pipeline when it is resumed.</p> <p>See here for more information on the Nextflow <code>resume</code> mechanism.</p> <p><p>Q: Why does my run fail with an \"o.h.e.jdbc.spi.SqlExceptionHelper - Incorrect string value\" error?</p></p>  <pre>1\n2\n3</pre><pre><code> [scheduled-executor-thread-2] - WARN  o.h.e.jdbc.spi.SqlExceptionHelper - SQL Error: 1366, SQLState: HY000\n [scheduled-executor-thread-2] - ERROR o.h.e.jdbc.spi.SqlExceptionHelper - (conn=34) Incorrect string value: '\\xF0\\x9F\\x94\\x8D |...' for column 'error_report' at row 1\n [scheduled-executor-thread-2] - ERROR i.s.t.service.job.JobSchedulerImpl - Oops .. unable to save status of job id=18165; name=nf-workflow-26uD5XXXXXXXX; opId=nf-workflow-26uD5XXXXXXXX; status=UNKNOWN\n</code></pre>  <p>Runs will fail if your Nextflow script or Nextflow config contain illegal characters (such as emojis or other non-UTF8 characters). Validate your script and config files for any illegal characters before atttempting to run again.</p>","title":"Nextflow Configuration"},{"location":"faqs/#nextflow-launcher","text":"<p><p>Q: There are several nf-launcher images available in the Seqera image registry. How can I tell which one is most appropriate for my implementation?</p></p> <p>Your Tower implementation knows the nf-launcher image version it needs and will specify this value automatically when launching a pipeline.</p> <p>If you are restricted from using public container registries, please see Tower Enterprise Release Note instructions (example) for the specific image you should use and how to set this as the default when invoking pipelines.</p> <p><p>Q: The nf-launcher is pinned to a specific Nextflow version. How can I make it use a different release? </p></p> <p>Each Nextflow Tower release uses a specific nf-launcher image by default. This image is loaded with a specific Nextflow version, meaning that any workflow run in the container uses this Nextflow version by default. You can force your jobs to use a newer/older version of Nextflow with any of the following strategies:</p> <ol> <li>Use the Pre-run script advanced launch option to set the desired Nextflow version. Example: <code>export NXF_VER=22.08.0-edge</code></li> <li>For jobs executing in an AWS Batch compute environment, create a custom job definition which references a different nf-launcher image.</li> </ol>","title":"Nextflow Launcher"},{"location":"faqs/#oidc","text":"<p><p>Q: Can I have users seamlessly log in to Tower if they already have an active session with their OpenId Connect (OIDC) Identity Provider (IDP)?</p></p> <p>Yes. If you are using OIDC as your authentication method, it is possible to implement a seamless login flow for your users.</p> <p>Rather than directing your users to <code>http(s)://YOUR_TOWER_HOSTNAME</code> or <code>http(s)://YOUR_TOWER_HOSTNAME/login</code>, point the user-initiated login URL here instead: <code>http(s)://YOUR_TOWER_HOSTNAME/oauth/login/oidc</code>.</p> <p>If your user already has an active session established with the IDP, they will be automatically logged into Tower rather than having to manually choose their authentication method.</p>","title":"OIDC"},{"location":"faqs/#optimization","text":"<p><p>Q: When using optimization, why are tasks failing with an <code>OutOfMemoryError: Container killed due to memory usage</code> error?</p></p> <p>Improvements are being made to the way Nextflow calculates the optimal memory needed for containerized tasks, which will resolve issues with underestimating memory allocation in an upcoming release.</p> <p>A temporary workaround for this issue is to implement a <code>retry</code> error strategy in the failing process that will increase the allocated memory each time the failed task is retried. Add the following <code>errorStrategy</code> block to the failing process:</p> <pre>1\n2\n3\n4\n5</pre><pre><code>process {\n    errorStrategy = 'retry'\n    maxRetries    = \u200b3\n    memory  = 1.GB * task.attempt\n}\n</code></pre>","title":"Optimization"},{"location":"faqs/#plugins","text":"<p><p>Q: Is it possible to use the Nextflow SQL DB plugin to query AWS Athena?</p></p> <p>Yes. As of Nextflow 22.05.0-edge, your Nextflow pipelines can query data from AWS Athena. You must add the following configuration items to your <code>nextflow.config</code> (Note: the use of secrets is optional):</p> <pre> 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13</pre><pre><code>plugins {\n  id 'nf-sqldb@0.4.0'\n}\n\nsql {\n    db {\n        'athena' {\n              url = 'jdbc:awsathena://AwsRegion=YOUR_REGION;S3OutputLocation=s3://YOUR_S3_BUCKET'\n              user = secrets.ATHENA_USER\n              password = secrets.ATHENA_PASSWORD\n            }\n    }\n}\n</code></pre> <p>You can then call the functionality from within your workflow.</p> <pre>1\n2\n3</pre><pre><code>// Example\n  channel.sql.fromQuery(\"select * from test\", db: \"athena\", emitColumns:true).view()\n}\n</code></pre> <p>For more information on the implementation, please see https://github.com/nextflow-io/nf-sqldb/discussions/5.</p>","title":"Plugins"},{"location":"faqs/#repositories","text":"<p><p>Q: Can Tower integrate with private docker registries like JFrog Artifactory?</p></p> <p>Yes. Tower-invoked jobs can pull container images from private docker registries. The method to do so differs depending on platform, however:</p> <ul> <li>If using AWS Batch, modify your EC2 Launch Template as per these directions from AWS.Note:<ul> <li>This solution requires that your Docker Engine be at least 17.07 to use <code>--password-stdin</code>.</li> <li>You may need to add the following additional commands to your Launch Template depending on your security posture: <code>cp /root/.docker/config.json /home/ec2-user/.docker/config.json &amp;&amp; chmod 777 /home/ec2-user/.docker/config.json</code></li> </ul> </li> <li>If using Azure Batch, please create a Container Registry-type credential in your Tower Workspace and associate it with the Azure Batch object also defined in the Workspace.</li> <li>If using Kubernetes, please use an <code>imagePullSecret</code> as per https://github.com/nextflow-io/nextflow/issues/2827.</li> </ul> <p><p>Q: Why does my Nextflow log have a <code>Remote resource not found</code> error when trying to contact the workflow repository? </p></p> <p>This error can occur if the Nextflow head job fails to retrieve the necessary repository credentials from Nextflow Tower.</p> <p>To determine if this is the case, please do the following:</p> <ol> <li>Check your Nextflow log for an entry like <code>DEBUG nextflow.scm.RepositoryProvider - Request [credentials -:-]</code>.</li> <li>If the above is true, please check the protocol of the string that was assigned to your Tower instance's <code>TOWER_SERVER_URL</code> configuration value. It is possible this has been erroneously set to <code>http</code> rather than <code>https</code>.</li> </ol>","title":"Repositories"},{"location":"faqs/#secrets","text":"<p><p>Q: When using secrets in Tower workflow run, the process executed with an error <code>Missing AWS execution role arn</code> </p></p> <p>The ECS Agent must be empowered to retrieve Secrets from the AWS Secrets Manager. Secrets-using pipelines that are launched from Nextflow Tower and execute in an AWS Batch Compute Environment will encounter this error if an IAM Execution Role is not provided. Please see the Pipeline Secrets for remediation steps.</p> <p><p>Q: Why do work tasks which use Secrets fail when running in AWS Batch?</p></p> <p>Users may encounter a few different errors when executing pipelines that use Secrets, via AWS Batch:</p> <ul> <li> <p>If you use <code>nf-sqldb</code> version 0.4.1 or earlier and have Secrets in your <code>nextflow.config</code>, you may see following error in your Nextflow Log: <code>nextflow.secret.MissingSecretException: Unknown config secret {SECRET_NAME}</code>.     You can resolve this error by explicitly defining the <code>xpack-amzn</code> plugin in your configuration.     Example:</p> <pre>1\n2\n3\n4</pre><pre><code>plugins {\n  id 'xpack-amzn'\n  id 'nf-sqldb'\n}\n</code></pre> </li> <li> <p>If you have two or more processes that use the same container image, but only a subset of these processes use Secrets, your Secret-using processes may fail during the initial run but succeed when resumed. This is due to an bug in how Nextflow (22.07.1-edge and earlier) registers jobs with AWS Batch.</p> <p>To resolve the issue, please upgrade your Nextflow version to 22.08.0-edge. If you cannot upgrade, you can use the following as workarounds:</p> <ol> <li>Use a different container image for each process.</li> <li>Define the same set of Secrets in each process that uses the same container image.</li> </ol> </li> </ul>","title":"Secrets"},{"location":"faqs/#tower-agent","text":"<p><p>Q:Tower Agent closes a session with \"Unexpected Exception in WebSocket [io.seqera.tower.agent.AgentClientSocket$Intercepted@698514a]: Operation timed out java.io.IOException: Operation timed out\"</p></p> <p>The reconnection logic of Tower Agent has been improved with the release of version 0.5.0. Update your Tower Agent version before relaunching your pipeline.</p>","title":"Tower Agent"},{"location":"faqs/#tower-configuration","text":"<p><p>Q: Can I customize menu items on the Tower navigation menu?</p></p> <p>Yes. Using the <code>navbar</code> snippet in the tower.yml configuration file, you can specify custom navigation menu items for your Tower installation. See here for more details.</p> <p><p>Q: Can a custom path be specified for the <code>tower.yml</code> configuration file?</p></p> <p>Yes. Provide a POSIX-compliant path to the <code>TOWER_CONFIG_FILE</code> environment variable.</p> <p><p>Q: Why do parts of <code>tower.yml</code> not seem to work when I run my Tower implementation?</p></p> <p>There are two reasons why configurations specified in <code>tower.yml</code> are not being expressed by your Tower instance:</p> <ol> <li>There is a typo in one of the key value pairs.</li> <li> <p>There is a duplicate key present in your file.</p> <pre> 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11</pre><pre><code># EXAMPLE\n# This block will not end up being enforced because there is another `tower` key below.\ntower:\n  trustedEmails:\n    - user@example.com\n\n# This block will end up being enforced because it is defined last.\ntower:\n  auth:\n    oidc:\n      - \"*@foo.com\"\n</code></pre> </li> </ol> <p><p>Q: Do you have guidance on how to create custom Nextflow containers?</p></p> <p>Yes. Please see https://github.com/seqeralabs/gatk4-germline-snps-indels/tree/master/containers.</p> <p><p>Q: What DSL version does Nextflow Tower set as default for Nextflow head jobs?</p> <p>As of Nextflow 22.03.0-edge, DSL2 is the default syntax.</p> <p>To minimize disruption on existing pipelines, Nextflow Tower version 22.1.x and later are configured to default Nextflow head jobs to DSL 1 for a transition period (ending TBD).</p> <p>You can force your Nextflow head job to use DSL2 syntax via any of the following techniques:</p> <ul> <li>Adding <code>export NXF_DEFAULT_DSL=2</code> in the Advanced Features &gt; Pre-run script field of Tower Launch UI.</li> <li>Specifying <code>nextflow.enable.dsl = 2</code> at the top of your Nextflow workflow file.</li> <li>Providing the <code>-dsl2</code> flag when invoking the Nextflow CLI (e.g. <code>nextflow run ... -dsl2</code>)</li> </ul> <p><p>Q: Can Tower to use a Nextflow workflow stored in a local git repository?</p></p> <p>Yes. As of v22.1, Nextflow Tower Enterprise can link to workflows stored in \"local\" git repositories. To do so:</p> <ol> <li>Volume mount your repository folder into the Tower Enterprise <code>backend</code> container.</li> <li>Update your <code>tower.yml</code> with the following configuration:</li> </ol> <pre>1\n2\n3\n4</pre><pre><code>tower:\n    pipeline:\n        allow-local-repos:\n            - /path/to/repo\n</code></pre> <p>Note: This feature is not available to Tower Cloud users.</p> <p><p>Q: Am I forced to define sensitive values in <code>tower.env</code>?</p> No. You can inject values directly into <code>tower.yml</code> or - in the case of a Kubernetes deployment - reference data from a secrets manager like Hashicorp Vault.</p> <p>Please contact Seqera Labs for more details if this is of interest.</p>","title":"Tower Configuration"},{"location":"faqs/#tower-forge","text":"<p><p>Q: What does the <code>Enable GPU</code> option do when building an AWS Batch cluster via Tower Forge?</p></p> <p>Activating the Enable GPU field while creating an AWS Batch environment with Tower Forge will result in an AWS-recommended GPU-optimized ECS AMI being used as your Batch cluster's default image.</p> <p>Note:</p> <ol> <li>Activation does not cause GPU-enabled instances to automatically spawn in your Batch cluster. You must still specify these in the Forge screen's Advanced options &gt; Instance types field.</li> <li>Population of the Forge screen's Advanced options &gt; AMI Id field will supersede the AWS-recommended AMI.</li> <li>Your Nextflow script must include accelerator directives to use the provisioned GPUs.</li> </ol>","title":"Tower Forge"},{"location":"faqs/#tw-cli","text":"<p><p>Q: Can a custom run name be specified when launch a pipeline via the <code>tw</code> CLI?</p></p> <p>Yes. As of <code>tw</code> v0.6.0, this is possible. Example: <code>tw launch --name CUSTOM_NAME ...</code></p> <p><p>Q: Why are tw cli commands resulting in segfault errors?</p></p> <p><code>tw</code> cli versions 0.6.1 through 0.6.4 were compiled using glibc instead of MUSL. This change was discovered to cause segfaults in certain operating systems and has been rolled back in tw cli 0.6.5.</p> <p>To resolve this error, please try using the MUSL-based binary first. If this fails to work on your machine, an alternative Java JAR-based solution is available for download and use.</p> <p><p>Q: Can <code>tw cli</code> communicate with hosts using http?</p></p> <p>This error indicates that your Tower host accepts connections using http (insecure), rather than https. If your host cannot be configured to accept https connections, run your tw cli command with the <code>--insecure</code> flag.</p> <pre>1\n2</pre><pre><code> ERROR: You are trying to connect to an insecure server: http://hostname:port/api\n        if you want to force the connection use '--insecure'. NOT RECOMMENDED!\n</code></pre> <p>To do this, add the <code>--insecure</code> flag before your cli command (see below). Note that, although this approach is available for use in deployments that do not accept <code>https:</code> connections, it is not recommended. Best practice is to use <code>https:</code> wherever possible.</p> <pre>1</pre><pre><code>$ tw --insecure info\n</code></pre> <p>Note: The <code>${TOWER_API_ENDPOINT}</code> is equivalent to the <code>${TOWER_SERVER_URL}/api</code>.</p> <p><p>Q: Can a user resume/relaunch a pipeline using the tw cli?</p></p> <p>Yes, it is possible with <code>tw runs relaunch</code>.</p> <pre> 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13</pre><pre><code>$ tw runs relaunch -i 3adMwRdD75ah6P -w 161372824019700\n\n  Workflow 5fUvqUMB89zr2W submitted at [org / private] workspace.\n\n\n$ tw runs list -w 161372824019700\n\n  Pipeline runs at [org / private] workspace:\n\n     ID             | Status    | Project Name   | Run Name        | Username    | Submit Date\n    ----------------+-----------+----------------+-----------------+-------------+-------------------------------\n     5fUvqUMB89zr2W | SUBMITTED | nf/hello       | magical_darwin  | seqera-user | Tue, 10 Sep 2022 14:40:52 GMT\n     3adMwRdD75ah6P | SUCCEEDED | nf/hello       | high_hodgkin    | seqera-user | Tue, 10 Sep 2022 13:10:50 GMT\n</code></pre>","title":"tw CLI"},{"location":"faqs/#workspaces","text":"<p><p>Q: Why is my Tower-invoked pipeline trying to contact a different Workspace than the one it was launched from?</p></p> <p>This problem will express itself with the following entry in your Nextflow log: <code>Unexpected response for request http://YOUR_TOWER_URL/api/trace/TRACE_ID/begin?workspaceId=WORKSPACE_ID</code>.</p> <p>This can occur due to the following reasons:</p> <ol> <li>An access token value has been hardcoded in the <code>tower.accessToken</code> block of your <code>nextflow.config</code> (either via the git repository itself or override value in the launch form).</li> <li>In cases where your compute environment is an HPC cluster, the credentialized user's home directory contains a stateful <code>nextflow.config</code> with a hardcoded token (e.g. `~/.nextflow/config).</li> </ol> <p><p>Q: What privilege level is granted to a user assigned to a Workspace both as a Participant and Team member?</p></p> <p>It is possible for a user to be concurrently assigned to a Workspace both as a named Participant and member of a Team. In such cases, Tower will grant the higher of the two privilege sets.</p> <p>Example:</p> <ul> <li>If the Participant role is Launch and the Team role is Admin, the user will have Admin rights.</li> <li>If the Participant role is Admin and the Team role is Launch, the user will have Admin rights.</li> <li>If the Participant role is Launch and the Team role is Launch, the user will have Launch rights.</li> </ul> <p>As a best practice, Seqera suggests using Teams as the primary vehicle for assigning rights within a Workspace and only adding named Participants when one-off privilege escalations are deemed necessary.</p>","title":"Workspaces"},{"location":"faqs/#amazon","text":"","title":"Amazon"},{"location":"faqs/#ebs","text":"<p><p>Q: EBS Autoscaling: Why do some EBS volumes remain active after their associated jobs have completed?</p></p> <p>The EBS autoscaling solution relies on an AWS-provided script running on each container host. This script performs AWS EC2 API requests to delete EBS volumes when the jobs using those volumes have been completed. When running large Batch clusters (hundreds of compute nodes or more), EC2 API rate limits may cause the deletion of unattached EBS volumes to fail. Volumes that remain active after Nextflow jobs have been completed will incur additional costs and should therefore be manually deleted. You can monitor your AWS account for any orphaned EBS volumes via the EC2 console or with a Lambda function. See here for more information.</p>","title":"EBS"},{"location":"faqs/#ec2-instances","text":"<p><p>Q: Can I run a Nextflow head job on AWS Graviton instances?</p></p> <p>Yes, Nextflow supports Graviton architecture \u2014 use AWS Batch queues with Graviton-based instance types.</p>","title":"EC2 Instances"},{"location":"faqs/#ecs","text":"<p><p>Q:How often are Docker images pulled by the ECS Agent?</p></p> <p>As part of the AWS Batch creation process, Tower Forge will set ECS Agent parameters in the EC2 Launch Template that is created for your cluster's EC2 instances:</p> <ul> <li>For clients using Tower Enterprise v22.01 or later:<ul> <li>Any AWS Batch environment created by Tower Forge will set the ECS Agent's <code>ECS_IMAGE_PULL_BEHAVIOUR</code> set to <code>once</code>.</li> </ul> </li> <li>For clients using Tower Enterprise v21.12 or earlier:<ul> <li>Any AWS Batch environment created by Tower Forge will set the ECS Agent's <code>ECS_IMAGE_PULL_BEHAVIOUR</code> set to <code>default</code>.</li> </ul> </li> </ul> <p>Please see the AWS ECS documentation for an in-depth explanation of this difference.</p> <p></p>Note: This behaviour cannot be changed within the Tower Application. <p><p>Q: We encountered an error saying unable to parse HTTP 429 response body.</p></p> <p><code>CannotPullContainerError: Error response from daemon: error parsing HTTP 429 response body: invalid character 'T' looking for beginning of value: \"Too Many Requests (HAP429)\"</code></p> <p>This is because of the dockerhub rate limit of 100 anonymous pulls per 6 hours. We suggest to use the following on your launch template in order to avoid this issue:</p> <p><code>echo ECS_IMAGE_PULL_BEHAVIOR=once &gt;&gt; /etc/ecs/ecs.config</code></p> <p><p>Q: Help! My job failed due to a CannotInspectContainerError error.</p></p> <p>There are multiple reasons why your pipeline could fail with an <code>Essential container in task exited - CannotInspectContainerError: Could not transition to inspecting; timed out after waiting 30s</code> error.</p> <p>Please try the following:</p> <ol> <li>Upgrade your ECS Agent to 1.54.1 or newer (instructions for checking your ECS Agent version);</li> <li>Provision more storage space for your EC2 instance (preferably via ebs-autoscaling to ensure scalability).</li> <li>If the error is accompanied by <code>command exit status: 123</code> and a <code>permissions denied</code> error tied to a system command, please ensure that the binary is set to be executable (i.e. <code>chmod u+x</code>).</li> </ol>","title":"ECS"},{"location":"faqs/#queues","text":"<p><p>Q: Does Nextflow Tower support the use of multiple AWS Batch queues during a single job execution?</p></p> <p>Yes. Even though you can only create/identify a single work queue during the definition of your AWS Batch Compute Environment within Nextflow Tower, you can spread tasks across multiple queues when your job is sent to Batch for execution via your pipeline configuration.</p> <p>Adding the following snippet to either your nextflow.config or the Advanced Features &gt; Nextflow config gile field of Tower Launch UI, will cause processes to be distributed across two AWS Batch queues, depending on the assigned named.</p> <pre> 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13</pre><pre><code># nextflow.config\n\nprocess {\n  withName: foo {\n    queue: `TowerForge-1jJRSZmHyrrCvCVEOhmL3c-work`\n  }\n}\n\nprocess {\n  withName: bar {\n    queue: `custom-second-queue`\n  }\n}\n</code></pre>","title":"Queues"},{"location":"faqs/#security","text":"<p><p>Q: Can Tower connect to an RDS instance using IAM credentials instead of username/password?</p></p> <p>No. Nextflow Tower must be supplied with a username &amp; password to connect to its associated database.</p>","title":"Security"},{"location":"faqs/#storage","text":"<p><p>Q: Can I use EFS as my work directory?</p></p> <p>As of Nextflow Tower v21.12, you can specify an Amazon Elastic File System instance as your Nextflow work directory when creating your AWS Batch Compute Environment via Tower Forge.</p> <p><p>Q: Can I use FSX for Luster as my work directory?</p></p> <p>As of Nextflow Tower v21.12, you can specify an Amazon FSX for Lustre instance as your Nextflow work directory when creating your AWS Batch Compute Environment via Tower Forge.</p> <p><p>Q: How do I configure my Tower-invoked pipeline to be able to write to an S3 bucket that enforces AES256 server-side encryption?</p> <p>If you need to save files to an S3 bucket protected by a bucket policy which enforces AES256 server-side encryption, additional configuration settings must be provided to the nf-launcher script which invokes the Nextflow head job:</p> <ol> <li> <p>Add the following configuration to the Advanced options &gt; Nextflow config file textbox of the Launch Pipeline screen:</p> <pre>1\n2\n3\n4\n5</pre><pre><code>aws {\n  client {\n    storageEncryption = 'AES256'\n  }\n}\n</code></pre> </li> <li> <p>Add the following configuration to the Advanced options &gt; Pre-run script textbox of the Launch Pipeline screen:     <pre>1</pre><pre><code>export TOWER_AWS_SSE=AES256\n</code></pre></p> </li> </ol> <p>Note: This solution requires at least Tower v21.10.4 and Nextflow 22.04.0.</p>","title":"Storage"},{"location":"faqs/#azure","text":"","title":"Azure"},{"location":"faqs/#aks","text":"<p><p>Q: Why is Nextflow returning a \"... /.git/HEAD.lock: Operation not supported\" error?</p></p> <p>This problem can occur if your Nextflow pod uses an Azure Files-type (SMB) Persistent Volume as its storage medium. By default, the <code>jgit</code> library used by Nextflow attempts a filesystem link operation which is not supported by Azure Files (SMB).</p> <p>To avoid this problem, please add the following code snippet in your pipeline's pre-run script field:</p> <pre>1\n2\n3\n4</pre><pre><code>cat &lt;&lt;EOT &gt; ~/.gitconfig\n[core]\n    supportsatomicfilecreation = true\nEOT\n</code></pre>","title":"AKS"},{"location":"faqs/#batch","text":"<p><p>Q: Why is my Azure Batch VM quota set to 0?</p></p> <p>In order to manage capacity during the global health pandemic, Microsoft has reduced core quotas for new Batch accounts. Depending on your region and subscription type, a newly-created account may not be entitled to any VMs without first making a service request to Azure.</p> <p>Please see Azure's Batch service quotas and limits page for further details.</p>","title":"Batch"},{"location":"faqs/#ssl","text":"<p><p>Q: \"Problem with the SSL CA cert (path? access rights?)\" error</p></p> <p>This can occur if a tool/library in your task container requires SSL certificates to validate the identity of an external data source.</p> <p>You may be able to solve the issue by:</p> <ol> <li>Mounting host certificates into the container (example).</li> </ol> <p><p>Q: Why is my deployment using Azure SQL database returning an error about <code>Connections using insecure transport are prohibited while --require_secure_transport=ON.</code></p></p> <p>This is due to Azure's default MySQL behavior of enforcing the SSL connections between your server and client application, as detailed here. In order to fix this, append the following to your <code>TOWER_DB_URL</code> connection string: <code>useSSL=true&amp;enabledSslProtocolSuites=TLSv1.2&amp;trustServerCertificate=true</code></p> <p>eg, <code>TOWER_DB_URL=jdbc:mysql://azuredatabase.com/tower?serverTimezone=UTC&amp;useSSL=true&amp;enabledSslProtocolSuites=TLSv1.2&amp;trustServerCertificate=true</code></p>","title":"SSL"},{"location":"faqs/#google","text":"","title":"Google"},{"location":"faqs/#retry","text":"<p><p>Q: How do I make my Nextflow pipelines more resilient to VM preemption?</p></p> <p>Running your pipelines on preemptible VMs provides significant cost savings but increases the likelihood that a task will be interrupted before completion. It is a recommended best practice to implement a retry strategy when you encounter exit codes that are commonly related to preemption. Example:</p> <pre>1\n2\n3\n4\n5</pre><pre><code>process {\n  errorStrategy = { task.exitStatus in [8,10,14] ? 'retry' : 'finish' }\n  maxRetries    = 3\n  maxErrors     = '-1'\n}\n</code></pre> <p><p>Q: What are the minimum Tower Service account permissions needed for GLS and GKE?</p></p> <p>The following roles are needed to be granted to the <code>nextflow-service-account</code>.</p> <ol> <li>Cloud Life Sciences Workflows Runner</li> <li>Service Account User</li> <li>Service Usage Consumer</li> <li>Storage Object Admin</li> </ol> <p>For detailed information, please refer to this guide.</p>","title":"Retry"},{"location":"faqs/#kubernetes","text":"<p><p>Q: Pod failing with 'Invalid value: \"xxx\": must be less or equal to memory limit' error</p></p> <p>This error may be encountered when you specify a value in the Head Job memory field during the creation of a Kubernetes-type Compute Environment.</p> <p>If you receive an error that includes <code>field: spec.containers[x].resources.requests</code> and <code>message: Invalid value: \"xxx\": must be less than or equal to memory limit</code>, your Kubernetes cluster may be configured with system resource limits which deny the Nextflow head job's resource request. To isolate which component is causing the problem, try to launch a Pod directly on your cluster via your Kubernetes administration solution. Example:</p> <pre> 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16</pre><pre><code>---\napiVersion: v1\nkind: Pod\nmetadata:\n    name: debug\n    labels:\n        app: debug\nspec:\n    containers:\n        - name: debug\n          image: busybox\n          command: [\"sh\", \"-c\", \"sleep 10\"]\n          resources:\n              requests:\n                  memory: \"xxxMi\" # or \"xxxGi\"\n    restartPolicy: Never\n</code></pre>","title":"Kubernetes"},{"location":"faqs/#on-prem-hpc","text":"<p><p>Q: \"java: command not found\"</p></p> <p>When submitting jobs to your on-prem HPC (regardless of whether using SSH or Tower-Agent authentication), the following error may appear in your Nextflow logs even though you have Java on your $PATH environment variable:</p> <pre>1\n2\n3\n4</pre><pre><code>java: command not found\nNextflow is trying to use the Java VM defined for the following environment variables:\n  JAVA_CMD: java\n  NXF_OPTS:\n</code></pre> <p>Possible reasons for this error:</p> <ol> <li>The queue where the Nextflow head job runs in a different environment/node than your login node userspace.</li> <li>If your HPC cluster uses modules, the Java module may not be loaded by default.</li> </ol> <p>To troubleshoot:</p> <ol> <li>Open an interactive session with the head job queue.</li> <li>Launch the Nextflow job from the interactive session.</li> <li>If you cluster used modules:<ol> <li>Add <code>module load &lt;your_java_module&gt;</code> in the Advanced Features &gt; Pre-run script field when creating your HPC Compute Environment within Nextflow Tower.</li> </ol> </li> <li>If you cluster does not use modules:<ol> <li>Source an environment with java and Nextflow using the Advanced Features &gt; Pre-run script field when creating your HPC Compute Environment within Nextflow Tower.</li> </ol> </li> </ol>","title":"On-Prem HPC"},{"location":"administration/overview/","text":"","title":"User and organization administration"},{"location":"administration/overview/#administration-of-users-organizations-and-memberships","text":"<p>As a Root user, you can access a comprehensive overview of the users, workspaces, and organizations in the system from the Admin panel.</p> <p>The Admin panel menu entry will only be accessible in the top right avatar menu if you are logged in as a Root user. This role should only be assigned to a system administrator, since it enables several high level and potentially risky operations.</p>","title":"Administration of users, organizations, and memberships"},{"location":"administration/overview/#user-administration","text":"<p>The User administration page lists all the users in the Tower database. From this page, you can:</p>","title":"User administration"},{"location":"administration/overview/#search-users","text":"<p>The user search function allows you to find a specific user by name or email and perform various operations with that user.</p>","title":"Search users"},{"location":"administration/overview/#create-a-user","text":"<p>The Add user button above the table allows you to create a new user. If the new user email already exists in the system, the user creation will fail. Once the new user has been created, inform them that access has been granted.</p>","title":"Create a user"},{"location":"administration/overview/#edit-a-user","text":"<p>By selecting a username from the table, you can edit the user's details, or delete the user.</p>","title":"Edit a user"},{"location":"administration/overview/#membership-administration","text":"<p>Available from version 22.3.X</p> <p>From the user list, you have an overview of all the memberships for the selected user. The Membership administration page is reached by selecting the Edit organizations button. From here, you can list and search for all the organizations the user belongs to (as a member or as an owner), change the role of the user for a given membership, remove the user from an organization, or add the user to a new organization.</p> <p>Note: You can only add users to an existing organization, and you cannot remove the last owner of an organization.</p>","title":"Membership administration"},{"location":"administration/overview/#organization-administration","text":"<p>The Organization administration page lists all the organizations in the Tower database. From this page, you can:</p>","title":"Organization administration"},{"location":"administration/overview/#search-organizations","text":"<p>The organization search function allows you to find a specific organization by its name or email and perform various operations with that organization.</p>","title":"Search organizations"},{"location":"administration/overview/#create-an-organization","text":"<p>The Add organization button above the table allows you to create a new organization from scratch.</p>","title":"Create an organization"},{"location":"administration/overview/#edit-an-organization","text":"<p>By selecting an organization name from the table, you can edit the organization's details, or delete it.</p>","title":"Edit an organization"},{"location":"administration/overview/#membership-administration_1","text":"<p>Available from version 22.3.X</p> <p>From the organizations list, you have an overview of all the memberships for the selected organization. Select the Manage users button to access the Membership administration page. From here, you can list and search for all the users that are members or owners of the selected organization, change the role of the user for the given membership, remove the member from the organization, or add a new user to the organization.</p> <p>Note: You can only add existing users to an organization, and you cannot remove a membership if the user being removed is the last owner of the selected organization. To overcome this, promote another user to Owner before removing or demoting the last owner.</p>","title":"Membership administration"},{"location":"api/overview/","text":"<p>Tower exposes a public API with all the necessary endpoints to manage Nextflow workflows programmatically, allowing organizations to incorporate Tower seamlessly into their existing processes.</p>","title":"API"},{"location":"api/overview/#overview","text":"<p>The Tower API can be accessed from <code>https://api.tower.nf</code>. All API endpoints use HTTPS, and all request and response payloads use JSON encoding. All timestamps use the ISO 8601 date-time standard format: <code>YYYY-MM-DDTHH:MM:SSZ</code>.</p>","title":"Overview"},{"location":"api/overview/#openapi","text":"<p>The Tower API uses the OpenAPI standard. The current OpenAPI schema for Tower can be found here.</p>","title":"OpenAPI"},{"location":"api/overview/#endpoints","text":"<p>You can find a detailed list of all Tower endpoints here. This page also includes request and response payload examples, and the ability to test each endpoint interactively.</p>","title":"Endpoints"},{"location":"api/overview/#programmatic-api","text":"<p>You can use tools such as openapi-python-client to generate a programmatic API for a particular language (e.g. Python) based on the OpenAPI schema. However, we do not guarantee that any OpenAPI client generator will work with Tower API; use them at your own risk.</p>","title":"Programmatic API"},{"location":"api/overview/#authentication","text":"<p>Tower API requires an authentication token to be specified in each API request using the Bearer HTTP header.</p> <p>Your personal authorization token can be found in the user top-right menu under Your tokens.</p> <p>To create a new access token, just provide a name for the token. This will help to identify it later.</p> <p></p> <p>The token is only displayed once. Store your token in a safe place.</p> <p>Once created, use the token to authenticate to the Nextflow API via cURL, Postman, or within your code to requests.</p>","title":"Authentication"},{"location":"api/overview/#curl-example","text":"<pre>1</pre><pre><code>curl -H \"Authorization: Bearer eyJ...YTk0\" https://tower.nf/api/workflow\n</code></pre>   <p>Use your token in every API call</p> <p>Your token must be included in every API call. See Bearer token authentication for more information on bearer token authentication.</p>","title":"cURL example"},{"location":"api/overview/#parameters","text":"<p>Some API <code>GET</code> methods will accept standard <code>query</code> parameters, which are defined in the documentation; <code>querystring</code> optional parameters such as page size, number (when available) and file name; and body parameters, mostly used for <code>POST</code>, <code>PUT</code> and <code>DELETE</code> requests.</p> <p>Additionally, several head parameters are accepted such as <code>Authorization</code> for bearer access token or <code>Accept-Version</code> to indicate the desired API version to use (default to version 1)</p> <pre>1\n2\n3\n4</pre><pre><code>curl -H \"Authorization: Bearer QH..E5M=\"\n     -H \"Accept-Version:1\"\n     -X POST https://tower.nf/api/domain/{item_id}?queryString={value}\n     -d { params: { \"key\":\"value\" } }\n</code></pre>","title":"Parameters"},{"location":"api/overview/#client-errors","text":"<p>There exists two typical standard errors, or non <code>200</code> or <code>204</code> status responses, to expect from the API.</p>","title":"Client errors"},{"location":"api/overview/#bad-request","text":"<p>The request payload is not properly defined or the query parameters are invalid.</p> <pre>1\n2\n3</pre><pre><code>{\n    \"message\": \"Oops... Unable to process request - Error ID: 54apnFENQxbvCr23JaIjLb\"\n}\n</code></pre>","title":"Bad Request"},{"location":"api/overview/#forbidden","text":"<p>Your access token is invalid or expired. This response may also imply that the entry point you are trying to access is not available; in such a case, it is recommended you check your request syntax.</p> <pre>1</pre><pre><code>Status: 403 Forbidden\n</code></pre>","title":"Forbidden"},{"location":"api/overview/#rate-limiting","text":"<p>For all API requests, there is a limit of 20 calls per second (72000 calls per hour) and access key.</p>","title":"Rate limiting"},{"location":"compute-envs/altair-grid-engine/","text":"","title":"Altair Grid Engine"},{"location":"compute-envs/altair-grid-engine/#overview","text":"<p>Altair Grid Engine is a workload manager maintained by Altair Engineering, Inc.</p> <p>Tower streamlines the deployment of Nextflow pipelines into both cloud-based and on-prem Grid Engine clusters.</p>","title":"Overview"},{"location":"compute-envs/altair-grid-engine/#requirements","text":"<p>To launch pipelines into a Grid Engine cluster from Tower, the following requirements must be satisfied:</p> <ul> <li>The cluster should allow outbound connections to the Tower web service.</li> <li>The cluster queue used to run the Nextflow head job must be able to submit cluster jobs.</li> <li>The Nextflow runtime version 21.02.0-edge (or later) should be installed on the cluster.</li> </ul>","title":"Requirements"},{"location":"compute-envs/altair-grid-engine/#compute-environment","text":"<p>To create a new compute environment for Grid Engine in Tower:</p> <ol> <li> <p>In a workspace, select Compute Environments and then New Environment.</p> </li> <li> <p>Enter a descriptive name for this environment, e.g. \"Grid Engine\".</p> </li> <li> <p>Select Altair Grid Engine as the target platform.</p> </li> <li> <p>Select your credentials, or select + and SSH or Tower Agent to add new credentials.</p> </li> <li> <p>Enter a name for the credentials.</p> </li> <li> <p>Enter the absolute path of the Work directory to be used on the cluster.</p> </li> <li> <p>Enter the absolute path of the Launch directory to be used on the cluster. If omitted, it will be the same as the work directory.</p> </li> <li> <p>Enter the Login hostname, which is usually the hostname or public IP address of the cluster's login node.</p> </li> <li> <p>Enter the Head queue name, the cluster queue to which the Nextflow job will be submitted.</p> </li> <li> <p>Enter the Compute queue name, the cluster queue to which the Nextflow job will submit tasks.</p>  <p>Tip</p> <p>The compute queue can be overridden by the Nextflow pipeline configuration. See the Nextflow docs for more details.</p>  </li> <li> <p>You can use the Environment variables option to specify custom environment variables for the Head job and/or Compute jobs.</p> </li> <li> <p>Configure any advanced options described below, as needed.</p> </li> <li> <p>Select Create to finalize the creation of the compute environment.</p> </li> </ol> <p>Jump to the documentation for Launching Pipelines.</p>","title":"Compute Environment"},{"location":"compute-envs/altair-grid-engine/#advanced-options","text":"<ul> <li> <p>You can use the Nextflow queue size to limit the number of jobs that Nextflow can submit to the scheduler at the same time.</p> </li> <li> <p>You can use the Head job submit options to specify Grid Engine options for the head job. You can optionally apply these options to compute jobs as well:</p> </li> </ul> <p></p>","title":"Advanced options"},{"location":"compute-envs/altair-pbs-pro/","text":"","title":"Altair PBS Pro"},{"location":"compute-envs/altair-pbs-pro/#overview","text":"<p>Altair PBS Pro is a workload manager and job scheduler tool provided by Altair Engineering, Inc.</p> <p>Tower streamlines the deployment of Nextflow pipelines into both cloud-based and on-prem PBS Pro clusters.</p>","title":"Overview"},{"location":"compute-envs/altair-pbs-pro/#requirements","text":"<p>To launch pipelines into a PBS Pro cluster from Tower, the following requirements must be satisfied:</p> <ul> <li>The cluster should allow outbound connections to the Tower web service.</li> <li>The cluster queue used to run the Nextflow head job must be able to submit cluster jobs.</li> <li>The Nextflow runtime version 21.02.0-edge (or later) should be installed on the cluster.</li> </ul>","title":"Requirements"},{"location":"compute-envs/altair-pbs-pro/#compute-environment","text":"<p>To create a new compute environment for PBS Pro in Tower:</p> <ol> <li> <p>In a workspace, select Compute Environments and then New Environment.</p> </li> <li> <p>Enter a descriptive name for this environment, e.g. \"PBS Pro cluster\".</p> </li> <li> <p>Select Altair PBS Pro as the target platform.</p> </li> <li> <p>Select your credentials, or select + and SSH or Tower Agent to add new credentials.</p> </li> <li> <p>Enter a name for the credentials.</p> </li> <li> <p>Enter the absolute path of the Work directory to be used on the cluster.</p> </li> <li> <p>Enter the absolute path of the Launch directory to be used on the cluster. If omitted, it will be the same as the work directory.</p> </li> <li> <p>Enter the Login hostname, which is usually the hostname or public IP address of the cluster's login node.</p> </li> <li> <p>Enter the Head queue name, the cluster queue to which the Nextflow job will be submitted.</p> </li> <li> <p>Enter the Compute queue name, the cluster queue to which the Nextflow job will submit tasks.</p>  <p>Tip</p> <p>The compute queue can be overridden by the Nextflow pipeline configuration. See the Nextflow docs for more details.</p>  </li> <li> <p>You can use the Environment variables option to specify custom environment variables for the Head job and/or Compute jobs.</p> </li> <li> <p>Configure any advanced options described below, as needed.</p> </li> <li> <p>Select Create to finalize the creation of the compute environment.</p> </li> </ol> <p>Jump to the documentation for Launching Pipelines.</p>","title":"Compute Environment"},{"location":"compute-envs/altair-pbs-pro/#advanced-options","text":"<ul> <li> <p>You can use the Nextflow queue size to limit the number of jobs that Nextflow can submit to the scheduler at the same time.</p> </li> <li> <p>You can use the Head job submit options to specify PBS options for the head job. You can optionally apply these options to compute jobs as well:</p> </li> </ul> <p></p>","title":"Advanced options"},{"location":"compute-envs/aws-batch/","text":"","title":"AWS Batch"},{"location":"compute-envs/aws-batch/#overview","text":"<p>Requirements</p> <p>This guide assumes you have an existing Amazon Web Service (AWS) account.</p>  <p>There are two ways to create a Compute Environment for AWS Batch with Tower:</p> <ol> <li> <p>Tower Forge: This option automatically manages the AWS Batch resources in your AWS account.</p> </li> <li> <p>Manual: This option allows you to create a compute environment using existing AWS Batch resources.</p> </li> </ol> <p>If you don't have an AWS Batch environment fully set-up yet, it is suggested to follow the Tower Forge guide.</p> <p>If you have been provided an AWS Batch queue from your account administrator, or if you have set up AWS Batch previously, please follow the Manual guide.</p>","title":"Overview"},{"location":"compute-envs/aws-batch/#tower-forge","text":"<p>Warning</p> <p>Follow these instructions only if you have not pre-configured an AWS Batch environment. Note that this option will automatically create resources in your AWS account that you may be charged for by AWS.</p>  <p>Tower Forge automates the configuration of an AWS Batch compute environment and the queues required for deploying Nextflow pipelines.</p>","title":"Tower Forge"},{"location":"compute-envs/aws-batch/#iam","text":"<p>To use the Tower Forge feature, Tower requires an Identity and Access Management (IAM) user with the permissions listed in this policy file. These authorizations are more permissive than those required to only launch a pipeline, since Tower needs to manage AWS resources on your behalf. Note that launch permissions also require the S3 storage write permissions in this policy file.</p> <p>We recommend creating separate IAM policies for Tower Forge and Tower launch permissions using the policy files linked above. These policies can then be assigned to the Tower IAM user.</p>","title":"IAM"},{"location":"compute-envs/aws-batch/#create-tower-iam-policies","text":"<ol> <li> <p>Open the AWS IAM console.</p> </li> <li> <p>From the left navigation menu, select Policies under Access management.</p> </li> <li> <p>Select Create policy.</p> </li> <li> <p>On the Create policy page, select the JSON tab.</p> </li> <li> <p>Copy the contents of your policy JSON file (Forge or Launch, depending on the policy being created) and replace the default text in the policy editor area under the JSON tab. To create a Launch user, you must also create the S3 bucket write policy separately to attach to your Launch user.</p> </li> <li> <p>Select Next: Tags.</p> </li> <li> <p>Select Next: Review.</p> </li> <li> <p>Enter a name and description for the policy on the Review policy page, then select Create policy.</p> </li> <li> <p>Repeat these steps for both the <code>forge-policy.json</code> and <code>launch-policy.json</code> files. For a Launch user, also create the <code>s3-bucket-write-policy.json</code> listed in step 5 above.</p> </li> </ol>","title":"Create Tower IAM policies"},{"location":"compute-envs/aws-batch/#create-an-iam-user","text":"<ol> <li> <p>From the AWS IAM console, select Users in the left navigation menu, then select Add User at the top rigt of the page.</p> </li> <li> <p>Enter a name for your user (e.g. <code>tower</code>) and select the Programmatic access type.</p> </li> <li> <p>Select Next: Permissions.</p> </li> <li> <p>Select Next: Tags, then Next: Review and Create User.</p>  <p>This user has no permissions</p> <p>For the time being, you can ignore the warning. Permissions will be applied using the IAM Policy.</p>  </li> <li> <p>Save the Access key ID and Secret access key in a secure location as we will use these in the next section.</p> </li> <li> <p>Once you have saved the keys, select Close.</p> </li> <li> <p>Back in the users table, select the newly created user,then select Add permissions under the Permissions tab.</p> </li> <li> <p>Select Attach existing policies, then search for the policies created in the previous section (Create Tower IAM policies) and check each one.</p> </li> <li> <p>Select Next: Review.</p> </li> <li> <p>Select Add permissions.</p> </li> </ol>","title":"Create an IAM user"},{"location":"compute-envs/aws-batch/#s3-bucket","text":"<p>S3 stands for \"Simple Storage Service\" and is a type of object storage. To access files and store the results for our pipelines, we have to create an S3 Bucket and grant our new Tower IAM user access to it.</p> <ol> <li> <p>Navigate to S3 service.</p> </li> <li> <p>Select Create New Bucket.</p> </li> <li> <p>Enter a unique name for your Bucket and select a region.</p>  <p>Which AWS region should I use?</p> <p>The region of the bucket should be in the same region as the compute environment that we create in the next section. Typically users select a region closest to their physical location but Tower Forge supports creating resources in any available AWS region.</p>  </li> <li> <p>Select the default options for Configure options.</p> </li> <li> <p>Select the default options for Set permissions.</p> </li> <li> <p>Review and select Create bucket.</p>  <p>S3 Storage Costs</p> <p>S3 is used by Nextflow for the storage of intermediate files. For production pipelines, this can amount to a large quantity of data. To reduce costs, when configuring a bucket, users should consider using a retention policy, such as automatically deleting intermediate files after 30 days. For more information on this process, see here.</p>  </li> </ol>","title":"S3 Bucket"},{"location":"compute-envs/aws-batch/#compute-environment","text":"<p>Tower Forge automates the configuration of an AWS Batch compute environment and queues required for the deployment of Nextflow pipelines.</p> <p>Once the AWS resources are set up, we can add a new AWS Batch environment in Tower. To create a new compute environment:</p> <ol> <li> <p>In a workspace, select Compute Environments and then New Environment.</p> </li> <li> <p>Enter a descriptive name for this environment, e.g. \"AWS Batch Spot (eu-west-1)\"</p> </li> <li> <p>Select Amazon Batch as the target platform.</p> </li> <li> <p>From the Credentials drop-down, select existing AWS credentials, or add new credentials by selecting the + button. If you select to use existing credentials, skip to step 7.</p> </li> <li> <p>Enter a name, e.g. \"AWS Credentials\".</p> </li> <li> <p>Add the Access key and Secret key. These are the keys you saved previously when you created the AWS IAM user.</p>  <p>Multiple credentials</p> <p>You can create multiple credentials in your Tower environment.</p>   <p>Container registry credentials</p> <p>From version 22.3, Tower supports the use of credentials for container registry services. These credentials can be created from the Credentials tab.</p>  </li> <li> <p>Select a Region, for example \"eu-west-1 - Europe (Ireland)\".</p> </li> <li> <p>Enter the S3 bucket path created in the previous section to the Pipeline work directory field, e.g. <code>s3://unique-tower-bucket</code>.</p>  <p>Warning</p> <p>The bucket should be in the same Region selected in the previous step.</p>  </li> <li> <p>Select Enable Wave containers to facilitate access to private container repositories and provision containers in your pipelines using the Wave containers service. See Wave containers for more information.</p> </li> <li> <p>Select Enable Fusion v2 to allow access to your S3-hosted data via the Fusion v2 virtual distributed file system. This speeds up most data operations. The Fusion v2 file system requires Wave containers to be enabled (see above). See Fusion file system for configuration details.</p> </li> <li> <p>Select Enable fast instance storage to allow the use of NVMe instance storage to speed up I/O and disk access operations. NVMe instance storage requires Fusion v2 to be enabled (see above).</p>  <p>Note</p> <p>Fast instance storage requires an EC2 instance type that uses NVMe disks. Tower validates any instance types you specify (from Advanced options &gt; Instance types) during compute environment creation. If you do not specify an instance type, a standard EC2 instance with NVMe disks will be used (<code>'c5ad', 'c5d', 'c6id', 'i3', 'i4i', 'm5ad', 'm5d', 'm6id', 'r5ad', 'r5d', 'r6id'</code> EC2 instance families) for fast storage.</p>  </li> <li> <p>Set the Config mode to Batch Forge.</p> </li> <li> <p>Select a Provisioning model. In most cases this will be Spot.</p>  <p>Spot or On-demand?</p> <p>You can choose to create a compute environment that launches either Spot or On-demand instances. Spot instances can cost as little as 20% of on-demand instances, and with Nextflow's ability to automatically relaunch failed tasks, Spot is almost always the recommended provisioning model.</p> <p>Note, however, that when choosing Spot instances, Tower will also create a dedicated queue for running the main Nextflow job using a single on-demand instance in order to prevent any execution interruptions.</p>  </li> <li> <p>Enter the Max CPUs e.g. <code>64</code>. This is the maximum number of combined CPUs (the sum of all instances CPUs) AWS Batch will provision at any time.</p> </li> <li> <p>Select EBS Auto scale to allow the EC2 virtual machines to dynamically expand the amount of available disk space during task execution.</p>  <p>EBS autoscaling may cause unattached volumes on large clusters</p> <p>When running large AWS Batch clusters (hundreds of compute nodes or more), EC2 API rate limits may cause the deletion of unattached EBS volumes to fail. Volumes that remain active after Nextflow jobs have completed will incur additional costs, and should be manually deleted. Monitor your AWS account for any orphaned EBS volumes via the EC2 console, or with a Lambda function. See here for more information.</p>  </li> <li> <p>With the optional Enable Fusion mounts feature enabled, S3 buckets specified in Pipeline work directory and Allowed S3 Buckets will be mounted as file system volumes in the EC2 instances carrying out the Batch job execution. These buckets will be accessible at <code>/fusion/s3/&lt;bucket-name&gt;</code>. For example, if the bucket name is <code>s3://imputation-gp2</code>, the Nextflow pipeline will access it using the file system path <code>/fusion/s3/imputation-gp2</code>.</p>  <p>Tip</p> <p>You do not need to modify your pipeline or files to take advantage of this feature. Nextflow is able to recognise these buckets automatically and will replace any reference to files prefixed with <code>s3://</code> with the corresponding Fusion mount paths.</p>  </li> <li> <p>Select Enable GPUs if you intend to run GPU-dependent workflows in the compute environment. See GPU usage for more information.</p> </li> <li> <p>Enter any additional Allowed S3 buckets that your workflows require to read input data or write output data. The Pipeline work directory bucket above is added by default to the list of Allowed S3 buckets.</p> </li> <li> <p>To use EFS, you can either select Use existing EFS file system and specify an existing EFS instance, or select Create new EFS file system to create one. If you intend to use the EFS file system as your work directory, you will need to specify <code>&lt;your_EFS_mount_path&gt;/work</code> in the Pipeline work directory field (step 8 of this guide).</p> <ul> <li>To use an existing EFS file system, enter the EFS file system id and EFS mount path. This is the path where the EFS volume is accessible to the compute environment. For simplicity, we advise that you use <code>/mnt/efs</code> as the EFS mount path.</li> <li>To create a new EFS file system, enter the EFS mount path. We advise that you specify <code>/mnt/efs</code> as the EFS mount path.</li> </ul> </li> <li> <p>To use FSx for Lustre, you can either select Use existing FSx file system and specify an existing FSx instance, or select Create new FSx file system to create one. If you intend to use the FSx file system as your work directory, you will need to specify <code>&lt;your_FSx_mount_path&gt;/work</code> in the Pipeline work directory field (step 8 of this guide).</p> <ul> <li>To use an existing FSx file system, enter the FSx DNS name and FSx mount path. The FSx mount path is the path where the FSx volume is accessible to the compute environment. For simplicity, we advise that you use <code>/mnt/fsx</code> as the FSx mount path.</li> <li>To create a new FSx file system, enter the FSx size (in GB) and the FSx mount path. We advise that you specify <code>/mnt/fsx</code> as the FSx mount path.</li> </ul> </li> <li> <p>Select Dispose resources if you want Tower to automatically delete these AWS resources if you delete the compute environment in Tower.</p> </li> <li> <p>You can use the Environment variables option to specify custom environment variables for the Head job and/or Compute jobs.</p> </li> <li> <p>Configure any advanced options described below, as needed.</p> </li> <li> <p>Select Create to finalize the compute environment setup. It will take a few seconds for all the resources to be created, and then you will be ready to launch pipelines.</p> </li> </ol> <p>Jump to the documentation for launching pipelines.</p>","title":"Compute Environment"},{"location":"compute-envs/aws-batch/#advanced-options","text":"<ul> <li> <p>You can specify the Allocation strategy and indicate the preferred Instance types to AWS Batch.</p> </li> <li> <p>You can configure your custom networking setup using the VPC ID, Subnets and Security groups fields.</p> </li> <li> <p>You can specify a custom AMI ID.</p>  <p>Requirements for custom AMI</p> <p>To use a custom AMI, make sure the AMI is based on an Amazon Linux-2 ECS optimized image that meets the Batch requirements. To learn more about approved versions of the Amazon ECS optimized AMI, see this AWS guide</p>   <p>GPU-enabled AMI</p> <p>If a custom AMI is specified and the Enable GPU option is also selected, the custom AMI will be used instead of the AWS-recommended GPU-optimized AMI.</p>  </li> <li> <p>If you need to debug the EC2 instance provisioned by AWS Batch, specify a Key pair to log in to the instance via SSH.</p> </li> <li> <p>You can set Min CPUs to be greater than <code>0</code>, in which case some EC2 instances will remain active. An advantage of this is that pipeline executions will initialize faster.</p>  <p>Increasing Min CPUs may increase AWS costs</p> <p>Keeping EC2 instances running may result in additional costs. You will be billed for these running EC2 instances regardless of whether you are executing pipelines or not.</p>  </li> <li> <p>You can use Head Job CPUs and Head Job Memory to specify the hardware resources allocated for the Head Job.</p> </li> <li> <p>You can use Head Job role and Compute Job role to grant fine-grained IAM permissions to the Head Job and Compute Jobs</p> </li> <li> <p>You can add an execution role ARN to the Batch execution role field to grant permissions to make API calls on your behalf to the ECS container used by Batch. This is required if the pipeline launched with this compute environment needs access to the secrets stored in this workspace. This field can be ignored if you are not using secrets.</p> </li> <li> <p>Specify an EBS block size (in GB) in the EBS auto-expandable block size field to control the initial size of the EBS auto-expandable volume. New blocks of this size are added when the volume begins to run out of free space.</p> </li> <li> <p>Enter the Boot disk size (in GB) to specify the size of the boot disk in the VMs created by this compute environment.</p> </li> <li> <p>If you're using Spot instances, then you can also specify the Cost percentage, which is the maximum allowed price of a Spot instance as a percentage of the On-Demand price for that instance type. Spot instances will not be launched until the current spot price is below the specified cost percentage.</p> </li> <li> <p>You can use AWS CLI tool path to specify the location of the <code>aws</code> CLI.</p> </li> <li> <p>Specify a CloudWatch Log group for the <code>awslogs</code> driver to stream the logs entry to an existing Log group in Cloudwatch.</p> </li> <li> <p>Specify a custom ECS agent configuration for the ECS agent parameters used by AWS Batch. This is appended to the /etc/ecs/ecs.config file in each cluster node.</p>  <p>Note</p> <p>Altering this file may result in a malfunctioning Tower Forge compute environment. See Amazon ECS container agent configuration to learn more about the available parameters.</p>  </li> </ul>","title":"Advanced options"},{"location":"compute-envs/aws-batch/#manual","text":"<p>This section is for users with a pre-configured AWS environment. You will need a Batch queue, a Batch compute environment, an IAM user and an S3 bucket already set up.</p> <p>To enable Tower within your existing AWS configuration, you need to have an IAM user with the following IAM permissions:</p> <ul> <li><code>AmazonS3ReadOnlyAccess</code></li> <li><code>AmazonEC2ContainerRegistryReadOnly</code></li> <li><code>CloudWatchLogsReadOnlyAccess</code></li> <li>A custom policy to grant the ability to submit and control Batch jobs.</li> <li>Write access to any S3 bucket used by pipelines with the following policy template. See below for details</li> </ul> <p>With these permissions set, we can add a new AWS Batch compute environment in Tower.</p>","title":"Manual"},{"location":"compute-envs/aws-batch/#access-to-s3-buckets","text":"<p>Tower can use S3 to store intermediate and output data generated by pipelines. You need to create a policy for your Tower IAM user that grants access to specific buckets.</p> <ol> <li> <p>Go to the IAM User table in the IAM service</p> </li> <li> <p>Select the IAM user.</p> </li> <li> <p>Select Add inline policy.</p> </li> <li> <p>Copy the contents of this policy into the JSON tab. Replace <code>YOUR-BUCKET-NAME</code> (lines 10 and 21) with your bucket name.</p> </li> <li> <p>Name your policy and select Create policy.</p> </li> </ol>","title":"Access to S3 Buckets"},{"location":"compute-envs/aws-batch/#compute-environment_1","text":"<p>To create a new compute environment for AWS Batch (without Forge):</p> <ol> <li> <p>In a workspace, select Compute Environments and then New Environment.</p> </li> <li> <p>Enter a descriptive name for this environment, e.g. \"AWS Batch Manual (eu-west-1)\".</p> </li> <li> <p>Select Amazon Batch as the target platform.</p> </li> <li> <p>Add new credentials by selecting the + button.</p> </li> <li> <p>Enter a name for the credentials, e.g. \"AWS Credentials\".</p> </li> <li> <p>Enter the Access key and Secret key for your IAM user.</p>  <p>Multiple credentials</p> <p>You can create multiple credentials in your Tower environment. See the Credentials section.</p>  </li> <li> <p>Select a Region, e.g. \"eu-west-1 - Europe (Ireland)\"</p> </li> <li> <p>Enter an S3 bucket path for the Pipeline work directory, for example <code>s3://tower-bucket</code></p> </li> <li> <p>Set the Config mode to Manual.</p> </li> <li> <p>Enter the Head queue, which is the name of the AWS Batch queue that the Nextflow driver job will run.</p> </li> <li> <p>Enter the Compute queue, which is the name of the AWS Batch queue that tasks will be submitted to.</p> </li> <li> <p>You can use the Environment variables option to specify custom environment variables for the Head job and/or Compute jobs.</p> </li> <li> <p>Configure any advanced options described below, as needed.</p> </li> <li> <p>Select Create to finalize the compute environment setup.</p> </li> </ol> <p>Jump to the documentation for Launching Pipelines.</p>","title":"Compute Environment"},{"location":"compute-envs/aws-batch/#advanced-options_1","text":"<ul> <li> <p>You can use Head Job CPUs and Head Job Memory to specify the hardware resources allocated for the Head Job.</p> </li> <li> <p>You can use Head Job role and Compute Job role to grant fine-grained IAM permissions to the Head Job and Compute Jobs</p> </li> <li> <p>You can add an execution role ARN to the Batch execution role field to grant permissions to make API calls on your behalf to the ECS container used by Batch. This is required if the pipeline launched with this compute environment needs access to the secrets stored in this workspace. This field can be ignored if you are not using secrets.</p> </li> <li> <p>You can use AWS CLI tool path to specify the location of the <code>aws</code> CLI.</p> </li> <li> <p>Specify a CloudWatch Log group for the <code>awslogs</code> driver to stream the logs entry to an existing Log group in Cloudwatch.</p> </li> </ul>","title":"Advanced options"},{"location":"compute-envs/azure-batch/","text":"","title":"Azure Batch"},{"location":"compute-envs/azure-batch/#overview","text":"<p>Warning</p> <p>The Tower support for Azure Batch is currently in beta. Any feedback and suggestions are welcome.</p> <p>In order to manage capacity during the global health pandemic, Microsoft has reduced core quotas for new Batch accounts. Depending on your region and subscription type, a newly-created account may not be entitled to any VMs without first making a service request to Azure.</p> <p>Please see Azure's Batch service quotas and limits page for further details.</p>   <p>Requirements</p> <p>This guide assumes you have an existing Azure Account. Sign up for a free Azure account here.</p>  <p>There are two ways to create a Compute Environment for Azure Batch with Tower.</p> <ol> <li> <p>Tower Forge: This option automatically manages the Azure Batch resources in your Azure account.</p> </li> <li> <p>Manual: This option allows you to create a compute environment using existing Azure Batch resources.</p> </li> </ol> <p>If you don't yet have an Azure Batch environment fully set up, it is suggested that you follow the Tower Forge guide.</p> <p>If you have been provided an Azure Batch queue from your account administrator, or if you have set up Azure Batch previously, directly follow the Manual guide.</p>","title":"Overview"},{"location":"compute-envs/azure-batch/#tower-forge","text":"<p>Warning</p> <p>Follow these instructions only if you have not pre-configured an Azure Batch environment. Note that this option will create resources in your Azure account that you may be charged for by Azure.</p>","title":"Tower Forge"},{"location":"compute-envs/azure-batch/#resource-group","text":"<p>To create the necessary Azure Batch and Azure Storage accounts, we must first create a resource group in the region of your choice.</p> <p>When you open this link, you'll notice the Create new resource group dialogue.</p> <ol> <li> <p>Enter a name for the resource group (e.g. <code>towerrg</code>).</p> </li> <li> <p>Select the preferred region for this resource group.</p> </li> <li> <p>Select Review and Create to proceed to the review screen.</p> </li> <li> <p>Select Create to create the resources.</p> </li> </ol>","title":"Resource group"},{"location":"compute-envs/azure-batch/#storage-account","text":"<p>The next step is to create the necessary Azure Storage.</p> <p>When you open this link, you'll notice the Create a storage account dialogue.</p> <ol> <li> <p>Enter a name for the storage account (e.g. <code>towerrgstorage</code>).</p> </li> <li> <p>Select the preferred region for this resource group.</p> </li> <li> <p>Select Review and Create to proceed to the review screen.</p> </li> <li> <p>Select Create to create the Azure Storage account.</p> </li> <li> <p>Navigate to your new storage account and select Container.</p> </li> <li> <p>Create a new Blob container by selecting + Container.</p> <p>A new container dialogue will open. Enter a suitable name (e.g. <code>towerrgstorage-container</code>).</p> </li> <li> <p>Once the new Blob container is created, navigate to the Access Keys section of the storage account (<code>towerrgstorage</code> in this example).</p> </li> <li> <p>Store the access keys for the newly created Azure Storage account.</p>  <p>Note</p> <p>Blob container storage credentials are associated with the Batch pool configuration when it is created. Once your compute environment has been created with Tower Forge, these credentials should not be changed in Tower.</p>  </li> </ol>","title":"Storage account"},{"location":"compute-envs/azure-batch/#batch-account","text":"<p>The next step is to create the necessary Batch account.</p> <p>When you open this link, you'll notice the Create a batch account dialogue.</p> <ol> <li> <p>Enter a name for the storage account (e.g. <code>towerrgbatch</code>).</p> </li> <li> <p>Select the preferred region for this resource group.</p> </li> <li> <p>Select Review and Create to proceed to the review screen.</p> </li> <li> <p>Select Create to create the Azure Batch account.</p> </li> </ol>","title":"Batch account"},{"location":"compute-envs/azure-batch/#compute-environment","text":"<p>Tower Forge automates the configuration of an Azure Batch compute environment and queues required for the deployment of Nextflow pipelines.</p> <p>Once the Azure resources are set up, we can add a new Azure Batch environment in Tower. To create a new compute environment:</p> <ol> <li> <p>In a workspace, select Compute Environments and then New Environment.</p> </li> <li> <p>Enter a descriptive name for this environment, e.g. \"Azure Batch (east-us)\"</p> </li> <li> <p>Select Azure Batch as the target platform.</p> <p></p> </li> <li> <p>From the Credentials drop-down, select existing Azure credentials, or add new credentials by selecting the + button. If you select to use existing credentials, skip to step 7.</p> </li> <li> <p>Enter a name, e.g. \"Azure Credentials\".</p> </li> <li> <p>Add the Batch account and Blob Storage credentials that we created previously.</p> <p></p>  <p>Multiple credentials</p> <p>You can create multiple credentials in your Tower environment.</p>   <p>Container registry credentials</p> <p>From version 22.3, Tower supports the use of credentials for container registry services. These credentials can be created from the Credentials tab.</p>  </li> <li> <p>Select a Region, for example \"eastus (East US)\".</p> </li> <li> <p>Enter the Pipeline work directory as the Azure blob container we created in the previous section, e.g. <code>az://towerrgstorage-container/work</code>.</p>  <p>Warning</p> <p>The blob container should be in the same Region from the previous step.</p>  </li> <li> <p>Set the Config mode to Batch Forge.</p> <p></p> </li> <li> <p>Enter the default VM type depending on your quota limits. The default is <code>Standard_D4_v3</code>.</p> </li> <li> <p>Enter the VMs count, which is the number of VMs you'd like to deploy.</p> </li> <li> <p>Enable Autoscale if you'd like to automatically scale up and down based on the number of tasks. The number of VMs will vary from 0 to VMs count.</p> </li> <li> <p>Enable Dispose resources if you'd like Tower to automatically delete the Batch pool once the workflow is complete.</p> </li> <li> <p>Configure any advanced options described below, as needed.</p> </li> <li> <p>Select Create to finalize the compute environment setup. It will take a few seconds for all the resources to be created, and then you will be ready to launch pipelines.</p> <p></p> </li> </ol> <p>Jump to the documentation for Launching Pipelines.</p>","title":"Compute Environment"},{"location":"compute-envs/azure-batch/#advanced-options","text":"<ul> <li> <p>You can use the Jobs cleanup policy to control how jobs should be deleted on workflow completion.</p> </li> <li> <p>You can use the Token duration to control the duration of the SAS token generated by Nextflow.</p> </li> </ul>","title":"Advanced options"},{"location":"compute-envs/azure-batch/#manual","text":"<p>This section is for users with a pre-configured Azure environment. You will need an Azure Batch account and Storage account already set up.</p> <p>To create a new compute environment for AWS Batch (without Forge):</p> <ol> <li> <p>In a workspace, select Compute Environments and then New Environment.</p> </li> <li> <p>Enter a descriptive name for this environment, e.g. \"Azure Batch (east-us)\"</p> </li> <li> <p>Select Azure Batch as the target platform.</p> <p></p> </li> <li> <p>Select your Azure credentials or add new credentials by selecting the + button.</p> </li> <li> <p>Enter a name, e.g. \"Azure Credentials\".</p> </li> <li> <p>Add the Batch account and Blob Storage credentials that we created previously.</p> <p></p>  <p>Multiple credentials</p> <p>You can create multiple credentials in your Tower environment.</p>  </li> <li> <p>Select a Region, for example \"eastus (East US)\".</p> </li> <li> <p>Enter the Pipeline work directory as the Azure blob container we created in the previous section, e.g. <code>az://towerrgstorage-container/work</code>.</p>  <p>Warning</p> <p>The blob container should be in the same Region you specified in step 7 above.</p>  </li> <li> <p>Set the Config mode to Manual.</p> </li> <li> <p>Enter the Compute Pool name, the name of the Azure Batch pool provided to you by your Azure administrator.</p> <p></p> </li> <li> <p>You can use the Environment variables option to specify custom environment variables for the Head job and/or Compute jobs.</p> </li> <li> <p>Configure any advanced options described below, as needed.</p> </li> <li> <p>Select Create to finalize the compute environment setup. It will take a few seconds for all the resources to be created, and then you will be ready to launch pipelines.</p> <p></p> </li> </ol> <p>Jump to the documentation for Launching Pipelines.</p>","title":"Manual"},{"location":"compute-envs/azure-batch/#advanced-options_1","text":"<ul> <li> <p>You can use the Jobs cleanup policy to control how jobs should be deleted on workflow completion.</p> </li> <li> <p>You can use the Token duration to control the duration of the SAS token generated by Nextflow.</p> </li> </ul>","title":"Advanced options"},{"location":"compute-envs/eks/","text":"","title":"Amazon EKS"},{"location":"compute-envs/eks/#overview","text":"<p>Amazon EKS is a managed Kubernetes cluster that allows the execution of containerized workloads in the AWS cloud at scale.</p> <p>Tower offers native support for AWS EKS clusters and streamlines the deployment of Nextflow pipelines in such environments.</p>","title":"Overview"},{"location":"compute-envs/eks/#requirements","text":"<p>You need to have an EKS cluster up and running. Make sure you have followed the cluster preparation instructions to create the cluster resources required by Tower. In addition to the generic Kubernetes instructions, you will need to make a few modifications specific to EKS.</p> <p>Assign service account role to IAM user. You will need to assign the service role with an AWS user that will be used by Tower to access the EKS cluster.</p> <p>First, use the following command to modify the EKS auth configuration:</p> <pre>1</pre><pre><code>kubectl edit configmap -n kube-system aws-auth\n</code></pre> <p>Once the editor is open, add the following entry:</p> <pre>1\n2\n3\n4\n5</pre><pre><code>mapUsers: |\n  - userarn: &lt;AWS USER ARN&gt;\n    username: tower-launcher-user\n    groups:\n      - tower-launcher-role\n</code></pre> <p>Your user ARN can be retrieved from the AWS IAM console or from the AWS CLI:</p> <pre>1</pre><pre><code>aws sts get-caller-identity\n</code></pre>  <p>Note</p> <p>The same user needs to be used when specifying the AWS credentials in the configuration of the Tower compute environment for EKS.</p>  <p>The AWS user should have the following IAM policy:</p>  Click to view eks-iam-policy.json <pre> 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14</pre><pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n      {\n        \"Sid\": \"TowerEks0\",\n        \"Effect\": \"Allow\",\n        \"Action\": [\n          \"eks:ListClusters\",\n          \"eks:DescribeCluster\"\n        ],\n        \"Resource\": \"*\"\n      }\n    ]\n  }\n</code></pre>  <p>For more details, refer to the AWS documentation.</p>","title":"Requirements"},{"location":"compute-envs/eks/#compute-environment","text":"<ol> <li> <p>In a workspace, select Compute Environments and then New Environment.</p> </li> <li> <p>Enter a descriptive name for this environment, e.g. \"Amazon EKS (eu-west-1)\".</p> </li> <li> <p>Select Amazon EKS as the target platform.</p> </li> <li> <p>From the Credentials drop-down, select existing AWS credentials, or add new credentials by selecting the + button. If you select to use existing credentials, skip to step 7.</p>  <p>Note</p> <p>Make sure the user has the IAM permissions required to describe and list EKS clusters as explained here.</p>   <p>Container registry credentials</p> <p>From version 22.3, Tower supports the use of credentials for container registry services. These credentials can be created from the Credentials tab.</p>  </li> <li> <p>Select a Region, for example \"eu-west-1 - Europe (Ireland)\".</p> </li> <li> <p>Select a Cluster name from the list of available EKS clusters in the selected region.</p> </li> <li> <p>Specify the Namespace created in the cluster preparation instructions, which is <code>tower-nf</code> by default.</p> </li> <li> <p>Specify the Head service account created in the cluster preparation instructions, which is <code>tower-launcher-sa</code> by default.</p> </li> <li> <p>Specify the Storage claim created in the cluster preparation instructions, which serves as a scratch filesystem for Nextflow pipelines. In each of the provided examples, the storage claim is called <code>tower-scratch</code>.</p> </li> <li> <p>You can use the Environment variables option to specify custom environment variables for the Head job and/or Compute jobs.</p> </li> <li> <p>Configure any advanced options described below, as needed.</p> </li> <li> <p>Select Create to finalize the compute environment setup.</p> </li> </ol> <p>Jump to the documentation for Launching Pipelines.</p>","title":"Compute Environment"},{"location":"compute-envs/eks/#advanced-options","text":"<ul> <li> <p>The Storage mount path is the file system path where the Storage claim is mounted (default: <code>/scratch</code>).</p> </li> <li> <p>The Work directory is the file system path used as a working directory by Nextflow pipelines. It must be the the storage mount path (default) or a subdirectory of it.</p> </li> <li> <p>The Compute service account is the service account used by Nextflow to submit tasks (default: the <code>default</code> account in the given namespace).</p> </li> <li> <p>The Pod cleanup policy determines when terminated pods should be deleted.</p> </li> <li> <p>You can use Custom head pod specs to provide custom options for the Nextflow workflow pod (<code>nodeSelector</code>, <code>affinity</code>, etc). For example:</p> </li> </ul> <pre>1\n2\n3</pre><pre><code>spec:\n  nodeSelector:\n    disktype: ssd\n</code></pre> <ul> <li> <p>You can use Custom service pod specs to provide custom options for the compute environment pod. See above for an example.</p> </li> <li> <p>You can use Head Job CPUs and Head Job Memory to specify the hardware resources allocated for the Nextflow workflow pod.</p> </li> </ul>","title":"Advanced options"},{"location":"compute-envs/gke/","text":"","title":"Google GKE"},{"location":"compute-envs/gke/#overview","text":"<p>Google GKE is a managed Kubernetes cluster that allows the execution of containerized workloads in Google Cloud at scale.</p> <p>Tower offers native support for Google GKE clusters and streamlines the deployment of Nextflow pipelines in such environments.</p>","title":"Overview"},{"location":"compute-envs/gke/#requirements","text":"<p>Refer to the Google Cloud section for instructions on how to set up your Google Cloud account and any other services (e.g. Cloud Storage) that you intend to use.</p> <p>You need to have a GKE cluster up and running. Make sure you have followed the cluster preparation instructions to create the cluster resources required by Tower. In addition to the generic Kubernetes instructions, you will need to make a few modifications specific to GKE.</p> <p>Assign service account role to IAM user. You will need to grant the cluster access to the service account used to authenticate the Tower compute environment. This can be done by updating the role binding as shown below:</p> <pre> 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16</pre><pre><code>cat &lt;&lt; EOF | kubectl apply -f -\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: tower-launcher-userbind\nsubjects:\n  - kind: User\n    name: &lt;IAM SERVICE ACCOUNT&gt;\n    apiGroup: rbac.authorization.k8s.io\nroleRef:\n  kind: Role\n  name: tower-launcher-role\n  apiGroup: rbac.authorization.k8s.io\n---\nEOF\n</code></pre> <p>In the above snippet, replace <code>&lt;IAM SERVICE ACCOUNT&gt;</code> with the corresponding service account, e.g. <code>test-account@test-project-123456.google.com.iam.gserviceaccount.com</code>.</p> <p>For more details, refer to the Google documentation.</p>","title":"Requirements"},{"location":"compute-envs/gke/#compute-environment","text":"<ol> <li> <p>In a workspace, select Compute Environments and then New Environment.</p> </li> <li> <p>Enter a descriptive name for this environment, e.g. \"Google GKE (europe-west1)\".</p> </li> <li> <p>From the Provider drop-down, select Google GKE.</p> </li> <li> <p>From the Credentials drop-down, select existing GKE credentials, or add new credentials by selecting the + button. If you select to use existing credentials, skip to step 7.</p> </li> <li> <p>Enter a name for the credentials, e.g. \"GKE Credentials\".</p> </li> <li> <p>Enter the Service account key for your Google Service account.</p>  <p>Multiple credentials</p> <p>You can create multiple credentials in your Tower environment.</p>   <p>Container registry credentials</p> <p>From version 22.3, Tower supports the use of credentials for container registry services. These credentials can be created from the Credentials tab.</p>  </li> <li> <p>Select the Location of your GKE cluster.</p>  <p>Regional and zonal clusters</p> <p>GKE clusters can be either regional or zonal. For example, <code>us-west1</code> identifies the United States West-Coast region, which has three zones: <code>us-west1-a</code>, <code>us-west1-b</code>, and <code>us-west1-c</code>. Tower self-completion only shows regions. You should manually edit this field if you are using a zonal GKE cluster. </p>  </li> <li> <p>Select or enter the Cluster name of your GKE cluster.</p> </li> <li> <p>Specify the Namespace created in the cluster preparation instructions, which is <code>tower-nf</code> by default.</p> </li> <li> <p>Specify the Head service account created in the cluster preparation instructions, which is <code>tower-launcher-sa</code> by default.</p> </li> <li> <p>Specify the Storage claim created in the cluster preparation instructions, which serves as a scratch filesystem for Nextflow pipelines. In each of the provided examples, the storage claim is called <code>tower-scratch</code>.</p> </li> <li> <p>You can use the Environment variables option to specify custom environment variables for the Head job and/or Compute jobs.</p> </li> <li> <p>Configure any advanced options described below, as needed.</p> </li> <li> <p>Select Create to finalize the compute environment setup.</p> </li> </ol> <p>Jump to the documentation for Launching Pipelines.</p>","title":"Compute Environment"},{"location":"compute-envs/gke/#advanced-options","text":"<ul> <li> <p>The Storage mount path is the file system path where the Storage claim is mounted (default: <code>/scratch</code>).</p> </li> <li> <p>The Work directory is the file system path used as a working directory by Nextflow pipelines. It must be the the storage mount path (default) or a subdirectory of it.</p> </li> <li> <p>The Compute service account is the service account used by Nextflow to submit tasks (default: the <code>default</code> account in the given namespace).</p> </li> <li> <p>The Pod cleanup policy determines when terminated pods should be deleted.</p> </li> <li> <p>You can use Custom head pod specs to provide custom options for the Nextflow workflow pod (<code>nodeSelector</code>, <code>affinity</code>, etc). For example:</p> </li> </ul> <pre>1\n2\n3</pre><pre><code>spec:\n  nodeSelector:\n    disktype: ssd\n</code></pre> <ul> <li> <p>You can use Custom service pod specs to provide custom options for the compute environment pod. See above for an example.</p> </li> <li> <p>You can use Head Job CPUs and Head Job Memory to specify the hardware resources allocated for the Nextflow workflow pod.</p> </li> </ul>","title":"Advanced options"},{"location":"compute-envs/google-cloud-batch/","text":"","title":"Google Cloud Batch"},{"location":"compute-envs/google-cloud-batch/#overview","text":"<p>Warning</p> <p>Tower's Google Cloud Batch support is in Beta \u2014 more features will be added as Nextflow GCB support is enhanced over time.</p>  <p>This guide assumes you have an existing Google Cloud Account. Sign-up for a free account here.</p> <p>Tower provides integration to Google Cloud via the Batch API.</p> <p>The guide is split into two parts:</p> <ol> <li> <p>How to configure your Google Cloud account to use the Batch API.</p> </li> <li> <p>How to create a Google Cloud Batch compute environment in Tower.</p> </li> </ol>","title":"Overview"},{"location":"compute-envs/google-cloud-batch/#configure-google-cloud","text":"","title":"Configure Google Cloud"},{"location":"compute-envs/google-cloud-batch/#create-a-project","text":"<p>Navigate to the Google Project Selector page and either select an existing project or select Create project.</p> <p>Enter a name for your new project, e.g \"tower-nf\".</p> <p>If you are part of an organization, the location will default to your organization.</p>","title":"Create a project"},{"location":"compute-envs/google-cloud-batch/#enable-billing","text":"<p>In the navigation menu (\u2261), select Billing. You can follow these instructions to enable billing.</p>","title":"Enable billing"},{"location":"compute-envs/google-cloud-batch/#enable-apis","text":"<p>Use this link to enable the following APIs for your project:</p> <ul> <li>Batch API</li> <li>Compute Engine API</li> <li>Cloud Storage API</li> </ul> <p>Select your project from the dropdown menu and select Enable.</p> <p>Alternatively, you can enable each API manually by selecting your project in the nav bar and visiting each API page:</p> <ul> <li> <p>Batch API</p> </li> <li> <p>Compute Engine API</p> </li> <li> <p>Cloud Storage API</p> </li> </ul>","title":"Enable APIs"},{"location":"compute-envs/google-cloud-batch/#create-a-service-account-key","text":"<ol> <li> <p>In the navigation menu, select IAM &amp; Admin and then Service Accounts.</p> </li> <li> <p>Select the email address of the Compute Engine default service account.</p> </li> <li> <p>Select Keys, then Add key, then Create new key.</p> </li> <li> <p>Select JSON as the key type.</p> </li> <li> <p>Select Create.</p> </li> </ol> <p>A JSON file will be downloaded to your computer. This file contains the credential that will be used by Tower. You will need it to configure the compute environment in Tower.</p> <p>You can manage your key from the Service Accounts page.</p>","title":"Create a service account key"},{"location":"compute-envs/google-cloud-batch/#create-a-cloud-storage-bucket","text":"<ol> <li> <p>In the navigation menu (\u2261), select Cloud Storage and then Create bucket.</p> </li> <li> <p>Enter a name for your bucket. You will reference this name when creating the compute environment in Tower.</p>  <p>Warning</p> <p>Do not use underscores (<code>_</code>) in your bucket name. Use hyphens (<code>-</code>) instead.</p>  </li> <li> <p>Select Region for the Location type and select the Location for your bucket. You will reference this location when creating the compute environment in Tower.</p> </li> <li> <p>Select Standard for the default storage class.</p> </li> <li> <p>Select Uniform for the Access control.</p>  <p>Note</p> <p>The Batch API is available in a limited number of locations. However, these locations are only used to store metadata about the pipeline operations. The storage bucket and compute resources can be in any region.</p>  </li> <li> <p>Select Create.</p> </li> <li> <p>Once the bucket is created, you will be redirected to the Bucket details page.</p> </li> <li> <p>Select Permissions, then + Add.</p> </li> <li> <p>Copy the email address of the Compute Engine default service account into New principals.</p> </li> <li> <p>Select the following roles:</p> </li> <li> <p>Storage Admin</p> </li> <li>Storage Legacy Bucket Owner</li> <li>Storage Legacy Object Owner</li> <li>Storage Object Creator</li> </ol>  <p>Google Cloud configured</p> <p>You have created a project, enabled the necessary Google APIs, created a bucket, and created a JSON file with the required credentials. You are now ready to set up a new compute environment in Tower.</p>","title":"Create a Cloud Storage bucket"},{"location":"compute-envs/google-cloud-batch/#configure-tower","text":"<p>Requirements</p> <p>The following guide to configure Tower assumes you have (1) a service account key for a Google Cloud account and (2) the name and location of a Cloud Storage bucket.</p>  <p>To create a new compute environment for Google Cloud in Tower:</p> <ol> <li> <p>In a workspace, select Compute Environments and then New Environment.</p> </li> <li> <p>Enter a descriptive name for this environment, e.g. \"Google Cloud Batch (europe-north1)\".</p> </li> <li> <p>Select Google Cloud Batch as the target platform.</p> </li> <li> <p>Add new credentials by selecting the + button.</p> </li> <li> <p>Enter a name for the credentials, e.g. \"Google Cloud Credentials\".</p> </li> <li> <p>Enter the Service account key for your Google Cloud account. This key was created in the previous section.</p> </li> <li> <p>Select the Location where you'd like to execute pipelines.</p> </li> <li> <p>Enter your bucket URL for the Pipeline work directory. The URL is the name of your bucket with the <code>gs://</code> prefix, e.g. <code>gs://my-bucket</code>. This bucket should be accessible in the region selected in the previous step.</p> </li> <li> <p>You can enable Spot to use spot instances, which have significantly reduced cost compared to on-demand instances.</p> </li> <li> <p>You can use the Environment variables option to specify custom environment variables for the Head job and/or Compute jobs.</p> </li> <li> <p>Configure any advanced options described below, as needed.</p> </li> <li> <p>Select Create to finalize the compute environment setup.</p> </li> </ol> <p>Jump to the documentation for Launching Pipelines.</p>","title":"Configure Tower"},{"location":"compute-envs/google-cloud-batch/#advanced-options","text":"<ul> <li> <p>You can enable Use Private Address to ensure that your Google Cloud VMs aren't accessible to the public internet.</p> </li> <li> <p>You can use Boot disk size to control the boot disk size of VMs.</p> </li> <li> <p>You can use Head Job CPUs and Head Job Memory to specify the CPUs and memory allocated for head jobs.</p> </li> </ul>","title":"Advanced options"},{"location":"compute-envs/google-cloud-lifesciences/","text":"","title":"Google Life Sciences"},{"location":"compute-envs/google-cloud-lifesciences/#overview","text":"<p>This guide assumes you have an existing Google Cloud Account. Sign-up for a free account here.</p> <p>Tower provides integration to Google Cloud via the Cloud Life Sciences API.</p> <p>The guide is split into two parts:</p> <ol> <li> <p>How to configure your Google Cloud account to use the Cloud Life Sciences API.</p> </li> <li> <p>How to create a Google Life Sciences compute environment in Tower.</p> </li> </ol>","title":"Overview"},{"location":"compute-envs/google-cloud-lifesciences/#configure-google-cloud","text":"","title":"Configure Google Cloud"},{"location":"compute-envs/google-cloud-lifesciences/#create-a-project","text":"<p>Navigate to the Google Project Selector page and either select an existing project or select Create project.</p> <p>Enter a name for your new project, e.g \"tower-nf\".</p> <p>If you are part of an organization, the location will default to your organization.</p>","title":"Create a project"},{"location":"compute-envs/google-cloud-lifesciences/#enable-billing","text":"<p>In the navigation menu (\u2261), select Billing. You can follow these instructions to enable billing.</p>","title":"Enable billing"},{"location":"compute-envs/google-cloud-lifesciences/#enable-apis","text":"<p>Use this link to enable the following APIs for your project:</p> <ul> <li>Cloud Life Sciences API</li> <li>Compute Engine API</li> <li>Cloud Storage API</li> </ul> <p>Select your project from the dropdown menu and select Enable.</p> <p>Alternatively, you can enable each API manually by selecting your project in the nav bar and visiting each API page:</p> <ul> <li> <p>Cloud Life Sciences API</p> </li> <li> <p>Compute Engine API</p> </li> <li> <p>Cloud Storage API</p> </li> </ul>","title":"Enable APIs"},{"location":"compute-envs/google-cloud-lifesciences/#create-a-service-account-key","text":"<ol> <li> <p>In the navigation menu, select IAM &amp; Admin and then Service Accounts.</p> </li> <li> <p>Select the email address of the Compute Engine default service account.</p> </li> <li> <p>Select Keys, then Add key, then Create new key.</p> </li> <li> <p>Select JSON as the key type.</p> </li> <li> <p>Select Create.</p> </li> </ol> <p>A JSON file will be downloaded to your computer. This file contains the credential that will be used by Tower. You will need it to configure the compute environment in Tower.</p> <p>You can manage your key from the Service Accounts page.</p>","title":"Create a service account key"},{"location":"compute-envs/google-cloud-lifesciences/#create-a-cloud-storage-bucket","text":"<ol> <li> <p>In the navigation menu (\u2261), select Cloud Storage and then Create bucket.</p> </li> <li> <p>Enter a name for your bucket. You will reference this name when creating the compute environment in Tower.</p>  <p>Warning</p> <p>Do not use underscores (<code>_</code>) in your bucket name. Use hyphens (<code>-</code>) instead.</p>  </li> <li> <p>Select Region for the Location type and select the Location for your bucket. You will reference this location when creating the compute environment in Tower.</p> </li> <li> <p>Select Standard for the default storage class.</p> </li> <li> <p>Select Uniform for the Access control.</p>  <p>Note</p> <p>The Cloud Life Sciences API is available in a limited number of locations. However, these locations are only used to store metadata about the pipeline operations. The storage bucket and compute resources can be in any region.</p>  </li> <li> <p>Select Create.</p> </li> <li> <p>Once the bucket is created, you will be redirected to the Bucket details page.</p> </li> <li> <p>Select Permissions, then + Add.</p> </li> <li> <p>Copy the email address of the Compute Engine default service account into New principals.</p> </li> <li> <p>Select the following roles:</p> </li> <li> <p>Storage Admin</p> </li> <li>Storage Legacy Bucket Owner</li> <li>Storage Legacy Object Owner</li> <li>Storage Object Creator</li> </ol>","title":"Create a Cloud Storage bucket"},{"location":"compute-envs/google-cloud-lifesciences/#compute-environment","text":"<p>Requirements</p> <p>The following guide to configure Tower assumes you have (1) a service account key for a Google Cloud account and (2) the name and location of a Cloud Storage bucket.</p>  <p>To create a new compute environment for Google Cloud in Tower:</p> <ol> <li> <p>In a workspace, select Compute Environments and then New Environment.</p> </li> <li> <p>Enter a descriptive name for this environment, e.g. \"Google Life Sciences (europe-west2)\".</p> </li> <li> <p>Select Google Life Sciences as the target platform.</p> </li> <li> <p>From the Credentials drop-down, select existing Google Cloud credentials, or add new credentials by selecting the + button. If you select to use existing credentials, skip to step 7.</p> </li> <li> <p>Enter a name for the credentials, e.g. \"Google Cloud Credentials\".</p> </li> <li> <p>Enter the Service account key for your Google Cloud account. This key was created in the previous section.</p>  <p>Multiple credentials</p> <p>You can create multiple credentials in your Tower workspace.</p>   <p>Container registry credentials</p> <p>From version 22.3, Tower supports the use of credentials for container registry services. These credentials can be created from the Credentials tab.</p>  </li> <li> <p>Select the Region and Zones where you'd like to execute pipelines. You can leave the Location empty and the Cloud Life Sciences API will use the closest available location.</p> </li> <li> <p>Enter your bucket URL for the Pipeline work directory. The URL is the name of your bucket with the <code>gs://</code> prefix, e.g. <code>gs://my-bucket</code>. This bucket should be accessible in the region selected in the previous step.</p> </li> <li> <p>You can enable Preemptible to use preemptible instances, which have significantly reduced cost compared to on-demand instances.</p> </li> <li> <p>You can use a Filestore file system to automatically mount a Google Filestore volume in your pipelines.</p> </li> <li> <p>You can use the Environment variables option to specify custom environment variables for the Head job and/or Compute jobs.</p> </li> <li> <p>Configure any advanced options described below, as needed.</p> </li> <li> <p>Select Create to finalize the compute environment setup.</p> </li> </ol> <p>Jump to the documentation for Launching Pipelines.</p>","title":"Compute Environment"},{"location":"compute-envs/google-cloud-lifesciences/#advanced-options","text":"<ul> <li> <p>You can enable Use Private Address to ensure that your Google Cloud VMs aren't accessible to the public internet.</p> </li> <li> <p>You can use Boot disk size to control the boot disk size of VMs.</p> </li> <li> <p>You can use Head Job CPUs and Head Job Memory to specify the CPUs and memory allocated for head jobs.</p> </li> </ul>","title":"Advanced options"},{"location":"compute-envs/k8s/","text":"","title":"Kubernetes"},{"location":"compute-envs/k8s/#overview","text":"<p>Kubernetes is the leading technology for deployment and orchestration of containerized workloads in cloud-native environments.</p> <p>Tower streamlines the deployment of Nextflow pipelines into Kubernetes both for cloud-based and on-prem clusters.</p> <p>The following instructions are for a generic Kubernetes distribution. If you are using Amazon EKS or Google GKE, see the corresponding documentation pages.</p>","title":"Overview"},{"location":"compute-envs/k8s/#cluster-preparation","text":"<p>This section describes the steps required to prepare your Kubernetes cluster for the deployment of Nextflow pipelines using Tower. It is assumed the cluster itself has already been created and you have administrative privileges.</p> <ol> <li>Verify the connection to your Kubernetes cluster:</li> </ol> <pre>1</pre><pre><code>kubectl cluster-info\n</code></pre> <ol> <li>Create the Tower launcher:</li> </ol> <pre>1</pre><pre><code>kubectl apply -f https://help.tower.nf/22.1/_templates/k8s/tower-launcher.yml\n</code></pre> <p>This command creates a service account called <code>tower-launcher-sa</code>, and associated role bindings. Everything is contained in a namespace called <code>tower-nf</code>. The service account is used by Tower to launch Nextflow pipelines. Use this service account name when setting up the compute environment for this Kubernetes cluster in Tower.</p> <ol> <li>Create persistent storage. Tower requires a <code>ReadWriteMany</code> persistent volume claim (PVC) that is mounted by all nodes where workflow pods will be dispatched.</li> </ol> <p>You can use any storage solution that supports the <code>ReadWriteMany</code> access mode. The setup of this storage is beyond the scope of these instructions, because the right solution for you will depend on what is available for your infrastructure or cloud vendor (NFS, GlusterFS, CephFS, Amazon FSx, etc). Ask your cluster administrator for more information.</p> <ul> <li> <p>Example PVC backed by local storage: tower-scratch-local.yml</p> </li> <li> <p>Example PVC backed by NFS server: tower-scratch-nfs.yml</p> </li> </ul>","title":"Cluster Preparation"},{"location":"compute-envs/k8s/#compute-environment","text":"<ol> <li> <p>In a workspace, select Compute Environments and then New Environment.</p> </li> <li> <p>Enter a descriptive name for this environment, e.g. \"K8s cluster\".</p> </li> <li> <p>Select Kubernetes as the target platform.</p> </li> <li> <p>Select your Kubernetes credentials or add new credentials by selecting the + button.</p> </li> <li> <p>Enter a name, e.g. \"K8s Credentials\".</p> </li> <li> <p>Enter the Service account token.</p> </li> </ol> <p>The token can be obtained with the following command:</p> <pre>1\n2</pre><pre><code>SECRET=$(kubectl get secrets | grep &lt;SERVICE-ACCOUNT-NAME&gt; | cut -f1 -d ' ')\nkubectl describe secret $SECRET | grep -E '^token' | cut -f2 -d':' | tr -d '\\t'\n</code></pre> <p>Replace <code>&lt;SERVICE-ACCOUNT-NAME&gt;</code> with the name of the service account created in the cluster preparation instructions, which is <code>tower-launcher-sa</code> by default.</p> <ol> <li>Enter the Master server URL.</li> </ol> <p>The master server URL can be obtained with the following command:</p> <pre>1</pre><pre><code>kubectl cluster-info\n</code></pre> <p>It can also be found in your <code>~/.kube/config</code> file under the <code>server</code> field corresponding to your cluster.</p> <ol> <li>Specify the SSL Certificate to authenticate your connection.</li> </ol> <p>The certificate data can be found in your <code>~/.kube/config</code> file. It is the <code>certificate-authority-data</code> field corresponding to your cluster.</p> <ol> <li> <p>Specify the Namespace created in the cluster preparation instructions, which is <code>tower-nf</code> by default.</p> </li> <li> <p>Specify the Head service account created in the cluster preparation instructions, which is <code>tower-launcher-sa</code> by default.</p> </li> <li> <p>Specify the Storage claim created in the cluster preparation instructions, which serves as a scratch filesystem for Nextflow pipelines. In each of the provided examples, the storage claim is called <code>tower-scratch</code>.</p> </li> <li> <p>You can use the Environment variables option to specify custom environment variables for the Head job and/or Compute jobs.</p> </li> <li> <p>Configure any advanced options described below, as needed.</p> </li> <li> <p>Select Create to finalize the compute environment setup.</p> </li> </ol> <p>Jump to the documentation for Launching Pipelines.</p>","title":"Compute Environment"},{"location":"compute-envs/k8s/#advanced-options","text":"<ul> <li> <p>The Storage mount path is the file system path where the Storage claim is mounted (default: <code>/scratch</code>).</p> </li> <li> <p>The Work directory is the file system path used as a working directory by Nextflow pipelines. It must be the the storage mount path (default) or a subdirectory of it.</p> </li> <li> <p>The Compute service account is the service account used by Nextflow to submit tasks (default: the <code>default</code> account in the given namespace).</p> </li> <li> <p>The Pod cleanup policy determines when terminated pods should be deleted.</p> </li> <li> <p>You can use Custom head pod specs to provide custom options for the Nextflow workflow pod (<code>nodeSelector</code>, <code>affinity</code>, etc). For example:</p> </li> </ul> <pre>1\n2\n3</pre><pre><code>spec:\n  nodeSelector:\n    disktype: ssd\n</code></pre> <ul> <li> <p>You can use Custom service pod specs to provide custom options for the compute environment pod. See above for an example.</p> </li> <li> <p>You can use Head Job CPUs and Head Job Memory to specify the hardware resources allocated for the Nextflow workflow pod.</p> </li> </ul>","title":"Advanced options"},{"location":"compute-envs/lsf/","text":"","title":"IBM LSF"},{"location":"compute-envs/lsf/#overview","text":"<p>IBM Spectrum LSF is an IBM workload management solution for HPC. LSF aims to enhance user and administrator experience, reliability and performance at scale.</p> <p>Tower streamlines the deployment of Nextflow pipelines into both cloud-based and on-prem LSF clusters.</p>","title":"Overview"},{"location":"compute-envs/lsf/#requirements","text":"<p>To launch pipelines into an LSF cluster from Tower, the following requirements must be satisfied:</p> <ul> <li>The cluster should allow outbound connections to the Tower web service.</li> <li>The cluster queue used to run the Nextflow head job must be able to submit cluster jobs.</li> <li>The Nextflow runtime version 21.02.0-edge (or later) should be installed on the cluster.</li> </ul>","title":"Requirements"},{"location":"compute-envs/lsf/#compute-environment","text":"<p>To create a new compute environment for LSF in Tower:</p> <ol> <li> <p>In a workspace, select Compute Environments and then New Environment.</p> </li> <li> <p>Enter a descriptive name for this environment, e.g. \"LSF\".</p> </li> <li> <p>Select IBM LSF as the target platform.</p> </li> <li> <p>Select your credentials, or select + and SSH or Tower Agent to add new credentials.</p> </li> <li> <p>Enter a name for the credentials.</p> </li> <li> <p>Enter the absolute path of the Work directory to be used on the cluster.</p> </li> <li> <p>Enter the absolute path of the Launch directory to be used on the cluster. If omitted, it will be the same as the work directory.</p> </li> <li> <p>Enter the Login hostname, which is usually the hostname or public IP address of the cluster's login node.</p> </li> <li> <p>Enter the Head queue name, the cluster queue to which the Nextflow job will be submitted.</p> </li> <li> <p>Enter the Compute queue name, the cluster queue to which the Nextflow job will submit tasks.</p>  <p>Tip</p> <p>The compute queue can be overridden by the Nextflow pipeline configuration. See the Nextflow docs for more details.</p>  </li> <li> <p>You can use the Environment variables option to specify custom environment variables for the Head job and/or Compute jobs.</p> </li> <li> <p>Configure any advanced options described below, as needed.</p> </li> <li> <p>Select Create to finalize the creation of the compute environment.</p> </li> </ol> <p>Jump to the documentation for Launching Pipelines.</p>","title":"Compute Environment"},{"location":"compute-envs/lsf/#advanced-options","text":"<ul> <li> <p>You can use the Nextflow queue size to limit the number of jobs that Nextflow can submit to the scheduler at the same time.</p> </li> <li> <p>You can use the Head job submit options to specify LSF options for the head job. You can optionally apply these options to compute jobs as well:</p> </li> </ul> <p></p> <ul> <li>You can use Unit for memory limits, Per job memory limits, and Per task reserve to control how memory is requested for Nextflow jobs.</li> </ul>","title":"Advanced options"},{"location":"compute-envs/moab/","text":"","title":"Moab"},{"location":"compute-envs/moab/#overview","text":"<p>Moab is a scheduling and management system designed for clusters, grids, and on-demand/utility computing systems. At a high level, Moab applies site policies and extensive optimizations to orchestrate jobs, services, and other workload across the ideal combination of network, compute, and storage resources.</p> <p>Tower streamlines the deployment of Nextflow pipelines into both cloud-based and on-prem Moab clusters.</p>","title":"Overview"},{"location":"compute-envs/moab/#requirements","text":"<p>To launch pipelines into a Moab cluster from Tower, the following requirements must be satisfied:</p> <ul> <li>The cluster should allow outbound connections to the Tower web service.</li> <li>The cluster queue used to run the Nextflow head job must be able to submit cluster jobs.</li> <li>The Nextflow runtime version 21.02.0-edge (or later) should be installed on the cluster.</li> </ul>","title":"Requirements"},{"location":"compute-envs/moab/#compute-environment","text":"<p>To create a new compute environment for Moab in Tower:</p> <ol> <li> <p>In a workspace, select Compute Environments and then New Environment.</p> </li> <li> <p>Enter a descriptive name for this environment, e.g. \"Moab cluster\".</p> </li> <li> <p>Select Moab Workload Manager as the target platform.</p> </li> <li> <p>Select your credentials, or select + and SSH or Tower Agent to add new credentials.</p> </li> <li> <p>Enter a name for the credentials.</p> </li> <li> <p>Enter the absolute path of the Work directory to be used on the cluster.</p> </li> <li> <p>Enter the absolute path of the Launch directory to be used on the cluster. If omitted, it will be the same as the work directory.</p> </li> <li> <p>If using SSH credentials, enter the Login hostname, which is usually the hostname or public IP address of the cluster's login node.</p> </li> <li> <p>Enter the Head queue name, the cluster queue to which the Nextflow job will be submitted.</p> </li> <li> <p>Enter the Compute queue name, the cluster queue to which the Nextflow job will submit tasks.</p>  <p>Tip</p> <p>The compute queue can be overridden by the Nextflow pipeline configuration. See the Nextflow docs for more details.</p>  </li> <li> <p>You can use the Environment variables option to specify custom environment variables for the Head job and/or Compute jobs.</p> </li> <li> <p>Configure any advanced options described below, as needed.</p> </li> <li> <p>Select Create to finalize the creation of the compute environment.</p> </li> </ol> <p>Jump to the documentation for Launching Pipelines.</p>","title":"Compute Environment"},{"location":"compute-envs/moab/#advanced-options","text":"<ul> <li> <p>You can use the Nextflow queue size to limit the number of jobs that Nextflow can submit to the scheduler at the same time.</p> </li> <li> <p>You can use the Head job submit options to specify Moab options for the head job. You can optionally apply these options to compute jobs as well:</p> </li> </ul> <p></p>","title":"Advanced options"},{"location":"compute-envs/overview/","text":"","title":"Overview"},{"location":"compute-envs/overview/#overview","text":"<p>Tower uses the concept of compute environments to define the execution platform where a pipeline will run. Compute environments enable Tower users to launch pipelines on a growing number of cloud and on-premise infrastructures.</p> <p>Each compute environment must be configured to enable Tower to submit tasks. See the individual compute environment pages below for platform-specific configuration steps.</p>","title":"Overview"},{"location":"compute-envs/overview/#platforms","text":"<ul> <li>AWS Batch</li> <li>Azure Batch</li> <li>Google Cloud Batch</li> <li>Google Life Sciences</li> <li>Altair Grid Engine</li> <li>Altair PBS Pro</li> <li>IBM LSF</li> <li>Moab</li> <li>Slurm</li> <li>Kubernetes</li> <li>Amazon EKS</li> <li>Google GKE</li> </ul>","title":"Platforms"},{"location":"compute-envs/overview/#select-a-default-compute-environment","text":"<p>If you have more than one compute environment, you can select which one will be used by default when launching a pipeline.</p> <ol> <li> <p>In a workspace, select Compute Environments.</p> </li> <li> <p>Select Make primary for a particular compute environment to make it your default.</p> </li> </ol>","title":"Select a default compute environment"},{"location":"compute-envs/overview/#gpu-usage","text":"<p>The process for provisioning GPU instances in your compute environment differs for each cloud provider.</p>","title":"GPU usage"},{"location":"compute-envs/overview/#aws-batch","text":"<p>The AWS Batch compute environment creation form in Tower includes an Enable GPUs option. This option makes it possible to run GPU-dependent workflows in the compute environment. Note that:</p> <ul> <li> <p>The Enable GPUs setting alone does not cause GPU instances to deploy in your compute environment. You must still specify GPU-enabled instance types in the Advanced options &gt; Instance types field.</p> </li> <li> <p>The Enable GPUs setting causes Tower Forge to specify the most current AWS-recommended GPU-optimized ECS AMI as the EC2 fleet AMI when creating the compute environment.</p> </li> <li> <p>This setting can be overridden by AMI ID in the advanced options.</p> </li> <li> <p>The NVIDIA Container Runtime uses environment variables in container images to specify a GPU accelerated container. These variables should be included in the <code>containerOptions</code> directive for each GPU-dependent process in your Nextflow script. For example:</p> </li> </ul> <pre>1\n2\n3</pre><pre><code>process UseGPU {\n    containerOptions '-e NVIDIA_DRIVER_CAPABILITIES=compute,utility -e NVIDIA_VISIBLE_DEVICES=all'\n}\n</code></pre>","title":"AWS Batch"},{"location":"compute-envs/slurm/","text":"","title":"Slurm"},{"location":"compute-envs/slurm/#overview","text":"<p>Slurm is an open source, fault-tolerant, and highly scalable cluster management and job scheduling system for large and small Linux clusters.</p> <p>Tower streamlines the deployment of Nextflow pipelines into both cloud-based and on-prem Slurm clusters.</p>","title":"Overview"},{"location":"compute-envs/slurm/#requirements","text":"<p>To launch pipelines into a Slurm cluster from Tower, the following requirements must be satisfied:</p> <ul> <li>The cluster should allow outbound connections to the Tower web service.</li> <li>The cluster queue used to run the Nextflow head job must be able to submit cluster jobs.</li> <li>The Nextflow runtime version 21.02.0-edge (or later) should be installed on the cluster.</li> </ul>","title":"Requirements"},{"location":"compute-envs/slurm/#compute-environment","text":"<p>To create a new compute environment for Slurm in Tower:</p> <ol> <li> <p>In a workspace, select Compute Environments and then New Environment.</p> </li> <li> <p>Enter a descriptive name for this environment, e.g. \"Slurm cluster\".</p> </li> <li> <p>Select Slurm Workload Manager as the target platform.</p> </li> <li> <p>Select your credentials, or select + and SSH or Tower Agent to add new credentials.</p> </li> <li> <p>Enter a name for the credentials.</p> </li> <li> <p>Enter the absolute path of the Work directory to be used on the cluster.</p> </li> <li> <p>Enter the absolute path of the Launch directory to be used on the cluster. If omitted, it will be the same as the work directory.</p> </li> <li> <p>Enter the Login hostname, which is usually the hostname or public IP address of the cluster's login node.</p> </li> <li> <p>Enter the Head queue name, the cluster queue to which the Nextflow job will be submitted.</p> </li> <li> <p>Enter the Compute queue name, the cluster queue to which the Nextflow job will submit tasks.</p>  <p>Tip</p> <p>The compute queue can be overridden by the Nextflow pipeline configuration. See the Nextflow docs for more details.</p>  </li> <li> <p>You can use the Environment variables option to specify custom environment variables for the Head job and/or Compute jobs.</p> </li> <li> <p>Configure any advanced options described below, as needed.</p> </li> <li> <p>Select Create to finalize the creation of the compute environment.</p> </li> </ol> <p>Jump to the documentation for Launching Pipelines.</p>","title":"Compute Environment"},{"location":"compute-envs/slurm/#advanced-options","text":"<ul> <li> <p>You can use the Nextflow queue size to limit the number of jobs that Nextflow can submit to the scheduler at the same time.</p> </li> <li> <p>You can use the Head job submit options to specify Slurm options for the head job. You can optionally apply these options to compute jobs as well:</p> </li> </ul> <p></p>","title":"Advanced options"},{"location":"core-concepts/definitions/","text":"","title":"Core concepts"},{"location":"core-concepts/definitions/#pipelines","text":"<p>A pipeline is a pre-configured workflow that can be used by all users in a workspace. It is composed of a workflow repository, launch parameters, and a compute environment.</p>","title":"Pipelines"},{"location":"core-concepts/definitions/#launchpad","text":"<p>The Launchpad contains the collection of available pipelines that can be run in a workspace. From here, you can view and select pre-configured pipelines for launch.</p>","title":"Launchpad"},{"location":"core-concepts/definitions/#runs","text":"<p>The Runs view is used to monitor and inspect the details of workflow executions in a workspace.</p>","title":"Runs"},{"location":"core-concepts/definitions/#compute-environments","text":"<p>A compute environment is the platform where workflows are executed. It is composed of the credentials, configuration settings, and storage options configured for that platform.</p>","title":"Compute environments"},{"location":"core-concepts/definitions/#credentials","text":"<p>Credentials are access keys stored by Tower in an encrypted format, using AES-256 encryption. They allow the safe storage of authentication keys for compute environments, private code repositories, and external services.</p>","title":"Credentials"},{"location":"core-concepts/definitions/#datasets","text":"<p>Datasets are collections of versioned, structured data, usually in TSV (tab-separated values) and CSV (comma-separated values) formats. They are used to manage sample sheets and metadata, to be validated and used as inputs for workflow executions.</p>","title":"Datasets"},{"location":"core-concepts/definitions/#actions","text":"<p>Actions are used to automate the execution of pre-configured workflows (pipelines), based on event triggers such as code commits and webhooks.</p>","title":"Actions"},{"location":"core-concepts/definitions/#pipeline-secrets","text":"<p>Pipeline secrets are keys used by workflow tasks to interact with external systems, such as a password to connect to an external database or an API token. They are stored in Tower using AES-256 encryption.</p> <p>There are two types of pipeline secrets:</p> <ul> <li> <p>Pipeline secrets defined in a workspace are available to the workflows launched within that workspace.</p> </li> <li> <p>Pipeline secrets defined by a user are available to the workflows launched by that user in any workspace.</p> </li> </ul>","title":"Pipeline secrets"},{"location":"core-concepts/definitions/#workspaces","text":"<p>A workspace provides the context in which a user operates, including what resources are available and who can access them. It is composed of pipelines, compute environments, credentials, runs, actions, and datasets. Access permissions are controlled through participants, collaborators, and teams.</p>","title":"Workspaces"},{"location":"core-concepts/definitions/#organizations","text":"<p>An organization is the top-level entity where businesses, institutions, and groups can collaborate. It can contain multiple workspaces.</p>","title":"Organizations"},{"location":"core-concepts/definitions/#members","text":"<p>A member is a user who is internal to the organization. Members have an organization role and can operate in one or more organization workspaces. In each workspace, members can have a participant role that defines the permissions granted to them within that workspace.</p>","title":"Members"},{"location":"core-concepts/definitions/#team","text":"<p>A team is a group of members in the same organization. Teams can operate in one or more organization workspaces with a specific workspace role (one role per workspace).</p>","title":"Team"},{"location":"core-concepts/definitions/#participant","text":"<p>A user operating with an assigned role within a workspace.</p>","title":"Participant"},{"location":"core-concepts/definitions/#participant-role","text":"<p>The participant role defines the permissions granted to a user to perform actions or tasks within a workspace.</p>","title":"Participant role"},{"location":"credentials/agent_credentials/","text":"<p>Tower Agent enables Tower to launch pipelines on HPC clusters that do not allow direct access through an SSH client. Tower Agent authenticates a secure connection with Tower using a Tower Agent credential.</p>","title":"Tower Agent credentials"},{"location":"credentials/agent_credentials/#tower-agent-sharing","text":"<p>You can share a single Tower Agent instance with all members of a workspace. Create a Tower Agent credential, with Shared agent enabled, in the relevant workspace. All workspace members can then use this Tower Agent credential (Connection ID + Tower access token) to use the same Tower Agent instance.</p>","title":"Tower Agent sharing"},{"location":"credentials/agent_credentials/#create-a-tower-agent-credential","text":"<ul> <li> <p>From an organization workspace: navigate to the Credentials tab and select Add Credentials.</p> </li> <li> <p>From your personal workspace: select Your credentials from the user top-right menu, then select Add credentials.</p> </li> </ul> <p></p>    Property Description Example     Name A unique name for the credentials using alphanumeric characters, dashes, or underscores. <code>my-agent-creds</code>   Provider Credential type Tower Agent   Agent connection ID The connection ID used to run your Tower Agent instance. Must match the connection ID used when running the Agent (see Usage below) <code>5429d66d-7712-xxxx-xxxx-xxxxxxxxxxxx</code>   Shared agent Enables Tower Agent sharing for all workspace members.    Usage Populates a code snippet for Tower Agent download with your connection ID. Replace <code>&lt;YOUR TOKEN&gt;</code> with your Tower access token.     <p>Once the form is complete, select Add. The new credential is now listed under the Credentials tab.</p>","title":"Create a Tower Agent credential"},{"location":"credentials/aws_registry_credentials/","text":"","title":"AWS Elastic Container Registry"},{"location":"credentials/aws_registry_credentials/#container-registry-credentials","text":"<p>From version 22.3, Tower supports the configuration of credentials for the Nextflow Wave container service to authenticate to private and public container registries. For more information on Wave containers, see here.</p>  <p>Note</p> <p>Container registry credentials are only leveraged by the Wave containers service. In order for your pipeline execution to leverage Wave containers, add <code>wave { enabled=true }</code> either to the Nextflow config field on the launch page, or to your nextflow.config file.</p>","title":"Container registry credentials"},{"location":"credentials/aws_registry_credentials/#aws-ecr-access","text":"<p>Wave requires programmatic access to your private registry via long-term access keys. Create a user with registry read permissions (e.g. a subset of the AWS-managed <code>AmazonEC2ContainerRegistryReadOnly</code> policy) for this purpose.</p> <p>An IAM administrator can create and manage access keys from the AWS management console:</p> <ol> <li>Open the IAM console.</li> <li>Select Users from the navigation pane.</li> <li>Select the name of the user whose keys you want to manage, then select the Security credentials tab. We recommend creating an IAM user specifically for Wave authentication instead of using existing credentials with broader permissions.</li> <li>In the Access keys section, select Create access key. Each IAM user can have only two access keys at a time, so if the Create option is deactivated, delete an existing access key first.</li> <li>On the Access key best practices &amp; alternatives page, select Other and then Next.</li> <li>On the Retrieve access key page, you can either Show the user's secret access key details, or store them by selecting Download .csv file.</li> <li>The newly created access key pair is active by default and can be stored as a container registry credential in Tower.</li> </ol>  <p>Note</p> <p>Your credential must be stored in Tower as a container registry credential, even if the same access keys already exist in Tower as a workspace credential.</p>","title":"AWS ECR access"},{"location":"credentials/aws_registry_credentials/#add-credentials-to-tower","text":"<ul> <li> <p>From an organization workspace: navigate to the Credentials tab and select Add Credentials.</p> </li> <li> <p>From your personal workspace: select Your credentials from the user top-right menu, then select Add credentials.</p> </li> </ul> <p></p>    Property Description Example     Name A unique name for the credentials using alphanumeric characters, dashes, or underscores <code>my-registry-creds</code>   Provider Credential type Container registry   User name IAM user access key ID <code>AKIAIOSFODNN7EXAMPLE</code>   Password IAM user secret access key <code>wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY</code>   Registry server The container registry server name <code>https://&lt;aws_account_id&gt;.dkr.ecr.&lt;region&gt;.amazonaws.com</code>    <p>Once the form is complete, select Add. The new credential is now listed under the Credentials tab.</p>","title":"Add credentials to Tower"},{"location":"credentials/azure_registry_credentials/","text":"","title":"Azure Container Registry"},{"location":"credentials/azure_registry_credentials/#container-registry-credentials","text":"<p>From version 22.3, Tower supports the configuration of credentials for the Nextflow Wave container service to authenticate to private and public container registries. For more information on Wave containers, see here.</p>  <p>Note</p> <p>Container registry credentials are only leveraged by the Wave containers service. In order for your pipeline execution to leverage Wave containers, add <code>wave { enabled=true }</code> either to the Nextflow config field on the launch page, or to your nextflow.config file.</p>","title":"Container registry credentials"},{"location":"credentials/azure_registry_credentials/#azure-container-registry-access","text":"<p>Azure container registry makes use of Azure RBAC (Role-Based Access Control) to grant users access \u2014 for further details, see Azure container registry roles and permissions.</p> <p>You must use Azure credentials with long-term registry read (content/read) access to authenticate Tower to your registry. We recommend a token with repository-scoped permissions that is used only by Tower.</p> <ol> <li>In the Azure portal, navigate to your container registry.</li> <li>Under Repository permissions, select Tokens -&gt; +Add.</li> <li>Enter a token name.</li> <li>Under Scope map, select Create new.</li> <li>In the Create scope map section, enter a name and description for the new scope map.</li> <li>Select your Repository from the drop-down menu.</li> <li>Select content/read from the Permissions drop-down menu, then select Add to create the scope map.</li> <li>In the Create token section, ensure the Status is Enabled (default), then select Create.</li> <li>Return to Repository permissions -&gt; Tokens for your registry, then select the token you just created.</li> <li>On the token details page, select password1 or password2.</li> <li>In the password details section, uncheck the Set expiration date? checkbox, then select Generate.</li> <li>Copy and save the password after it is generated. The password will be displayed only once.</li> </ol>","title":"Azure Container Registry access"},{"location":"credentials/azure_registry_credentials/#add-credentials-to-tower","text":"<ul> <li> <p>From an organization workspace: navigate to the Credentials tab and select Add Credentials.</p> </li> <li> <p>From your personal workspace: select Your credentials from the user top-right menu, then select Add credentials.</p> </li> </ul> <p></p>    Property Description Example     Name A unique name for the credentials using alphanumeric characters, dashes, or underscores <code>my-registry-creds</code>   Provider Credential type Container registry   User name Registry token name <code>my-registry-token</code>   Password Registry token password <code>OuSrehzUX...ACRDO+2TX</code>   Registry server The container registry server name (Settings -&gt; Access keys -&gt; Login server in Azure portal) <code>myregistry.azurecr.io</code>    <p>Once the form is complete, select Add. The new credential is now listed under the Credentials tab.</p>","title":"Add credentials to Tower"},{"location":"credentials/docker_hub_registry_credentials/","text":"","title":"Docker Hub"},{"location":"credentials/docker_hub_registry_credentials/#container-registry-credentials","text":"<p>From version 22.3, Tower supports the configuration of credentials for the Nextflow Wave container service to authenticate to private and public container registries. For more information on Wave containers, see here.</p>  <p>Note</p> <p>Container registry credentials are only leveraged by the Wave containers service. In order for your pipeline execution to leverage Wave containers, add <code>wave { enabled=true }</code> either to the Nextflow config field on the launch page, or to your nextflow.config file.</p>","title":"Container registry credentials"},{"location":"credentials/docker_hub_registry_credentials/#docker-hub-registry-access","text":"<p>You must use Docker Hub credentials with Read-only access to authenticate Tower to your registry. Docker Hub makes use of Personal Access Tokens (PATs) for authentication. Note that we do not currently support Docker Hub authentication using 2FA (two-factor authentication).</p> <p>To create your access token in Docker Hub:</p> <ol> <li>Log in to Docker Hub.</li> <li>Select your username in the top right corner and select Account Settings.</li> <li>Select Security -&gt; New Access Token.</li> <li>Enter a token description and select Read-only from the Access permissions drop-down menu, then select Generate.</li> <li>Copy and save the generated access token (this is only displayed once).</li> </ol>","title":"Docker Hub registry access"},{"location":"credentials/docker_hub_registry_credentials/#add-credentials-to-tower","text":"<ul> <li> <p>From an organization workspace: navigate to the Credentials tab and select Add Credentials.</p> </li> <li> <p>From your personal workspace: select Your credentials from the user top-right menu, then select Add credentials.</p> </li> </ul> <p></p>    Property Description Example     Name A unique name for the credentials using alphanumeric characters, dashes, or underscores <code>my-registry-creds</code>   Provider Credential type Container registry   User name Your Docker username <code>user1</code>   Password Your Personal Access Token <code>1fcd02dc-...215bc3f3</code>   Registry server The container registry hostname (excluding protocol) <code>docker.io</code>    <p>Once the form is complete, select Add. The new credential is now listed under the Credentials tab.</p>","title":"Add credentials to Tower"},{"location":"credentials/google_registry_credentials/","text":"","title":"Google Cloud"},{"location":"credentials/google_registry_credentials/#container-registry-credentials","text":"<p>From version 22.3, Tower supports the configuration of credentials for the Nextflow Wave container service to authenticate to private and public container registries. For more information on Wave containers, see here.</p>  <p>Note</p> <p>Container registry credentials are only leveraged by the Wave containers service. In order for your pipeline execution to leverage Wave containers, add <code>wave { enabled=true }</code> either to the Nextflow config field on the launch page, or to your nextflow.config file.</p>","title":"Container registry credentials"},{"location":"credentials/google_registry_credentials/#google-cloud-registry-access","text":"<p>Although Container Registry is still available and supported as a Google Enterprise API, new features will only be available in Artifact Registry. Container Registry will only receive critical security fixes. Google recommends using Artifact Registry for all new registries moving forward.</p> <p>Google Cloud Artifact Registry and Container Registry are fully integrated with Google Cloud services and support various authentication methods. Tower requires programmatic access to your private registry using long-lived service account keys in JSON format.</p> <p>Create dedicated service account keys that are only used to interact with your repositories. Tower requires the Artifact Registry Reader or Storage Object Viewer role.</p>","title":"Google Cloud registry access"},{"location":"credentials/google_registry_credentials/#create-a-service-account","text":"Google Cloud Artifact RegistryGoogle Cloud Container Registry   <p>Administrators can create a service account from the Google Cloud console:</p> <ol> <li>Navigate to the Create service account page.</li> <li>Select a Cloud project.</li> <li>Enter a service account name and (optional) description.</li> <li>Select Create and continue.</li> <li>From the Role drop-down menu under step 2, select Artifact Registry -&gt; Artifact Registry Reader, then select Continue.</li> <li>(Optional) Grant other users and admins access to this service account under step 3.</li> <li>Select Done.</li> <li>From the project service accounts page, select the three-dot menu button under Actions for the service account you just created, then select Manage keys.</li> <li>On the Keys page, select Add key.</li> <li>On the Create private key popup, select JSON and then Create. This triggers a download of a JSON file containing the service account private key and service account details.</li> <li>Base-64 encode the contents of the JSON key file:</li> </ol> <pre>1\n2\n3\n4\n5\n6\n7\n8</pre><pre><code>#Linux\nbase64 KEY-FILE-NAME &gt; NEW-KEY-FILE-NAME\n\n#macOS\nbase64 -i KEY-FILE-NAME -o NEW-KEY-FILE-NAME\n\n#Windows\nBase64.exe -e KEY-FILE-NAME &gt; NEW-KEY-FILE-NAME\n</code></pre>   <p>Administrators can create a service account from the Google Cloud console:</p> <ol> <li>Navigate to the Create service account page.</li> <li>Select a Cloud project.</li> <li>Enter a service account name and (optional) description.</li> <li>Select Create and continue.</li> <li>From the Role drop-down menu under step 2, search for and select Storage Object Viewer, then select Continue.</li> <li>(Optional) Grant other users and admins access to this service account under step 3.</li> <li>Select Done.</li> <li>From the project service accounts page, select the three-dot menu button under Actions for the service account you just created, then select Manage keys.</li> <li>On the Keys page, select Add key.</li> <li>On the Create private key popup, select JSON and then Create. This triggers a download of a JSON file containing the service account private key and service account details.</li> </ol>","title":"Create a service account"},{"location":"credentials/google_registry_credentials/#add-credentials-to-tower","text":"<ul> <li> <p>From an organization workspace: navigate to the Credentials tab and select Add Credentials.</p> </li> <li> <p>From your personal workspace: select Your credentials from the user top-right menu, then select Add credentials.</p> </li> </ul> <p></p>    Property Description Example     Name A unique name for the credentials using alphanumeric characters, dashes, or underscores <code>my-registry-creds</code>   Provider Credential type Container registry   User name Service account key type (Container Registry: <code>_json_key</code>, Artifact Registry: <code>_json_key_base64</code>)   Password JSON key file content (base64-encoded for Artifact Registry \u2014 remove any line breaks or trailing spaces) <code>wewogICJ02...9tIgp9Cg==</code>   Registry server The container registry hostname (excluding protocol) <code>&lt;location&gt;-docker.pkg.dev</code>    <p>Once the form is complete, select Add. The new credential is now listed under the Credentials tab.</p>","title":"Add credentials to Tower"},{"location":"credentials/overview/","text":"","title":"Overview"},{"location":"credentials/overview/#credentials","text":"<p>In Tower, you can configure workspace credentials to store the access keys and tokens for your compute environments and Git hosting services.</p> <p>From Tower 22.3, you can configure container registry credentials to be used by the Wave containers service to authenticate to private and public container registries such as Docker Hub, Google Artifact Registry, Quay, etc.</p> <p>See the Container registry credentials section for registry-specific instructions.</p> <p></p>  <p>Note</p> <p>All credentials are (AES-256) encrypted before secure storage and not exposed in an unencrypted way by any Tower API.</p>","title":"Credentials"},{"location":"credentials/quay_registry_credentials/","text":"","title":"Quay"},{"location":"credentials/quay_registry_credentials/#container-registry-credentials","text":"<p>From version 22.3, Tower supports the configuration of credentials for the Nextflow Wave container service to authenticate to private and public container registries. For more information on Wave containers, see here.</p>  <p>Note</p> <p>Container registry credentials are only leveraged by the Wave containers service. In order for your pipeline execution to leverage Wave containers, add <code>wave { enabled=true }</code> either to the Nextflow config field on the launch page, or to your nextflow.config file.</p>","title":"Container registry credentials"},{"location":"credentials/quay_registry_credentials/#quay-repository-access","text":"<p>For Quay repositories, we recommend using robot accounts with Read access permissions for authentication:</p> <ol> <li>Sign in to quay.io.</li> <li>From the user or organization view, select the Robot Accounts tab.</li> <li>Select Create Robot Account.</li> <li>Enter a robot account name. The username for robot accounts have the format <code>namespace+accountname</code>, where <code>namespace</code> is the user or organization name and <code>accountname</code> is your chosen robot account name.</li> <li>Grant the robot account repository Read permissions from Settings -&gt; User and Robot Permissions in the repository view.</li> <li>Select the robot account in your admin panel to retrieve the token value.</li> </ol>","title":"Quay repository access"},{"location":"credentials/quay_registry_credentials/#add-credentials-to-tower","text":"<ul> <li> <p>From an organization workspace: navigate to the Credentials tab and select Add Credentials.</p> </li> <li> <p>From your personal workspace: select Your credentials from the user top-right menu, then select Add credentials.</p> </li> </ul> <p></p>    Property Description Example     Name A unique name for the credentials using alphanumeric characters, dashes, or underscores <code>my-registry-creds</code>   Provider Credential type Container registry   User name Robot account username (<code>namespace+accountname</code>) <code>mycompany+myrobotaccount</code>   Password Robot account access token <code>PasswordFromQuayAdminPanel</code>   Registry server The container registry hostname <code>quay.io</code>    <p>Once the form is complete, select Add. The new credential is now listed under the Credentials tab.</p>","title":"Add credentials to Tower"},{"location":"credentials/ssh_credentials/","text":"<p>SSH public key authentication relies on asymmetric cryptography to generate a public and private key pair. The public key remains on the target (remote) machine, while the private key (and passphrase) is stored in Tower as a credential. The key pair is used to authenticate a Tower connection with your SSH-enabled environment.</p>  <p>Note</p> <p>All credentials are (AES-256) encrypted before secure storage and not exposed in an unencrypted way by any Tower API.</p>","title":"SSH credentials"},{"location":"credentials/ssh_credentials/#create-an-ssh-key-pair","text":"<p>To use SSH public key authentication:</p> <ul> <li>The remote system must have a version of SSH installed. This guide assumes the remote system uses OpenSSH. If you are using a different version of SSH, the key generation steps may differ.</li> <li>The SSH public key must be present on the remote system (usually in <code>~/.ssh/authorized_keys</code>).</li> </ul> <p>To generate an SSH key pair:</p> <ol> <li>From the target machine, open a terminal and run <code>ssh-keygen</code>.</li> <li>Follow the prompts to:</li> <li>specify a file path and name (or keep the default)</li> <li>specify a passphrase (recommended)</li> <li>Navigate to the target folder (default <code>/home/user/.ssh/id_rsa</code>) and open the private key file with a plain text editor.</li> <li>Copy the private key file contents before navigating to Tower.</li> </ol>","title":"Create an SSH key pair"},{"location":"credentials/ssh_credentials/#create-an-ssh-credential-in-tower","text":"<ul> <li> <p>From an organization workspace: navigate to the Credentials tab and select Add Credentials.</p> </li> <li> <p>From your personal workspace: select Your credentials from the user top-right menu, then select Add credentials.</p> </li> </ul> <p></p>    Property Description Example     Name A unique name for the credentials using alphanumeric characters, dashes, or underscores. <code>my-ssh-creds</code>   Provider Credential type SSH   SSH private key The SSH private key file contents. <code>-----BEGIN OPENSSH PRIVATE KEY-----b3BlbnNza....</code>   Passphrase SSH private key passphrase (recommended). If your key pair was created without a passphrase, leave this blank.     <p>Once the form is complete, select Add. The new credential is now listed under the Credentials tab.</p>","title":"Create an SSH credential in Tower"},{"location":"dashboard/overview/","text":"","title":"Dashboard"},{"location":"dashboard/overview/#overview","text":"<p>Note</p> <p>This feature is available from Tower v.22.3.</p>  <p>From version 22.3, Tower contains a Dashboard page that provides an overview of runs in your organizations and personal workspace at a glance. The dashboard is accessed from the user menu in the top right corner. Click your avatar, then select \"Dashboard\".</p> <p></p> <p>The page is split into two main areas:</p>","title":"Overview"},{"location":"dashboard/overview/#filters-and-summary","text":"<p>The drop-down lists at the top of the dashboard page filter total runs by your personal workspace, the organizations you have access to, and time range.</p> <p>Below the filters, a summary of total runs is shown by status.</p>","title":"Filters and summary"},{"location":"dashboard/overview/#runs-per-organization","text":"<p>Below the cards displaying total runs by status, run totals are filtered by each organization or your personal workspace. Filtering depends on what you selected in the drop-down options near the top of the page.</p> <p>Each card represents an organization. Total runs for the organization are arranged by workspace and status.</p> <p></p> <p>Click a run value in the table to navigate to a run list filtered by the status selected.</p> <p>Click a workspace name in the table to navigate to a run list filtered by the workspace selected.</p>","title":"Runs per organization"},{"location":"data-privacy/overview/","text":"","title":"Data privacy"},{"location":"data-privacy/overview/#your-data","text":"<p>Your data stays strictly within your infrastructure itself. When you launch a workflow through Tower, you need to connect your infrastructure (HPC/VMs/K8s) by creating the appropriate credentials and compute environment in a workspace.</p> <p>Tower then uses this configuration to trigger a Nextflow workflow within your infrastructure similar to what is done via the Nextflow CLI, therefore Tower does not manipulate any data itself and no data is transferred to the infrastructure where Tower is running.</p> <p>It may be possible to access some data within your storage from the Nextflow Tower interface - for example, viewing logs and reports generated in a pipeline run - however, this data is never stored within the Tower infrastructure.</p>","title":"Your data"},{"location":"data-privacy/overview/#metadata-stored-by-nextflow-tower","text":"<p>Workflow execution metadata is sent by the Nextflow runtime to Nextflow Tower when:</p> <ul> <li>Launching workflow with Tower</li> <li>Using the <code>-with-tower</code> option at the command line</li> <li>When a Nextflow Tower is specified in the Nextflow config</li> </ul> <p>The following sections describe the data structure and metadata fields collected by Tower.</p>","title":"Metadata stored by Nextflow Tower"},{"location":"data-privacy/overview/#workflow-metadata","text":"<p>The following metadata fields are collected and stored by the Tower backend during a workflow execution:</p>    Name Description     <code>command_line</code> The command line used to launch the workflow execution   <code>commit_id</code> The workflow project commit Id at the time of the execution   <code>complete</code> The workflow execution completion timestamp   <code>config_files</code> The nextflow config file paths(s) involved in the workflow execution   <code>config_text</code> The nextflow config content used for the workflow execution. Note: secrets, such as, AWS keys are stripped and not included in this field.   <code>container</code> The container image name(s) used for the pipeline execution   <code>container_engine</code> The container engine name used for the pipeline execution   <code>duration</code> The workflow execution overall duration (wall time)   <code>error_message</code> The error message reported in the case of nextflow execution failure   <code>error_report</code> The extended error message reported in case of workflow execution error.   <code>exit_status</code> The workflow execution (POSIX) exit code   <code>home_dir</code> The launching user home directory path   <code>launch_dir</code> The workflow launching directory path   <code>manifest_author</code> The workflow project author as defined in the nextflow config manifest file   <code>manifest_default_branch</code> The workflow project default Git branch as defined in the nextflow config manifest file   <code>manifest_description</code> The workflow project description as defined in the nextflow config manifest file   <code>manifest_gitmodules</code> The workflow project Git submodule flag in the nextflow config manifest file   <code>manifest_home_page</code> The workflow project Git home page as defined in the nextflow config manifest file   <code>manifest_main_script</code> The workflow project main script file name as defined in the nextflow config manifest file   <code>manifest_name</code> The workflow project name as defined in the nextflow config manifest file   <code>manifest_nextflow_version</code> The workflow project required Nextflow version defined in the nextflow config manifest file   <code>manifest_version</code> The workflow project version string as defined in the nextflow config manifest file   <code>nextflow_build</code> The build number of the Nextflow runtime used to launch the workflow execution   <code>nextflow_timestamp</code> The build timestamp of the Nextflow runtime used to launch the workflow execution   <code>nextflow_version</code> The version string of the Nextflow runtime used to launch the workflow execution   <code>params</code> The workflow params used to launch the pipeline execution   <code>profile</code> The workflow config profile string used for the pipeline execution   <code>project_dir</code> The directory path where the workflow scripts are stored   <code>project_name</code> The workflow project name   <code>repository</code> The workflow project repository   <code>resume</code> The flag set when a resume execution was submitted   <code>revision</code> The workflow project revision number   <code>run_name</code> The workflow run name as given by the Nextflow runtime   <code>script_file</code> The workflow script file path   <code>script_id</code> The workflow script checksum number   <code>script_name</code> The workflow script filename   <code>session_id</code> The workflow execution unique UUID as assigned by the Nextflow runtime   <code>start</code> The workflow execution start timestamp   <code>stats_cached_count</code> The number of cached tasks upon completion   <code>stats_cached_duration</code> The aggregate time of cached tasks upon completion   <code>stats_cached_pct</code> The percentage of cached tasks upon completion   <code>stats_compute_time_fmt</code> The overall compute time as a formatted string   <code>stats_failed_count</code> The number of failed tasks upon completion   <code>stats_failed_count_fmt</code> The number of failed tasks upon completion as a formatted string   <code>stats_failed_duration</code> The aggregate time of failed tasks upon completion   <code>stats_failed_pct</code> The percentage of failed tasks upon completion   <code>stats_ignored_count</code> The number of ignored tasks upon completion   <code>stats_ignored_count_fmt</code> The number of ignored tasks upon completion as a formatted string   <code>stats_ignored_pct</code> The percentage of ignored tasks upon completion   <code>stats_succeed_count</code> The number of succeeded tasks upon completion   <code>stats_succeed_count_fmt</code> The number of succeeded tasks upon completion as a formatted string   <code>stats_succeed_duration</code> The aggregate time of succeeded tasks upon completion   <code>stats_succeed_pct</code> The percentage of succeeded tasks upon completion   <code>status</code> The workflow execution status   <code>submit</code> The workflow execution submission timestamp   <code>success</code> The flag reporting whether the execution completed successfully   <code>user_name</code> The POSIX user name launching that launched the workflow execution   <code>work_dir</code> The workflow execution scratch directory path","title":"Workflow metadata"},{"location":"data-privacy/overview/#task-metadata","text":"Name Description     <code>attempt</code> Number of execution attempt of the task   <code>cloud_zone</code> Cloud zone where the task execution was allocated   <code>complete</code> Task execution completion timestamp   <code>container</code> Container image name used to execute the task   <code>cost</code> Estimated task compute cost   <code>cpus</code> Number of CPUs requested   <code>disk</code> Amount of disk storage requested   <code>duration</code> Amount of time for the task completion   <code>env</code> Task execution environment variables   <code>error_action</code> Action applied on task failure   <code>executor</code> Executor requested for the task execution   <code>exit_status</code> Task POSIX exit code on completion   <code>hash</code> Task unique hash code   <code>inv_ctxt</code> Number of involuntary context switches   <code>machine_type</code> Cloud virtual machine type   <code>memory</code> Amount of memory requested   <code>module</code> Environment Module requested   <code>name</code> Task unique name   <code>native_id</code> Task unique ID as assigned by the underlying execution platform   <code>pcpu</code> Percentage of CPU used to compute the task   <code>peak_rss</code> Peak of real memory during the task execution   <code>peak_vmem</code> Peak of virtual memory during the task execution   <code>pmem</code> Percentage of memory used to compute the task   <code>price_model</code> The cloud price model applied for the task   <code>process</code> The nextflow process name   <code>queue</code> The compute queue name requested   <code>rchar</code> Number of bytes the process read, using any read-like system call from files, pipes, tty, etc.   <code>read_bytes</code> Number of bytes the process directly read from disk   <code>realtime</code> The time required to compute the task   <code>rss</code> Real memory (resident set) size of the process   <code>scratch</code> Flag reporting the task was executed in a local scratch path   <code>script</code> The task command script   <code>start</code> Task execution start timestamp   <code>status</code> The task execution status   <code>submit</code> Task submission timestamp   <code>syscr</code> Number of read-like system call invocations that the process performed   <code>syscw</code> Number of write-like system call invocations that the process performed   <code>tag</code> Nextflow tag associated to the task execution   <code>task_id</code> Nextflow task ID   <code>time</code> Task execution timeout requested   <code>vmem</code> Virtual memory size used by the task execution   <code>vol_ctxt</code> Number of voluntary context switches   <code>wchar</code> Number of bytes the process wrote, using any write-like system call   <code>workdir</code> Task execution work directory   <code>write_bytes</code> Number of bytes the process written to disk","title":"Task Metadata"},{"location":"datasets/overview/","text":"","title":"Datasets"},{"location":"datasets/overview/#overview","text":"<p>Note</p> <p>This feature is only available in organization workspaces.</p>  <p>Datasets in Nextflow Tower are CSV (comma-separated values) and TSV (tab-separated values) formatted files stored in a workspace. They are designed to be used as inputs to pipelines to simplify data management, minimize user data-input errors, and facilitate reproducible workflows.</p> <p>The combination of datasets, pipeline secrets, and pipeline actions in Tower allow you to automate workflows to curate your data and maintain and launch pipelines based on specific events. See here for an example of pipeline workflow automation using Tower.</p> <ul> <li> <p>Using datasets reduces errors that occur due to manual data entry when launching pipelines.</p> </li> <li> <p>Datasets can be generated automatically in response to events (such as S3 storage new file notifications).</p> </li> <li> <p>Datasets can streamline differential data analysis when using the same pipeline to launch a run for each dataset as it becomes available.</p> </li> </ul> <p>For your pipeline to use your dataset as input during runtime, information about the dataset and file format must be included in the relevant parameters of your pipeline schema.</p>","title":"Overview"},{"location":"datasets/overview/#dataset-validation-and-file-content-requirements","text":"<p>Tower does not validate your dataset file contents. While datasets can contain static file links, you are responsible for maintaining the access to that data.</p> <p>Datasets can point to files stored in various locations, such as Amazon S3 or GitHub. To stage the file paths defined in the dataset, Nextflow requires access to the infrastructure where the files reside, whether on Cloud or HPC systems. Add the access keys for data sources that require authentication to your pipeline secrets.</p>","title":"Dataset validation and file content requirements"},{"location":"datasets/overview/#dataset-permissions","text":"<p>All Tower users have access to the datasets feature in organization workspaces.</p>","title":"Dataset permissions"},{"location":"datasets/overview/#creating-a-new-dataset","text":"<p>To create a new dataset, follow these steps:</p> <ol> <li>Open the Datasets tab in your organization workspace.</li> <li>Select New dataset.</li> <li>Complete the Name and Description fields using information relevant to your dataset.</li> <li>Add the dataset file to your workspace with drag-and-drop or the system file explorer dialog.</li> <li>For dataset files that use the first row for column names, customize the dataset view with the First row as header option.</li> </ol>  <p>Warning</p> <p>The size of the dataset file cannot exceed 10MB.</p>","title":"Creating a new dataset"},{"location":"datasets/overview/#dataset-versions","text":"<p>Datasets in Tower can accommodate multiple versions of a dataset. To add a new version for an existing dataset, follow these steps:</p> <ol> <li>Select Edit next to the dataset you wish to update.</li> <li>In the Edit dialog, select Add a new version.</li> <li>Upload the newer version of the dataset and select Update.</li> </ol>  <p>Warning</p> <p>All subsequent versions of a dataset must be in the same format (.csv or .tsv) as the initial version.</p>","title":"Dataset versions"},{"location":"datasets/overview/#using-a-dataset","text":"<p>To use a dataset with the saved pipelines in your workspace, follow these steps:</p> <ol> <li>Open any pipeline that contains a pipeline-schema from the Launchpad.</li> <li>Select the input field for the pipeline, removing any default value.</li> <li>Pick the dataset to use as input to your pipeline.</li> </ol>  <p>Note</p> <p>The datasets shown in the drop-down menu depend on the chosen format in your <code>pipeline-schema.json</code>. If the schema specifies <code>\"mimetype\": \"text/csv\"</code>, no TSV datasets will be available, and vice versa.</p>","title":"Using a dataset"},{"location":"functionality_matrix/functionality_matrix/","text":"","title":"Functionality matrix"},{"location":"functionality_matrix/functionality_matrix/#tower-nextflow-version-compatibility","text":"<p>Each Tower version makes use of <code>nf-launcher</code> to determine the Nextflow version used as its baseline. This Nextflow version can be overridden with the <code>NXF_VER</code> environment variable in your <code>nextflow.conf</code> file, but note that Tower may not work reliably with Nextflow versions other than the baseline version.</p> <p>We officially support the two latest Tower major releases (22.3.x, 22.4.x, etc) at any given time.</p> <p>nf-launcher versions prefixed with j17 refer to Java version 17; j11 refers to Java 11.</p>    Tower version nf-launcher version Nextflow version     22.4.1 j17-22.10.6 22.10.6   22.4.0 j17-22.10.6 22.10.6   22.3.1 j17-22.10.4 22.10.4   22.3 j17-22.10.1 22.10.1   22.2.4 j17-22.06.1-edge 22.06.1-edge   22.2.3 j11-22.06.1-edge 22.06.1-edge   22.2.2 j17-22.08.0-edge 22.08.0-edge     <p>If no Nextflow version is specified in your configuration, Tower defaults to the baseline version outlined above.</p>","title":"Tower / Nextflow version compatibility"},{"location":"getting-started/deployment-options/","text":"<p>Tower is available in three versions:</p> <ul> <li> <p>Tower Cloud: The hosted version of Tower is available free of charge at tower.nf. This version is for individuals and organizations that want to get set up fast. It is the recommended way for users to become familiar with Tower. The service is hosted by Seqera Labs.</p> </li> <li> <p>Tower Community: The Community edition of Tower is open-source and can be deployed by anyone on their own infrastructure. The community edition has basic features for the monitoring of pipelines by an individual user.</p> </li> <li> <p>Tower Enterprise: The Enterprise edition of Tower contains the latest features and can be deployed in an organization's own cloud or on-premises infrastructure. This option includes dedicated support from Seqera Labs and is recommended for production environments.</p> </li> </ul>","title":"Deployment options"},{"location":"getting-started/deployment-options/#tower-cloud","text":"<p>To try Tower Cloud, visit tower.nf and log in with your GitHub or Google credentials. The Launching pipelines page provides step-by-step instructions to launch your first pipeline. Tower Cloud has a limit of five concurrent workflow runs per user.</p> <p></p>","title":"Tower Cloud"},{"location":"getting-started/deployment-options/#tower-community","text":"<p>For instructions to install the Community edition of Tower, visit the GitHub repository.</p> <p></p>  <p>Warning</p> <p>Tower Community does not include all the features of Tower Cloud and Tower Enterprise, such as Tower Launch, Organizations, and Workspaces.</p>","title":"Tower Community"},{"location":"getting-started/deployment-options/#tower-enterprise","text":"<p>Tower Enterprise is installed in an organization's own cloud or on-premises infrastructure. It includes:</p> <ul> <li>Monitoring, logging, and observability</li> <li>Pipeline execution launchpad</li> <li>Cloud resource provisioning</li> <li>Pipeline actions and event-based execution</li> <li>LDAP &amp; OpenID authentication</li> <li>Enterprise role-based access control (RBAC)</li> <li>Full-featured API</li> <li>Technical support for Nextflow and Tower</li> </ul> <p>To install Tower in your organization, contact Seqera Labs for a demo to discuss your requirements.</p> <p></p>","title":"Tower Enterprise"},{"location":"getting-started/usage/","text":"<p>You can use Tower through the web interface, the API, the CLI, or in Nextflow directly using the <code>-with-tower</code> option.</p>","title":"Usage"},{"location":"getting-started/usage/#tower-web-interface","text":"<ol> <li> <p>Create an account and log in to Tower, available free of charge at tower.nf.</p> </li> <li> <p>Create and configure a new compute environment.</p> </li> <li> <p>Start launching pipelines.</p> </li> </ol>","title":"Tower web interface"},{"location":"getting-started/usage/#tower-api","text":"<p>See API.</p>","title":"Tower API"},{"location":"getting-started/usage/#tower-cli","text":"<p>See CLI.</p>","title":"Tower CLI"},{"location":"getting-started/usage/#nextflow-with-tower","text":"<ol> <li> <p>Create an account and log in to Tower.</p> </li> <li> <p>Create a new token. You can access your tokens from the Settings drop-down menu:</p> </li> </ol> <p></p> <ol> <li>Name your token.</li> </ol> <p></p> <ol> <li>Store your token securely.</li> </ol> <p></p>   <p>Note</p> <p>The token will only be displayed once. You must copy and save the token before closing the Personal Access Token window.</p>  <ol> <li>Open a terminal and enter the following commands:</li> </ol> <pre>1\n2</pre><pre><code>export TOWER_ACCESS_TOKEN=eyxxxxxxxxxxxxxxxQ1ZTE=\nexport NXF_VER=22.10.6\n</code></pre> <p>Where <code>eyxxxxxxxxxxxxxxxQ1ZTE=</code> is the token you just created.</p> <p>!!! note \"Nextflow version\"    Bearer token support requires Nextflow version 20.10.0 or later, set with the second command above.</p> <p>To submit a pipeline to a workspace using Nextflow, add the workspace ID to your environment:</p> <pre>1</pre><pre><code>export TOWER_WORKSPACE_ID=000000000000000\n</code></pre> <p>The workspace ID can be found on the organization workspaces overview page.</p> <ol> <li>Run your Nextflow pipeline with the <code>-with-tower</code> flag:</li> </ol> <pre>1</pre><pre><code>nextflow run hello.nf -with-tower\n</code></pre> <p>You can now monitor your workflow runs in Tower.</p> <p>To configure and execute Nextflow pipelines in cloud environments, see Compute Environments.</p>   <p>Tip</p> <p>See the Nextflow documentation for further run configuration options using Nextflow configuration files.</p>","title":"Nextflow <code>-with-tower</code>"},{"location":"getting-started/workspace/","text":"<p>Each user has a unique workspace to manage all resources, such as pipelines, compute environments, and credentials.</p>   <p>Tip</p> <p>You can create multiple workspaces within an organization context and associate each of these workspaces with dedicated teams of users, while providing a fine-grained access control model for each of the teams. See Orgs and teams.</p>  <p>The core components of a workspace are:</p>","title":"Workspaces"},{"location":"getting-started/workspace/#launchpad","text":"<p>The Launchpad offers a streamlined UI for launching and managing pipelines and their associated compute environments and credentials. Using the Launchpad, you can create a curated set of pipelines (including variations of the same pipeline) that are ready to be executed on the associated compute environments, while allowing the user to customize the pipeline-level parameters if needed.</p>","title":"Launchpad"},{"location":"getting-started/workspace/#runs","text":"<p>The Runs section monitors a launched workflow with real-time execution metrics, such as the number of pending or completed processes.</p> <p>See Launch.</p>","title":"Runs"},{"location":"getting-started/workspace/#actions","text":"<p>You can trigger pipelines based on specific events, such as a version release on Github or a general Tower webhook.</p> <p>See Pipeline actions.</p>","title":"Actions"},{"location":"getting-started/workspace/#compute-environments","text":"<p>Tower uses the concept of a Compute environment to define an execution platform for pipelines. Tower supports launching pipelines into a growing number of cloud (AWS, Azure, GCP) and on-premises (Slurm, IBM LSF, Grid Engine, etc.) infrastructures.</p> <p>See Compute environments.</p>","title":"Compute environments"},{"location":"getting-started/workspace/#credentials","text":"<p>The Credentials section allows users to set up the access credentials for various platforms (Github, Gitlab, BitBucket, etc.) and compute environments (cloud, Slurm, Kubernetes, etc.) See Compute environments and Git integration for information on your infrastructure.</p> <p>See Credentials.</p>","title":"Credentials"},{"location":"git/overview/","text":"","title":"Git integration"},{"location":"git/overview/#overview","text":"<p>Data pipelines can be composed of many assets (pipeline scripts, configuration files, dependency descriptors such as for Conda or Docker, documentation, etc). By managing complex data pipelines as Git repositories, all assets can be versioned and deployed with a specific tag, release or commit id. Version control, combined with containerization, is crucial for enabling reproducible pipeline executions, and it provides the ability to continuously test and validate pipelines as the code evolves over time.</p> <p>Nextflow has built-in support for Git and several Git-hosting platforms. Nextflow pipelines can be pulled remotely from both public and private Git-hosting providers, including the most popular platforms: GitHub, GitLab, and BitBucket.</p>","title":"Overview"},{"location":"git/overview/#public-repositories","text":"<p>You can use a publicly hosted Nextflow pipeline by specifying the Git repository URL in the Pipeline to launch field.</p> <p>When specifying the Revision number, the list of available revisions are automatically pulled using the Git provider's API. By default, the default branch (usually <code>main</code> or <code>master</code>) will be used.</p> <p></p>   <p>Tip</p> <p>nf-core is a great resource for public Nextflow pipelines.</p>    <p>API Rate Limits</p> <p>The GitHub API imposes rate limits on API requests. You can increase your rate limit by adding GitHub credentials to your workspace as shown below.</p>","title":"Public repositories"},{"location":"git/overview/#private-repositories","text":"<p>In order to access private Nextflow pipelines, you must add credentials for your private Git hosting provider.</p>   <p>Note</p> <p>All credentials are (AES-256) encrypted before secure storage and are not exposed in an unencrypted way by any Tower API.</p>","title":"Private repositories"},{"location":"git/overview/#multiple-credential-filtering","text":"<p>When your Tower instance has multiple stored credentials, selection of the most relevant credential for your repository takes precedence in the following order:</p> <ol> <li> <p>Tower evaluates all the stored credentials available to the current Workspace.</p> </li> <li> <p>Credentials are filtered by Git provider (GitHub, GitLab, Bitbucket, etc.)</p> </li> <li> <p>Tower selects the credential with a Repository base URL most similar to the target repository.</p> </li> <li> <p>If no Repository base URL values are specified in the Workspace credentials, the the most long-lived credential is selected.</p> </li> </ol> <p>Example:</p> <p>Workspace A contains 4 credentials:</p> <p>Credential A</p> <pre>1\n2\n3</pre><pre><code>Type: GitHub\n\nRepository base URL:\n</code></pre> <p>Credential B</p> <pre>1\n2\n3</pre><pre><code>Type: GitHub\n\nRepository base URL: https://github.com/\n</code></pre> <p>Credential C</p> <pre>1\n2\n3</pre><pre><code>Type: GitHub\n\nRepository base URL: https://github.com/pipeline-repo\n</code></pre> <p>Credential D</p> <pre>1\n2\n3</pre><pre><code>Type: GitLab\n\nRepository base URL: https://gitlab.com/repo-a\n</code></pre> <p>If you launch a pipeline with a Nextflow workflow residing in https://github.com/pipeline-repo, Tower will use Credential C.</p> <p>To ensure automatic selection of the most appropriate credential for your repository, we recommend that you:</p> <ul> <li> <p>Specify Repository base URL values as precisely as possible for each Git credential used in the Workspace.</p> </li> <li> <p>Favor the use of service account type credentials where possible (such as GitLab group access tokens).</p> </li> <li> <p>Avoid the use of multiple user-based tokens with similar permissions.</p> </li> </ul>","title":"Multiple credential filtering"},{"location":"git/overview/#github","text":"<p>To connect a private GitHub repository, personal (classic) or fine-grained access tokens can be used.</p>   <p>Note</p> <p>A personal access token (classic) can access every repository that the user it belongs to can access. GitHub recommends that you use fine-grained personal access tokens (currently in beta) instead, which you can restrict to specific repositories. Fine-grained personal access tokens also enable you to specify granular permissions instead of broad scopes.</p>  <p>For personal (classic) tokens, you must grant access to the private repository by selecting the main <code>repo</code> scope when the token is created. See here for instructions to create your personal access token (classic).</p> <p>For fine-grained tokens, the repository's organization must opt in to the use of fine-grained tokens. Tokens can be restricted by Resource owner (organization), Repository access, and Permissions. See here for instructions to create your fine-grained access token.</p> <p>Once you have created and copied your access token, create a new credential in Tower using these steps:</p> <ol> <li> <p>Navigate to the Credentials tab. If you are using your personal workspace, select Your credentials from the user icon menu (top right).</p> </li> <li> <p>Select Add Credentials.</p> </li> <li> <p>Enter a Name for the new credentials.</p> </li> <li> <p>Select \"GitHub\" as the Provider.</p> </li> <li> <p>Enter your Username and Access token.</p> </li> <li> <p>Enter the Repository base URL for which the credentials should be applied (recommended). This option can be used to apply the provided credentials to a specific repository, e.g. <code>https://github.com/seqeralabs</code>.</p> </li> </ol>","title":"GitHub"},{"location":"git/overview/#gitlab","text":"<p>GitLab supports Personal, Group, and Project access tokens for authentication. Your access token should have the <code>api</code>, <code>read_api</code>, and <code>read_repository</code> scopes in order to work with Tower. For all three token types, the token value is used for both the Password and Access token fields in the Tower credential creation form.</p> <p>To connect Tower to a private GitLab repository:</p> <ol> <li> <p>Navigate to the Credentials tab. If you are using your personal workspace, select Your credentials from the user icon menu (top right).</p> </li> <li> <p>Select Add Credentials.</p> </li> <li> <p>Enter a Name for the new credentials.</p> </li> <li> <p>Select \"GitLab\" as the Provider.</p> </li> <li> <p>Enter your Username. For Group and Project access tokens, the username can be any non-empty value.</p> </li> <li> <p>Enter your token value in the Password and Access token fields.</p> </li> <li> <p>Enter the Repository base URL (recommended). This option is used to apply the credentials to a specific repository, e.g. <code>https://gitlab.com/seqeralabs</code>.</p> </li> </ol>","title":"GitLab"},{"location":"git/overview/#gitea","text":"<p>Available from Tower 22.4.X</p> <p>To connect to a private Gitea repository, supply your Gitea user credentials to create a new credential in Tower with these steps:</p> <ol> <li> <p>Navigate to the Credentials tab. If you are using your personal workspace, select Your credentials from the user icon menu (top right).</p> </li> <li> <p>Select Add Credentials.</p> </li> <li> <p>Enter a Name for the new credentials.</p> </li> <li> <p>Select \"Gitea\" as the Provider.</p> </li> <li> <p>Enter your Username.</p> </li> <li> <p>Enter your Password.</p> </li> <li> <p>Enter your Repository base URL (required).</p> </li> </ol>","title":"Gitea"},{"location":"git/overview/#bitbucket","text":"<p>To connect to a private BitBucket repository, refer to the BitBucket documentation to learn how to create a BitBucket App password. Then, create a new credential in Tower using these steps:</p> <ol> <li> <p>Navigate to the Credentials tab. If you are using your personal workspace, select Your credentials from the user icon menu (top right).</p> </li> <li> <p>Select Add Credentials.</p> </li> <li> <p>Enter a Name for the new credentials.</p> </li> <li> <p>Select \"BitBucket\" as the Provider.</p> </li> <li> <p>Enter your Username and Password.</p> </li> <li> <p>Enter the Repository base URL (recommended). This option can be used to apply the provided credentials to a specific repository, e.g. <code>https://bitbucket.org/seqeralabs</code>.</p> </li> </ol>","title":"Bitbucket"},{"location":"git/overview/#aws-codecommit","text":"<p>To connect to a private AWS CodeCommit repository, refer to the AWS documentation to learn more about IAM permissions for CodeCommit. Then, supply the IAM account access key and secret key to create a credential in Tower using these steps:</p> <ol> <li> <p>Navigate to the Credentials tab. If you are using your personal workspace, select Your credentials from the user icon menu (top right).</p> </li> <li> <p>Select Add Credentials.</p> </li> <li> <p>Enter a Name for the new credentials.</p> </li> <li> <p>Select \"CodeCommit\" as the Provider.</p> </li> <li> <p>Enter the Access key and Secret key of the AWS IAM account that will be used to access the desired CodeCommit repository.</p> </li> <li> <p>Enter the Repository base URL for which the credentials should be applied (recommended). This option can be used to apply the provided credentials to a specific region, e.g. <code>https://git-codecommit.eu-west-1.amazonaws.com</code>.</p> </li> </ol>","title":"AWS CodeCommit"},{"location":"git/overview/#self-hosted-git","text":"<p>It is also possible to specify Git server endpoints for Tower Enterprise. For more information, refer to the Tower Install Documentation.</p>","title":"Self-hosted Git"},{"location":"installation/system-deployment/","text":"<p>Tip</p> <p>It is highly recommended to first Sign up and try the hosted version of Tower for free or request a demo for a deployment in your own on-premises or cloud environment.</p>  <p>Nextflow Tower is a web application server based on a microservice oriented architecture and designed to maximize the portability, scalability and security of the application.</p> <p>The application is composed of a variety of modules that can be configured and deployed depending on organization's requirements.</p> <p>All components for the Enterprise release are packaged as Docker container images which are hosted and security validated by the Amazon ECR service. The community version can be accessed via GitHub.</p>","title":"System deployment"},{"location":"installation/system-deployment/#deployment-configurations","text":"<p>Warning</p> <p>To install Nextflow Tower on private infrastructure, you'd need a license key. Please contact us at sales@seqera.io to get your license key.</p>","title":"Deployment configurations"},{"location":"installation/system-deployment/#basic-deployment","text":"<p>The minimal Tower configuration only requires the front-end, backend and database modules.</p> <p>These can be executed as Docker containers or as native services running in the hosting environment. Such a minimal configuration is only suggested for evaluation purposes or for a small number of users.</p>","title":"Basic deployment"},{"location":"installation/system-deployment/#kubernetes-deployment","text":"<p>Kubernetes cluster management is emerging as the technology of choice for the deployment of applications requiring high-availability, scalability and security.</p> <p>Nextflow Tower Enterprise includes configuration manifests for the deployment in the Kubernetes environment.</p> <p>This diagram shows the system architecture for the reference deployment on AWS.</p> <p></p>","title":"Kubernetes deployment"},{"location":"installation/system-deployment/#tower-modules","text":"<p>The application is composed of a number of modules that can be configured and deployed depending on user requirements.</p> <p>All components are packaged as Docker container images which are hosted and security validated by the Amazon ECR service.</p>","title":"Tower Modules"},{"location":"installation/system-deployment/#backend-module","text":"<p>The backend is implemented as a JVM-based application server based on the Micronaut framework which provides a modern and secure backbone for the application server.</p> <p>The backend module requires OpenJDK 8 or later.</p> <p>The backend layer implements the main application logic organised in a service layer, which is then exposed via a REST API and defined via an OpenAPI schema.</p> <p>The backend module uses JPA/Hibernate/JDBC API industry standards to connect the underlying relational database.</p> <p>The backend is designed to run standalone or as multiple replicas for scalability when deployed in high-availability mode.</p>","title":"Backend module"},{"location":"installation/system-deployment/#frontend-module","text":"<p>The frontend module is composed by Angular 8 application which is served by an Nginx web server.</p> <p>The frontend can be configured to expose the application directly to the user/DMZ via an HTTPS connection or through a load balancer.</p>","title":"Frontend module"},{"location":"installation/system-deployment/#storage","text":"<p>Nextflow Tower requires a relational database as its primary storage.</p> <p>It is suggested to use MySQL 5.6, however, any SQL database compatible with JPA/JDBC industry-standards is supported.</p>","title":"Storage"},{"location":"installation/system-deployment/#caching","text":"<p>Tower provides an optional caching module for configurations requiring high availability.</p> <p>This module requires a Redis 5.0 in-memory database.</p>","title":"Caching"},{"location":"installation/system-deployment/#authentication-module","text":"<p>Nextflow Tower supports enterprise authentication mechanisms such as OAuth and LDAP.</p> <p>Third-party authority providers and custom single-sign-on flow can be developed depending on exact customer requirements.</p>","title":"Authentication module"},{"location":"installation/system-deployment/#cron-scheduler","text":"<p>Tower implements a cron service which takes care of executing periodical activities, such as sending e-mail notifications and cleaning up.</p> <p>The cron service can be configured to run as an embedded backend service or an independent service.</p>","title":"Cron scheduler"},{"location":"labels/overview/","text":"","title":"Labels"},{"location":"labels/overview/#overview","text":"<p>Use labels to organize your work and filter key information. Labels are free-text annotations that can be applied to pipelines, actions, or workflow runs either during creation or afterward.</p> <p>Labels are workspace specific,each workspace has an independent set of labels), and are not propagated to Nextflow during the workflow execution.</p>","title":"Overview"},{"location":"labels/overview/#create-and-apply-labels","text":"<p>Labels can be created, applied and edited by a workspace maintainer, admin or owner. When applying a label, users can select from existing labels or add new ones on the fly.</p> <p></p>","title":"Create and apply labels"},{"location":"labels/overview/#labels-applied-to-a-pipeline","text":"<p>Warning</p> <p>Labels are applied to elements in a workspace-specific context. This means that labels applied to a shared pipeline in workspace A will not be shown when viewing the pipeline from workspace B.</p>  <p>Labels applied to a pipeline are displayed on the bottom of the pipeline card on the Launchpad screen. To see all labels, hover over a label with the \u201c+\u201d character.</p> <p></p> <p>Apply label to a pipeline when adding a new pipeline or editing existing pipeline.</p> <p>If a label was applied to a pipeline, all workflow runs of this pipeline will inherit the label. If the label applied to the pipeline changes, this change will not be reflected on previously executed workflow runs, it will affect only future workflow runs.</p> <p></p>","title":"Labels applied to a pipeline"},{"location":"labels/overview/#labels-applied-to-an-action","text":"<p>Labels applied to an action are displayed in the action card on the Actions screen. To see all labels, hover over a label with the \u201c+\u201d character.</p> <p>Apply label to action when adding a new action or editing an existing action.</p> <p>If a label was applied to an action, all workflow runs of this pipeline will inherit the label. If the label is applied to the action changes, this change will not be reflected on previously executed workflow runs, it will affect only future workflow runs.</p>","title":"Labels applied to an action"},{"location":"labels/overview/#labels-applied-to-a-workflow-run","text":"<p>Labels applied to a workflow run are displayed in the card on the Workflow runs list screen as well as in the Workflow run detail screen. To see all labels, hover over a label with the \u201c+\u201d character. Apply a label to workflow run at any moment, when launching a workflow run, as well as in the Workflow runs list screen or Workflow run detail screen.</p> <p></p>","title":"Labels applied to a workflow run"},{"location":"labels/overview/#search-and-filter-with-labels","text":"<p>Search and filter pipelines and workflow runs using one or more labels. Filter and search are complementary.</p> <p></p>","title":"Search and filter with labels"},{"location":"labels/overview/#overview-of-labels-in-a-workspace","text":"<p>All labels used in a workspace can be viewed, added, edited, and deleted by a maintainer, admin, or workspace owner in the workspace\u2019s Setting screen. If a label is edited or deleted in this screen, the change is propagated to all items where the label was used. Such a change is irreversible</p> <p></p>","title":"Overview of labels in a workspace"},{"location":"labels/overview/#limits","text":"<p>Warning</p>  <p>Label names must contain a minimum of 2 and a maximum of 39 alphanumeric characters, separated by dashes or underscores, and must be unique in each workspace</p> <ul> <li>Label names cannot begin or end with dashes <code>-</code> or underscores <code>_</code>.</li> <li>Label names cannot contain a consecutive combination of <code>-</code> or <code>_</code> characters (<code>--</code>, <code>__</code>, <code>-_</code>, etc.)</li> <li>A maximum of 25 labels can be applied to each resource.</li> <li>A maximum of 100 labels can be used in each workspace.</li> </ul>","title":"Limits"},{"location":"launch/advanced/","text":"<p>Advanced launch options allow users to modify the configuration and execution of the pipeline.</p>","title":"Advanced options"},{"location":"launch/advanced/#nextflow-config-file","text":"<p>The Nextflow config field allows the addition of settings to the Nextflow configuration file.</p> <p>This text should follow the same syntax as the Nextflow configuration file.</p> <p>In the example below, we can modify the manifest section to give the pipeline a name and description which will show up in the Tower monitoring section.</p> <p></p>","title":"Nextflow config file"},{"location":"launch/advanced/#pre-post-run-scripts","text":"<p>It is possible to run custom code either before or after the execution of the Nextflow script. These fields allow users to enter shell commands.</p>","title":"Pre &amp; post-run scripts"},{"location":"launch/advanced/#pull-latest","text":"<p>Enabling this option ensures Nextflow pulls the latest version from the Git repository. This is equivalent to using the <code>-latest</code> flag.</p> <p></p>","title":"Pull latest"},{"location":"launch/advanced/#main-script","text":"<p>Nextflow will attempt to run the script named <code>main.nf</code> in the project repository by default. This can be changed via either the <code>manifest.mainScript</code> option or by providing the script filename to run in this field.</p>","title":"Main script"},{"location":"launch/advanced/#workflow-entry-name","text":"<p>Nextflow DSL2 provides the ability to launch specific-named workflows. Enter the name of the workflow to be executed in this field.</p>","title":"Workflow entry name"},{"location":"launch/launch/","text":"","title":"Launch form"},{"location":"launch/launch/#pipeline-launch-form","text":"<p>The Launch Form can be used for launching pipelines and for adding pipelines to the Launchpad.</p> <p>To launch a pipeline:</p> <ol> <li> <p>Select Start Quick Launch in the navigation bar. The Launch Form will appear.</p> </li> <li> <p>Select a Compute Environment from the available options.</p> </li> </ol> <p>Visit the Compute Environment documentation to learn how to create an environment for your preferred execution platform.</p> <ol> <li>Enter a repository URL for the Pipeline to launch (e.g. <code>https://github.com/nf-core/rnaseq.git</code>).</li> </ol>   <p>Tip</p> <p>Nextflow pipelines are just Git repositories and they can reside on any public or private Git-hosting platform. See Git Integration in the Tower docs and Pipeline Sharing in the Nextflow docs for more details.</p>  <ol> <li>You can select a Revision number to use a specific version of the pipeline.</li> </ol> <p>The Git default branch (e.g. <code>main</code> or <code>master</code>) or <code>manifest.defaultBranch</code> in the Nextflow configuration will be used by default.</p> <ol> <li>Enter the Work directory, which corresponds to the Nextflow work directory.</li> </ol> <p>The default work directory of the compute environment will be used by default.</p>   <p>Warning</p> <p>The credentials associated with the compute environment must be able to access the work directory (e.g. an S3 bucket).</p>  <ol> <li> <p>Select any Config profiles you would like to use.</p> <p>Visit the Nextflow Config profiles documentation for more details.</p> </li> <li> <p>Enter any Pipeline parameters in YAML or JSON format.</p> <pre>1\n2\n3\n4\n5</pre><pre><code>YAML example:\n```yaml\nreads: 's3://nf-bucket/exome-data/ERR013140_{1,2}.fastq.bz2'\npaired_end: true\n```\n</code></pre> </li> </ol>   <p>Tip</p> <p>In YAML, quotes should be used for paths but not for numbers or Booleans.</p>  <ol> <li>Select Launch to launch the pipeline.</li> </ol>","title":"Pipeline launch form"},{"location":"launch/launchpad/","text":"","title":"Launchpad"},{"location":"launch/launchpad/#overview","text":"<p>Launchpad makes it easy for any workspace user to launch a pre-configured pipeline.</p> <p></p> <p>A pipeline is a repository containing a Nextflow workflow, a compute environment, and pipeline parameters.</p>","title":"Overview"},{"location":"launch/launchpad/#pipeline-parameters-form","text":"<p>Launchpad automatically detects the presence of a <code>nextflow_schema.json</code> in the root of the repository and dynamically creates a form where users can easily update the parameters.</p>   <p>Tip</p> <p>The parameter forms view will appear if the workflow has a Nextflow schema file for the parameters. Please refer to the Nextflow Schema guide to learn more about the use cases and how to create them.</p>  <p>This makes it trivial for users without any expertise in Nextflow to enter their pipeline parameters and launch.</p> <p></p>","title":"Pipeline Parameters Form"},{"location":"launch/launchpad/#adding-a-new-pipeline","text":"<p>Adding a pipeline to the workspace launchpad is similar to the Launch except, instead of launching the pipeline, it gets added to the list of pipelines with the pre-saved values of fields, such as the pipeline parameters and the revision number.</p>   <p>Tip</p> <p>To create your own customized Nextflow Schema for your pipeline, see the <code>nf-core</code> workflows that have adopted this.  nf-core/eager and nf-core/rnaseq are excellent examples.</p>","title":"Adding a New Pipeline"},{"location":"launch/notifications/","text":"","title":"Notifications"},{"location":"launch/notifications/#email-notifications","text":"<p>You can receive email notifications at the completion or a failure of a workflow execution.</p> <p>Navigate to your profile page using dropdown on your avatar in the top-right of the page. Select the Send notification email on workflow completion toggle option at the bottom of the profile settings page.</p> <p></p>","title":"Email Notifications"},{"location":"launch/relaunch/","text":"<p>Re-launching pipelines is a great way to quickly troubleshoot or make use of Nextflow's resume functionality and re-launch the same pipeline with different parameters.</p> <p>The Resume option is selected by default when re-launching a new pipeline from the Runs monitoring screen. In short, This option allows for the continuation of a workflow execution using Nextflow resume.</p>   <p>Nextflow resume</p> <p>For a detailed explanation of how the resume option works, please visit Part 1 and Part 2 of the Demystifying Nextflow resume description in the Nextflow blog.</p>","title":"Re-launching pipelines"},{"location":"launch/relaunch/#change-compute-environment-when-resuming-a-run","text":"<p>Available from Tower 22.4.0</p> <p>Users with appropriate permissions can change the compute environment when resuming a run. The new compute environment must have access to the original run work directory. This means that the new compute environment must have a work directory that matches the root path of the original pipeline work directory, e.g. if the original pipeline work directory is <code>s3://foo/work/12345</code>, the new compute environment must have access to <code>s3://foo/work</code>.</p>","title":"Change compute environment when resuming a run"},{"location":"limits/limits/","text":"<p>Tower Cloud elements and features have default limits per workspace and organization.</p>","title":"Usage limits"},{"location":"limits/limits/#workspaces","text":"Description Value     Active runs 5   Members 50   Participants 50   Pipelines 100   Datasets 100   Labels 1000","title":"Workspaces"},{"location":"limits/limits/#organizations","text":"Description Value     Workspaces 50   Teams 20","title":"Organizations"},{"location":"limits/limits/#datasets","text":"Description Value     File size 10 MB   Versions per dataset 100    <p>If you need higher limits and capabilities, contact us to discuss your application requirements.</p>","title":"Datasets"},{"location":"monitoring/aggregate_stats/","text":"<p>The Aggregate stats panel displays a real-time summary of the resources used by the workflow. These include total running time ('wall time'), aggregated CPU time (CPU hours), memory usage (GB hours), data i/o and cost.</p>","title":"Aggregate stats & load"},{"location":"monitoring/aggregate_stats/#estimated-cost","text":"<p>Note that the cost estimate in Tower is a heuristic estimation of computation-only cost and is not intended to be a replacement for your cloud provider tooling (such as AWS Cost Explorer). Tower uses a database of costs for all cloud instances of AWS and Google Cloud in all regions and zones. This estimate does not currently take storage or associated network costs into account.</p> <p>The addition of Resource labels to your compute environments provides additional cost tracking through annotation of the actual cloud resources consumed by a run.</p> <p></p>","title":"Estimated cost"},{"location":"monitoring/aggregate_stats/#load-and-utilization","text":"<p>As processes are being submitted to the compute environment, the Load monitors how many cores and tasks are currently being used. For the cores gauge chart, the denominator is the maximum number of cores that have already been used at that moment during the execution of that specific pipeline.</p> <p>Utilization is calculated for memory and CPUs. This is the average value across all tasks and is calculated by dividing the memory (or CPUs) usage by the memory (or CPUs) requested.</p> <p></p>","title":"Load and Utilization"},{"location":"monitoring/execution/","text":"","title":"Execution details & logs"},{"location":"monitoring/execution/#run-execution-details","text":"<p>Selecting a workflow run from the Runs tab will display the workflow details. This view contains:</p> <ul> <li>Run information with command-line, parameters, configuration, and execution logs in real-time.</li> <li>Summary and status section.</li> <li>List of pipeline processes.</li> <li>Aggregated stats and load.</li> <li>Detailed list of individual tasks and metrics.</li> </ul>","title":"Run execution details"},{"location":"monitoring/execution/#run-information","text":"<p>This section is composed of several tabs containing details about the Nextflow execution:</p> <ul> <li> <p>The Nextflow Command line that was executed.</p> </li> <li> <p>The Parameters that were provided to the pipeline (taken from the configuration <code>params</code> scope).</p> </li> <li> <p>The Configuration files as well as the final resolved configuration.</p> </li> <li> <p>The Execution log from the main Nextflow process, which is updated in real time.</p> </li> </ul> <p></p>","title":"Run information"},{"location":"monitoring/overview/","text":"<p>Jobs that have been submitted with Tower can be monitored wherever you have an internet connection.</p> <p>The Runs tab contains all previous jobs executions. Each new or resumed job will be given a random name e.g: <code>grave_williams</code>.</p> <p></p> <p>The colors signify the completion status:</p> <ul> <li>Blue are running.</li> <li>Green are successfully executed.</li> <li>Red are successfully executed where at least one task failed with a \"terminate\" error strategy.</li> <li>Grey are jobs that were forced to stop during execution.</li> </ul> <p>Selecting any particular run from the panel will display that run's execution details.</p>","title":"Overview"},{"location":"monitoring/overview/#all-runs-view","text":"<p>Available from version 22.4.0</p> <p>The All runs page, accessed from the top right avatar menu, provides a comprehensive overview of the runs accessible to a user across the entire Tower instance. This facilitates overall status monitoring and early detection of execution issues from a single view split across organizations and workspaces.</p>","title":"All runs view"},{"location":"monitoring/overview/#search","text":"<p>Our integrated search covers all workflow runs inside a workspace, enabling easy retrieval of complex queries. To search and filter the runs in a workspace, the user can write a search query in the \"Search workflow\" textbox.</p> <p>The search text is interpreted by identifying all substrings formatted by <code>keyword:value</code> (this only applies to valid keywords shown below), combining all the rest in a single <code>Freetext</code> string, and then using all these search criteria to filter the runs.</p> <p>An example of a complex search query is the following:</p> <p><code>rnaseq username:john_doe status:succeeded after:2022-02-20</code>.</p> <p>This string will retrieve all runs from the workspace that:</p> <ul> <li>Ended successfully (<code>status:succeeded</code>)</li> <li>AND have been launched by user john_doe (<code>username:john_doe</code>)</li> <li>AND include \"rnaseq\" in the data fields covered by the free text search (e.g. the run name includes rnaseq)</li> <li>AND were submitted after February 20, 2022.</li> </ul> <p>The freetext search uses a partial match to find runs, meaning that it will search for \"<code>*freetext*</code>\" when looking for runs. The <code>keyword:value</code> item, instead use exact match to filter runs, so <code>username:john</code> will not retrieve runs launched by <code>john_doe</code></p>   <p>Warning</p> <p>The implemented logic combines all filtering elements with AND logic. This means that queries like <code>status:succeeded, status:submitted</code> are formally valid but will return and empty list because a workflow can only have one status.</p>    <p>Warning</p> <p>The freetext resulting after identifying all the <code>keyword:value</code> are merged into a unique string including spaces, which may result in an empty list of results if there are typos.</p>    <p>Note</p> <p>Keywords corresponding to dates (e.g. <code>after</code> or <code>before</code>) automatically convert the input date to valid ISO-8601, taking into account the user's timezone. Partial dates are also supported e.g. <code>before:2022-5</code> will automatically be converted to <code>before:2022-05-01T00:00:00.000Z</code> under the hood.</p>  <p>Tower will automatically auto-suggest matching keywords while you type into the search bar. Additionally it will suggest valid values for some keywords, when supported. </p>","title":"Search"},{"location":"monitoring/overview/#search-keywords","text":"","title":"Search keywords"},{"location":"monitoring/overview/#free-text","text":"<ul> <li>The search box allows searching for workflows by partial match with <code>project name</code>, <code>run name</code>, <code>session id</code> or <code>manifest name</code>. Moreover, wildcards can be used to filter the desired workflows such as using asterisks <code>*</code> before and after keyword to filter results.</li> </ul>","title":"Free text"},{"location":"monitoring/overview/#exact-match-keywords","text":"<ul> <li> <p><code>worlflowId:&lt;id&gt;</code>: search a workflow by its <code>id</code>.</p> <p>E.g: <code>workflowId:3b7ToXeH9GvESr</code></p> </li> <li> <p><code>runName:&lt;name&gt;</code>: search with a specific <code>run name</code>.</p> <p>E.g: <code>runName:happy_einstein</code></p> </li> <li> <p><code>sessionId:&lt;id&gt;</code>: search workflows with a specific <code>session id</code>.</p> <p>E.g: <code>sessionId:85d35eae-21ea-4294-bc92-e35a60efa1a4</code></p> </li> <li> <p><code>projectName:&lt;name&gt;</code>: search workflows with a specific <code>project name</code>.</p> <p>E.g: <code>projectName:nextflow-io/hello</code></p> </li> <li> <p><code>userName:&lt;name&gt;</code>: search workflows by a specific <code>user name</code>.</p> <p>E.g: <code>userName:john_doe</code></p> </li> <li> <p><code>status:&lt;value&gt;</code>: search workflows with a specific <code>status</code> (<code>submitted</code>, <code>running</code>, <code>succeeded</code>, <code>failed</code>, <code>cancelled</code>, <code>unknown</code>).</p> <p>E.g: <code>status:succeeded</code></p> </li> <li> <p><code>before:&lt;date&gt;</code>: search workflows submitted before the given date (<code>YYYY-MM-DD</code> format), this includes the specified date.</p> <p>E.g: <code>before:2022-04-07</code></p> </li> <li> <p><code>after:&lt;date&gt;</code>: search workflows submitted after the given date (<code>YYYY-MM-DD</code> format), this includes the specified date.</p> <p>E.g: <code>after:2022-04-06</code></p> </li> <li> <p><code>label:&lt;name&gt;</code>: search workflows with a specific label (combine multiple label keywords in order to search workflows associated with all of those labels).</p> <p>E.g: <code>label:label1 label:label2</code></p> </li> <li> <p><code>is:starred</code>: search workflows that have been starred by the user.   E.g: <code>is:starred</code></p> </li> </ul> <p></p>","title":"Exact match keywords"},{"location":"monitoring/processes/","text":"<p>In Nextflow, a process is the basic primitive to execute a block of code. The Processes section shows all processes and the status of the tasks.</p> <p>In the example below, there are four tasks of the fastqc process.</p> <p></p> <p>By selecting a process, the Tasks table is filtered below.</p>","title":"Processes"},{"location":"monitoring/summary/","text":"","title":"Summary & status"},{"location":"monitoring/summary/#general","text":"<p>The General summary displays information on the environment and the job being executed:</p> <ul> <li>Unique workflow run ID</li> <li>Workflow run name</li> <li>Date and time of job submission timestamp</li> <li>Project revision and Git commit ID</li> <li>Nextflow session ID</li> <li>Username of the launcher</li> <li>Work directory path</li> <li>Container image</li> <li>Executor</li> <li>Compute environment details</li> <li>Nextflow version</li> </ul>   <p>Tip</p> <p>Hover over with the mouse to get full details on the compute environment.</p>  <p></p>","title":"General"},{"location":"monitoring/summary/#task-status","text":"<p>The Task status section shows in real time the statuses of your workflow tasks. The panel uses the same colour code as the pipelines in the navigation bar.</p> <p>The exact meaning of each status is dependant on the execution platform.</p> <p></p>","title":"Task status"},{"location":"monitoring/tasks/","text":"","title":"Tasks & metrics"},{"location":"monitoring/tasks/#task-table","text":"<p>The Tasks section shows all the tasks from an execution.</p> <p>You can use the <code>Search</code> bar to filter tasks by process name, tag, hash, status, etc.</p> <p>Selecting a status in status section filters the task table. E.g. clicking in the CACHED card in the status column.</p> <p></p> <p>Selecting a <code>process</code> in the Processes section above will filter all tasks for that specific process.</p> <p></p> <p>Selecting a task in the task table provides specific information about the task in the Task details dialog.</p> <p></p> <p>The task details dialog has the task information tab and the task Execution log tab.</p>","title":"Task table"},{"location":"monitoring/tasks/#task-information","text":"<p>The task information tab contains the process name and task tag in the title. The tab includes:</p> <ul> <li>Command</li> <li>Status</li> <li>Work directory</li> <li>Environment</li> <li>Execution time</li> <li>Resources requested</li> <li>Resources used</li> </ul> <p></p>","title":"Task information"},{"location":"monitoring/tasks/#execution-log","text":"<p>The Execution log provides a realtime log of the individual task of a Nextflow execution.</p> <p>This can be very helpful for troubleshooting. It is possible to download the log files including <code>stdout</code> and <code>stderr</code> from your compute environment.</p> <p></p>","title":"Execution log"},{"location":"monitoring/tasks/#resource-metrics","text":"<p>This section displays plots with CPU, memory, task duration and I/O usage, grouped by process.</p> <p>These metrics can be used to profile an execution to ensure that the correct amount or resources are being requested for each process.</p> <p></p>   <p>Tip</p> <p>Hover the mouse over the box plots to display more details.</p>","title":"Resource metrics"},{"location":"orgs-and-teams/organizations/","text":"","title":"Organizations"},{"location":"orgs-and-teams/organizations/#overview","text":"<p>Organizations are the top-level structure and contain Workspaces, Members, Teams, and Collaborators.</p>","title":"Overview"},{"location":"orgs-and-teams/organizations/#create-an-organization","text":"<p>To create a new organization:</p> <ol> <li> <p>Navigate to Your organizations and select Add Organization.</p> </li> <li> <p>Enter a Name and Full name for your organization.</p>  <p>Warning</p> <p>The organization name must follow a specific pattern. Refer to the UI for guidance.</p>  </li> <li> <p>Enter any other optional fields as needed: Description, Location, Website URL and Logo.</p> </li> <li> <p>Select Add.</p> </li> </ol> <p>You can view the list of all Members, Teams, and Collaborators in an organization on the organization's page. You can also edit any of the optional fields by selecting Edit from the organizations page or by selecting the Settings tab from the organization's page, provided that you are an Owner of the organization.</p>","title":"Create an organization"},{"location":"orgs-and-teams/organizations/#members","text":"<p>Once an organization is created, the user who created the organization is the default owner of that organization. It is also possible to invite or add other members as well.</p> <p>Tower provides access control for members of an organization by classifying them either as an Owner or a Member. Each organization can have multiple owners and members.</p>  <p>Note</p> <p>Owners have full read/write access to modify members, teams, collaborators, and settings within a organization. Members are limited in their actions.</p>","title":"Members"},{"location":"orgs-and-teams/organizations/#create-a-new-member","text":"<p>To add a new member to an organization:</p> <ol> <li>Go to the Members tab of the organization menu</li> <li>Click on Invite member</li> <li>Enter the email ID of user you'd like to add to the organization</li> </ol> <p>An e-mail invitiation will be sent which needs to be accepted by the user. Once they accept the invitation, they can switch to the organization (or organization workspace) using their workspace dropdown.</p>","title":"Create a new member"},{"location":"orgs-and-teams/organizations/#collaborators","text":"<p>Collaborators are users who are invited to an organization's workspace, but are not members of that organization. As a result, their access is limited to only within that workspace.</p> <p>New collaborators to an organization's workspace can be added using Participants. To learn more about the various available access levels for Participants, please refer to the participant roles section.</p>  <p>Note</p> <p>Collaborators can only be added from a workspace. For more information, see workspace management.</p>","title":"Collaborators"},{"location":"orgs-and-teams/organizations/#teams","text":"<p>Teams allow the organization owners to group members and collaborators together into a single unit and to manage them as a whole.</p>","title":"Teams"},{"location":"orgs-and-teams/organizations/#create-a-new-team","text":"<p>To create a new team within an organization:</p> <ol> <li>Go to the Teams tab of the organization menu</li> <li>Click on New team</li> <li>Enter the Name of team</li> <li>Optionally, add the Description and the team's Avatar</li> <li>For the newly created team, click on View</li> <li>Click on Add team member and type in the name of the organization members or collaborators</li> </ol>","title":"Create a new team"},{"location":"orgs-and-teams/overview/","text":"","title":"Overview"},{"location":"orgs-and-teams/overview/#overview","text":"<p>Nextflow Tower simplifies the development and execution of workflows by providing a centralized interface for managing users and resources, while providing ready-to-launch workflows for users. This is achieved through the context of workspaces.</p>","title":"Overview"},{"location":"orgs-and-teams/overview/#organization-resources","text":"<p>Tower allows the creation of multiple organizations, each of which can contain multiple workspaces with shared users and resources. This allows any organization to customize and organize the usage of resources while maintaining an access control layer for users associated with a workspace.</p> <ul> <li> <p>For further information on organizations, see Organizations.</p> </li> <li> <p>For further information on organization workspaces, see Workspace management.</p> </li> </ul>","title":"Organization resources"},{"location":"orgs-and-teams/overview/#organization-users","text":"<p>Any user can be added or removed from an organization or workspace and can be allocated a specific access role within that workspace.</p> <p>Teams provide a way for organizations to group users and participants together into teams, such as <code>workflow-developers</code> or <code>analysts</code>, and apply access control for all users within this team.</p> <p>For further information on user and team creation, see User management.</p>","title":"Organization users"},{"location":"orgs-and-teams/shared-workspaces/","text":"","title":"Shared workspaces"},{"location":"orgs-and-teams/shared-workspaces/#overview","text":"<p>Nextflow Tower introduces the concept of shared workspaces as a solution for synchronization and resource sharing within an organization.</p> <p>A shared workspace enables the creation of pipelines in a centralized location, making them accessible to all members of an organization.</p> <p>The benefits of using a shared workspace within an organization include:</p> <ul> <li> <p>Define once and share everywhere: Set up shared resources once and automatically share them across the organization.</p> </li> <li> <p>Centralize the management of key resources: Organization administrators can ensure the correct pipeline configuration is used in all areas of an organization without needing to replicate pipelines across multiple workspaces.</p> </li> <li> <p>Immediate update adoption: Updated parameters for a shared pipeline become immediately available across the entire organization, reducing the risk of pipeline discrepancies.</p> </li> <li> <p>Computational resource provision: Pipelines in shared workflows can be shared along with the required computational resources. This eliminates the need to duplicate resource setup in individual workspaces across the organization. Shared workspaces in Tower centralize and simplify resource sharing within an organization.</p> </li> </ul>","title":"Overview"},{"location":"orgs-and-teams/shared-workspaces/#create-a-shared-workspace","text":"<p>Creating a shared workspace is similar to the creation of a private workspace, with the exception of the Visibility option, which must be set to Shared.</p> <p></p>","title":"Create a shared workspace"},{"location":"orgs-and-teams/shared-workspaces/#create-a-shared-pipeline","text":"<p>When creating a pipeline within a shared workspace, associating it with a compute environment is optional.</p> <p>If a compute environment from the shared workspace is associated with the pipeline, it will be available to users in other workspaces who can launch the shared pipeline using the provided environment by default.</p>","title":"Create a shared pipeline"},{"location":"orgs-and-teams/shared-workspaces/#use-shared-pipelines-from-a-private-workspace","text":"<p>Once a pipeline is set up in a shared workspace and associated with a compute environment within that shared workspace, any user can launch the pipeline from a private workspace using the shared workspace's compute environment. This eliminates the need for users to replicate shared compute environments in their private workspaces.</p>   <p>Note</p> <p>The shared compute environment will not be available to launch other pipelines limited to that specific private workspace.</p>  <p>If a pipeline from a shared workspace is shared without an associated compute environment, users from other workspaces can run it from their local workspaces. By default, the primary compute environment of the local workspace will be selected.</p>","title":"Use shared pipelines from a private workspace"},{"location":"orgs-and-teams/shared-workspaces/#make-shared-pipelines-visible-in-a-private-workspace","text":"<p>To view pipelines from shared workspaces, set the Filter -&gt; Pipelines from option to This and shared workspaces on the Launchpad.</p>   <p>Note</p> <p>Currently, the pipelines from all shared workspaces are visible when the visibility is set to \"Shared workspaces\".</p>  <p></p>","title":"Make shared pipelines visible in a private workspace"},{"location":"orgs-and-teams/workspace-management/","text":"","title":"Workspace management"},{"location":"orgs-and-teams/workspace-management/#overview","text":"<p>Organization workspaces extend the functionality of user workspaces by adding the ability to fine-tune access levels for specific members, collaborators, or teams. This is achieved by managing participants in the organization workspaces.</p> <p>Organizations consist of members, while workspaces consist of participants.</p>   <p>Note</p> <p>A workspace participant may be a member of the workspace organization or a collaborator within that workspace only. Collaborators count toward the total number of workspace participants. See Usage limits.</p>","title":"Overview"},{"location":"orgs-and-teams/workspace-management/#create-a-new-workspace","text":"<p>Organization owners and admins can create a new workspace within an organization:</p> <ol> <li>Go to the Workspaces tab of the organization page.</li> <li>Select Add Workspace.</li> <li>Enter the Name and Full name for the workspace.</li> <li>Optionally, add a Description for the workspace.</li> <li>Under Visibility, select either Private or Shared. Private visibility means that workspace pipelines are only accessible to workspace participants.</li> <li>Select Add.</li> </ol>   <p>Tip</p> <p>Optional workspace fields can be modified after workspace creation, either by using the Edit option on the workspace listing for an organization or by accessing the Settings tab within the workspace page, provided that you are the Owner of the workspace.</p>  <p>Apart from the Participants tab, the organization workspace is similar to the user workspace. As such, the relation to runs, pipeline actions, compute environments and credentials is the same.</p>","title":"Create a new workspace"},{"location":"orgs-and-teams/workspace-management/#add-a-new-participant","text":"<p>To add a new participant to a workspace:</p> <ol> <li>Go to the Participants tab in the workspace menu.</li> <li>Select Add participant.</li> <li>Enter the Name of the new participant.</li> <li>Optionally, update the participant role. For more information on roles, see participant roles.</li> </ol>   <p>Tip</p> <p>A new workspace participant can be an existing organization member, team, or collaborator.</p>","title":"Add a new participant"},{"location":"orgs-and-teams/workspace-management/#participant-roles","text":"<p>Organization owners can assign role-based access levels to any of the workspace participants in an organization workspace.</p>   <p>Hint</p> <p>It is also possible to group members and collaborators into teams and apply a role to that team. Members and collaborators inherit the access role of the team.</p>  <p>There are five roles available for every workspace participant.</p> <ol> <li> <p>Owner: The participant has full permissions for all resources within the workspace, including the workspace settings.</p> </li> <li> <p>Admin: The participant has full permissions for resources associated with the workspace. They can create, modify, and delete pipelines, compute environments, actions, and credentials. They can add or remove users from the workspace but cannot access the workspace settings.</p> </li> <li> <p>Maintain: The participant can launch pipelines and modify pipeline executions (e.g., they can change the pipeline launch compute environments, parameters, pre/post-run scripts, and Nextflow configuration) and create new pipelines in the Launchpad. Users with maintain permissions cannot modify compute environments and credentials.</p> </li> <li> <p>Launch: The participant can launch pipelines and modify the pipeline input/output parameters in the Launchpad. They cannot modify the launch configuration or other resources.</p> </li> <li> <p>View: The participant can view workspace pipelines and runs in read-only mode.</p> </li> </ol>","title":"Participant roles"},{"location":"orgs-and-teams/workspace-management/#workspace-run-monitoring","text":"<p>To allow users executing pipelines from the command-line to share their runs with a given workspace, see Getting started.</p>","title":"Workspace run monitoring"},{"location":"pipeline-actions/overview/","text":"","title":"Pipeline actions"},{"location":"pipeline-actions/overview/#overview","text":"<p>Pipeline actions allow launching of pipelines based on events.</p> <p>Tower currently offers support for native GitHub webhooks and a general Tower webhook that can be invoked programmatically. Support for Bitbucket and GitLab are coming soon.</p>","title":"Overview"},{"location":"pipeline-actions/overview/#github-webhooks","text":"<p>A GitHub webhook listens for any changes made in the pipeline repository. When a change occurs, Tower triggers the launch of the pipeline automatically.</p> <p>To create a new Pipeline action, select the Actions tab and select Add Action.</p> <ol> <li> <p>Enter a Name for your Action.</p> </li> <li> <p>Select GitHub webhook as the Event source.</p> </li> </ol> <p></p> <ol> <li> <p>Select the Compute environment where the pipeline will be executed.</p> </li> <li> <p>Select the Pipeline to launch and (optionally) the Revision number.</p> </li> <li> <p>Enter the Work directory, the Config profiles, and the Pipeline parameters.</p> </li> <li> <p>Select Add.</p> </li> </ol> <p></p> <p>The pipeline action is now setup. When a new commit occurs for the selected repository and revision, an event will be triggered in Tower and the pipeline will be launched.</p> <p></p>","title":"GitHub webhooks"},{"location":"pipeline-actions/overview/#tower-launch-hooks","text":"<p>A Tower launch hook creates a custom endpoint URL which can be used to trigger the execution of your pipeline programmatically from a script or web service.</p> <p>To create a new Pipeline action, select the Actions tab and select Add Action.</p> <ol> <li> <p>Enter a Name for your Action.</p> </li> <li> <p>Select Tower launch hook as the event source.</p> </li> </ol> <p></p> <ol> <li> <p>Select the Compute environment to execute your pipeline.</p> </li> <li> <p>Enter the Pipeline to launch and (optionally) the Revision number.</p> </li> <li> <p>Enter the Work directory, the Config profiles, and the Pipeline parameters.</p> </li> <li> <p>Select Add.</p> </li> </ol> <p></p> <p>The pipeline action has been created, and the new endpoint can be used to programmatically launch the corresponding pipeline. The snippet below shows an example <code>curl</code> command with the authentication token.</p> <p></p> <p>When you create a Tower launch hook, you also create an access token for launching pipelines through Tower. Access tokens can be managed on the tokens page, which is also accessible from the navigation menu.</p> <p></p>","title":"Tower launch hooks"},{"location":"pipeline-schema/overview/","text":"","title":"Pipeline schema"},{"location":"pipeline-schema/overview/#overview","text":"<p>Pipeline schema files describe the structure and validation constraints of your workflow parameters. They are used to validate parameters before launch to prevent software or pipelines from failing in unexpected ways at runtime.</p> <p>You can populate the parameters in the pipeline by uploading a YAML or JSON file, or in the Tower UI. Tower uses your pipeline schema to build a bespoke launchpad parameters form.</p> <p>See nf-core/rnaseq as an example of the pipeline parameters that can be represented by a JSON schema file.</p>","title":"Overview"},{"location":"pipeline-schema/overview/#building-pipeline-schema-files","text":"<p>The pipeline schema is based on json-schema.org syntax, with some additional conventions. While you can create your pipeline schema manually, we highly recommmend the use of nf-core tools, a toolset for developing Nextflow pipelines built by the nf-core community.</p> <p>When you run the <code>nf-core schema build</code> command in your pipeline root directory, the tool collects your pipeline parameters and gives you interactive prompts about missing or unexpected parameters. If no existing schema file is found, the tool creates one for you. <code>schema build</code> commands include the option to validate and lint your schema file according to best practice guidelines from the nf-core community.</p>","title":"Building pipeline schema files"},{"location":"pipeline-schema/overview/#customizing-pipeline-schema","text":"<p>Once the skeleton pipeline schema file has been built with <code>nf-core schema build</code>, the command line tool will prompt you to open a graphical schema editor on the nf-core website.</p> <p></p> <p>Leave the command-line tool running in the background - it checks the status of your schema on the website. When you select Finished on the schema editor page, your changes are saved to the schema file locally.</p>   <p>Note</p> <p>The schema builder is created by the nf-core community, but can be used any Nextflow pipeline.</p>","title":"Customizing pipeline schema"},{"location":"reports/overview/","text":"","title":"Pipeline reports"},{"location":"reports/overview/#overview","text":"<p>Most Nextflow pipelines will generate reports or output files which are useful to inspect at the end of the pipeline execution. Reports may be in various formats (e.g. HTML, PDF, TXT) and would typically contain quality control (QC) metrics that would be important to assess the integrity of the results. Tower has a Reports feature that allows you to directly visualise supported file types or to download them directly via the user interface (see Limitations). This saves users the time and effort from having to retrieve and visualise output files from their local storage.</p>","title":"Overview"},{"location":"reports/overview/#visualizing-reports","text":"<p>Available reports are listed in a Reports tab within the Runs page. Users can select a report from the table and open or download it (see Limitations for supported file types and sizes).</p> <p></p> <p>To open a report preview, the file must be smaller than 10MB.</p> <p></p> <p>Users can download a report directly from Tower or using the path. Download is not available if a report is larger than 25 MB. Option to download from path is suggested instead.</p> <p></p>","title":"Visualizing Reports"},{"location":"reports/overview/#providing-reports","text":"<p>To render reports users need to create a Tower config file that defines the paths to a selection of output files published by the pipeline. There are 2 ways users can provide the Tower config file both of which have to be in YAML format:</p> <ol> <li>Pipeline repository: If a file called tower.yml exists in the root of the pipeline repository then this will be fetched automatically before the pipeline execution.,</li> <li>Tower UI: Providing the YAML definition within the Advanced options &gt; Tower config file box when:    1.Creating a Pipeline in the Launchpad    2.Amending the Launch settings when launching a Pipeline. Users with Maintain role only.</li> </ol>   <p>Warning</p> <p>Any configuration provided in the Tower UI will completely override that which is supplied via the pipeline repository.</p>  <p></p>","title":"Providing Reports"},{"location":"reports/overview/#reports-implementation","text":"<p>Pipeline Reports need to be specified via YAML syntax</p> <pre>1\n2\n3\n4</pre><pre><code>reports:\n  &lt;path pattern&gt;:\n    display: text to display (required)\n    mimeType: file mime type (optional)\n</code></pre>","title":"Reports implementation"},{"location":"reports/overview/#path-pattern","text":"<p>Only the published files (using the Nextflow <code>publishDir</code> directive) are possible report candidates files. The path pattern is used to match published files to a report entry. It can be a partial path, a glob expression or just a file name.</p> <p>Examples of valid path patterns are:</p> <ul> <li><code>multiqc.html</code>: This will match all the published files with this name.</li> <li><code>**/multiqc.html</code>: This is a glob expression that matches any subfolder. It is equivalent to the previous expression.</li> <li><code>results/output.txt</code>: This will match all the <code>output.txt</code> files inside any results folder.</li> <li><code>*_output.tsv</code>: This will match any file that ends with \u201c_output.tsv\u201d</li> </ul>   <p>Warning</p> <p>When you use <code>*</code> it is important to also use double quotes, otherwise it is not a valid YAML.</p>","title":"Path pattern"},{"location":"reports/overview/#display","text":"<p>Display defines the title that will be shown on the website. If there are multiple files that match the same pattern an automatic suffix will be added. The suffix is the minimum difference between all the matching paths. For example given this report definition:</p> <pre>1\n2\n3</pre><pre><code>reports:\n  \"**/out/sheet.tsv\":\n    display: \"Data sheet\"\n</code></pre> <p>If you have these two paths <code>/workdir/sample1/out/sheet.tsv</code> and <code>/workdir/sample2/out/sheet.tsv</code> both of them will match the path pattern and their final display name will be Data sheet (sample1) and Data sheet (sample2).</p>","title":"Display"},{"location":"reports/overview/#mimetype","text":"<p>By default the mime type is deduced from the file extension, so in general you don\u2019t need to explicitly define it. Optionally, you can define it to force a viewer, for example showing a <code>txt</code> file as a <code>tsv</code>. It is important that it is a valid mime type text, otherwise it will be ignored and the extension will be used instead.</p>","title":"mimeType"},{"location":"reports/overview/#limitations","text":"<p>The current reports implementation limits the rendering to the following formats: HTML, CSV, tsv, pdf, and txt.</p> <p>In-page rendering/report preview is restricted to files smaller than 10MB to reduce the UI overload. Larger files need to be downloaded first.</p> <p>The download is restricted to files smaller than 25 MB to reduce the overload. Larger files need to be downloaded from the path.</p> <p>Currently, there is a YAML formatting validation in place checking both the tower.yml file inside the repository and the UI configuration box. The validation phase will emit an error message when users try to launch a pipeline with non-compliant YAML definitions.</p>","title":"Limitations"},{"location":"resource-labels/overview/","text":"","title":"Resource labels"},{"location":"resource-labels/overview/#overview","text":"<p>From version 22.3.0, Tower supports applying resource labels to compute environments and other Tower elements. This offers a flexible tagging system for annotation and tracking of the cloud services consumed by a run. Resource labels are sent to the service provider for each cloud compute environment in <code>key=value</code> format.</p> <p>Resource labels are applied to Tower elements during:</p> <ul> <li>compute environment creation with Forge</li> <li>submission</li> <li>and execution</li> </ul>","title":"Overview"},{"location":"resource-labels/overview/#create-and-apply-labels","text":"<p>Resource labels can be created, applied, and edited by a workspace admin or owner. When applying a label, users can select from existing labels or add new labels on the fly.</p> <p></p>","title":"Create and apply labels"},{"location":"resource-labels/overview/#resource-labels-applied-to-a-compute-environment","text":"<p>Admins can assign a set of resource labels when creating a compute environment. All runs executed using the compute environment will be tagged with its resource labels. Resource labels applied to a compute environment are displayed on the compute environment details page.</p> <p></p> <p>Apply a label when adding a new compute environment to the workspace.</p>   <p>Warning</p> <p>Once the compute environment has been created, its resource labels cannot be edited.</p>  <p>If a resource label is applied to a compute environment, all runs in that compute environment will inherit it. Likewise, all cloud resources generated during the workflow execution will be tagged with the same resource label.</p>","title":"Resource labels applied to a compute environment"},{"location":"resource-labels/overview/#resource-labels-applied-to-pipelines-actions-and-runs","text":"<p>Available from version 22.4.0</p> <p>Admins can override the default resource labels inherited from the compute environment when creating and editing pipelines, actions, and runs on the fly. The custom resource labels associated with each Tower element will propagate to the associated resources in the cloud environment without altering the default resource labels associated with the compute environment in Tower.</p> <p>When an admin adds or edits the resource labels associated with a pipeline, action, or run, the submission and execution time resource labels are altered. This does not affect the resource labels for resources spawned at (compute environment) creation time.</p> <p>For example, the resource label <code>name=ce1</code> is set during AWS Batch compute environment creation. If you create the resource label <code>pipeline=pipeline1</code> while creating a pipeline which uses the same AWS Batch compute environment, the EC2 instances associated with that compute environment still contain only the label <code>name=ce1</code>, while the Job Definitions associated with the pipeline will inherit the <code>pipeline=pipeline1</code> resource label.</p> <p>If a maintainer changes the compute environment associated with a pipeline or run, the resource labels field is updated with the resource labels from the new compute environment.</p> <p></p>","title":"Resource labels applied to pipelines, actions, and runs"},{"location":"resource-labels/overview/#search-and-filter-with-labels","text":"<p>Search and filter pipelines and runs using one or more resource labels. The resource label search uses a <code>label:key=value</code> format.</p> <p></p>","title":"Search and filter with labels"},{"location":"resource-labels/overview/#overview-of-resource-labels-in-a-workspace","text":"<p>All resource labels used in a workspace can be viewed in the workspace\u2019s Settings screen. Resource labels can only be edited or deleted by admins and only if they are not already associated with any Tower resource. This includes both compute environments and runs. The deletion of a resource label from a workspace has no influence on the cloud environment.</p> <p></p>","title":"Overview of resource labels in a workspace"},{"location":"resource-labels/overview/#resource-label-propagation-to-cloud-environments","text":"<p>Note</p> <p>You cannot assign multiple resource labels, using the same key, to the same resource \u2014 regardless of whether this option is supported by the destination cloud provider.</p>  <p>Resource labels are only available for cloud environments that use a resource tagging system. Tower supports AWS, Google Life Sciences, Azure, and Kubernetes \u2014 HPC compute environments do not support resource labels.</p> <p>Note that the cloud provider credentials used by Tower must have the appropriate roles or permissions to tag resources in your environment.</p> <p>When a run is executed in a compute environment with associated resource labels, Tower propagates the labels to a set of resources (listed below), while Nextflow distributes the labels for the resources spawned at runtime.</p> <p>If the compute environment is created through Forge, the compute environment will propagate the tags to the resources generated by the Forge execution.</p>   <p>Warning</p> <p>Resource label propagation is one-way and not synchronized with the cloud environment. This means that Tower attaches tags to cloud resources, but is not aware if those tags are changed or deleted directly in the cloud environment.</p>","title":"Resource label propagation to cloud environments"},{"location":"resource-labels/overview/#aws","text":"<p>When the compute environment is created with Forge, the following resources will be tagged using the labels associated with the compute environment:</p> <p>Forge creation time</p> <ul> <li>FSX Filesystems (does not cascade to files)</li> <li>EFS Filesystems (does not cascade to files)</li> <li>Batch Compute Environment</li> <li>Batch Queue(s)</li> <li>ComputeResource (EC2 instances, excluding EBS volumes)</li> <li>Service Role</li> <li>Spot Fleet Role</li> <li>Execution Role</li> <li>Instance Profile Role</li> </ul> <p>Submission time</p> <ul> <li>Jobs and Job Definitions</li> <li>Tasks (via the propagateTags paramater on Job Definitions)</li> </ul> <p>Execution time</p> <ul> <li>Work Tasks (via the propagateTags paramater on Job Definitions)</li> </ul> <p>At execution time, when the jobs are submitted to Batch, the requests are set up to propagate tags to all the instances created by the head job.</p> <p>The <code>forge-policy.json</code> file contains the roles needed for Tower Forge-created AWS compute environments to tag AWS resources. Specifically, the required roles are <code>iam:TagRole</code>, <code>iam:TagInstanceProfile</code>, and <code>batch:TagResource</code>.</p> <p>To view and manage the resource labels applied to AWS resources by Tower and Nextflow, navigate to the AWS Tag Editor(as an administrative user) and follow these steps:</p> <ol> <li> <p>Under Find resources to tag, search for the resource label key and value in the relevant search fields under Tags. Your search can be further refined by AWS region and resource type. Then select Search resources.</p> </li> <li> <p>Resource search results displays all the resources tagged with your given resource label key and/or value.</p> </li> </ol> <p>To include the cost information associated with your resource labels in your AWS billing reports, follow these steps:</p> <ol> <li> <p>You need to activate the associated tags in the AWS Billing and Cost Management console. Note that newly-applied tags may take up to 24 hours to appear on your cost allocation tags page.</p> </li> <li> <p>Once your tags are activated and displayed on your Cost allocation tags page in the Billing and Cost Management console, you can apply those tags when creating cost allocation reports.</p> </li> </ol>","title":"AWS"},{"location":"resource-labels/overview/#aws-limits","text":"<ul> <li> <p>Resource label keys and values must contain a minimum of 2 and a maximum of 39 alphanumeric characters (each), separated by dashes or underscores.</p> </li> <li> <p>The key and value cannot begin or end with dashes <code>-</code> or underscores <code>_</code>.</p> </li> <li> <p>The key and value cannot contain a consecutive combination of <code>-</code> or <code>_</code> characters (<code>--</code>, <code>__</code>, <code>-_</code>, etc.)</p> </li> <li> <p>A maximum of 25 resource labels can be applied to each resource.</p> </li> <li> <p>A maximum of 100 resource labels can be used in each workspace.</p> </li> <li> <p>Keys and values cannot start with <code>aws</code> or <code>user</code>, as these are reserved prefixes appended to tags by AWS.</p> </li> <li> <p>Keys and values are case-sensitive in AWS.</p> </li> </ul> <p>See here for more information on AWS resource tagging.</p>","title":"AWS limits"},{"location":"resource-labels/overview/#google-batch-and-google-life-sciences","text":"<p>When the compute environment is created with Forge, the following resources will be tagged using the labels associated with the compute environment:</p> <p>Submission time</p> <ul> <li>Job (Batch)</li> <li>RunPipeline (Life Sciences)</li> </ul> <p>Execution time</p> <ul> <li>AllocationPolicy (Batch)</li> <li>VirtualMachine (Life Sciences)</li> <li>RunPipeline (Life Sciences)</li> </ul>","title":"Google Batch and Google Life Sciences"},{"location":"resource-labels/overview/#gcp-limits","text":"<ul> <li> <p>Resource label keys and values must contain a minimum of 2 and a maximum of 39 alphanumeric characters (each), separated by dashes or underscores.</p> </li> <li> <p>The key and value cannot begin or end with dashes <code>-</code> or underscores <code>_</code>.</p> </li> <li> <p>The key and value cannot contain a consecutive combination of <code>-</code> or <code>_</code> characters (<code>--</code>, <code>__</code>, <code>-_</code>, etc.)</p> </li> <li> <p>A maximum of 25 resource labels can be applied to each resource.</p> </li> <li> <p>A maximum of 100 resource labels can be used in each workspace.</p> </li> <li> <p>Keys and values in Google Cloud Resource Manager may contain only lowercase letters. Resource labels created with uppercase characters in Tower are changed to lowercase before propagating to Google Cloud.</p> </li> </ul> <p>See here for more information on Google Cloud Resource Manager labeling.</p>","title":"GCP limits"},{"location":"resource-labels/overview/#azure","text":"<p>Note</p> <p>The labeling system on Azure Cloud uses the term metadata to refer to resource and other labels</p>  <p>When creating an Azure Compute Environment through Forge, resource labels are added to the Pool parameters \u2014 this will add a set of <code>key=value</code> metadata pairs to the Azure Batch Pool.</p>","title":"Azure"},{"location":"resource-labels/overview/#azure-limits","text":"<ul> <li> <p>Resource label keys and values must contain a minimum of 2 and a maximum of 39 alphanumeric characters (each), separated by dashes or underscores.</p> </li> <li> <p>The key and value cannot begin or end with dashes <code>-</code> or underscores <code>_</code>.</p> </li> <li> <p>The key and value cannot contain a consecutive combination of <code>-</code> or <code>_</code> characters (<code>--</code>, <code>__</code>, <code>-_</code>, etc.)</p> </li> <li> <p>A maximum of 25 resource labels can be applied to each resource.</p> </li> <li> <p>A maximum of 100 resource labels can be used in each workspace.</p> </li> <li> <p>Keys are case-insensitive, but values are case-sensitive.</p> </li> <li> <p>Microsoft advises against using a non-English language in your resource labels, as this can lead to decoding progress failure while loading your VM's metadata.</p> </li> </ul> <p>See here for more information on Azure Resource Manager tagging.</p>","title":"Azure limits"},{"location":"resource-labels/overview/#kubernetes","text":"<p>Both the Head pod and Work pod specs will contain the set of labels associated with the compute environment in addition to the standard labels applied by Tower and Nextflow.</p>   <p>Warning</p> <p>Currently, tagging with resource labels is not available for the files created during a workflow execution. The cloud instances are the elements being tagged.</p>  <p>The following resources will be tagged using the labels associated with the compute environment:</p> <p>Forge creation time</p> <ul> <li>Deployment</li> <li>PodTemplate</li> </ul> <p>Submission time</p> <ul> <li>Head Pod Metadata</li> </ul> <p>Execution time</p> <ul> <li>Run Pod Metadata</li> </ul>","title":"Kubernetes"},{"location":"resource-labels/overview/#kubernetes-limits","text":"<ul> <li> <p>Resource label keys and values must contain a minimum of 2 and a maximum of 39 alphanumeric characters (each), separated by dashes or underscores.</p> </li> <li> <p>The key and value cannot begin or end with dashes <code>-</code> or underscores <code>_</code>.</p> </li> <li> <p>The key and value cannot contain a consecutive combination of <code>-</code> or <code>_</code> characters (<code>--</code>, <code>__</code>, <code>-_</code>, etc.)</p> </li> <li> <p>A maximum of 25 resource labels can be applied to each resource.</p> </li> <li> <p>A maximum of 100 resource labels can be used in each workspace.</p> </li> </ul> <p>See here for more information on Kubernetes object labeling.</p>","title":"Kubernetes limits"},{"location":"secrets/overview/","text":"","title":"Pipeline secrets"},{"location":"secrets/overview/#overview","text":"<p>Tower uses the concept of Secrets to store the keys and tokens used by workflow tasks to interact with external systems e.g. a password to connect to an external database or an API token. Tower relies on third-party secret manager services in order to maintain security between the workflow execution context and the secret container. This means that no secure data is transmitted from Tower to the Compute Environment.</p>   <p>Note</p> <p>Currently only AWS Batch or HPC batch schedulers are supported. Please read more about the AWS Secret Manager here</p>","title":"Overview"},{"location":"secrets/overview/#pipeline-secrets","text":"<p>To create a Pipeline Secret navigate to a Workspace (private or shared) and click on the Secrets tab in the top navigation pane to gain access to the Secrets management interface.</p> <p></p> <p>All of the available Secrets will be listed here and users with the appropriate permissions (maintainer, admin or owner) will be able to create or update Secret values.</p> <p></p> <p>The form for creating or updating a Secret is very similar to the one used for Credentials.</p> <p></p>","title":"Pipeline Secrets"},{"location":"secrets/overview/#pipeline-secrets-for-users","text":"<p>Secrets can be defined for users by clicking on your avatar in the top right corner of the Tower interface and selecting \"Your Secrets\". Listing, creating and updating Secrets for users is the same as Secrets in a Workspace. However, Secrets defined by a user have a higher priority and will override any Secrets defined in a Workspace with the same name.</p> <p></p>   <p>Warning</p> <p>Secrets defined by a user have higher priority and will override any Secrets defined in a Workspace with the same name.</p>","title":"Pipeline Secrets for users"},{"location":"secrets/overview/#using-secrets-in-workflows","text":"<p>When a new workflow is launched, all Secrets are sent to the corresponding secret manager for the Compute Environment. Nextflow will download these Secrets internally and use them when they are referenced in the pipeline code as described in the Nextflow Secrets documentation.</p> <p>Secrets will be automatically deleted from the secret manager when the Pipeline completes (successful or unsuccessful).</p>","title":"Using Secrets in workflows"},{"location":"secrets/overview/#aws-secrets-manager-integration","text":"<p>If you are planning to use the Pipeline Secrets feature provided by Tower with the AWS Secrets Manager, the following IAM permissions should be provided:</p> <ol> <li> <p>Create the AWS Batch IAM Execution role as specified in the AWS documentation.</p> </li> <li> <p>Add the <code>AmazonECSTaskExecutionRolePolicy</code> policy and this custom policy to the execution role created above.</p> </li> <li> <p>Specify the execution role ARN in the Batch execution role option (under Advanced options) when creating your Compute Environment in Tower.</p> </li> <li> <p>Add this custom policy to the ECS Instance role associated with the Batch compute environment that will be used to deploy your pipelines. Replace <code>YOUR-ACCOUNT</code> and <code>YOUR-EXECUTION-ROLE-NAME</code> with the appropriate values. See here for more details about the Instance role.</p> </li> <li> <p>Add this custom policy to your Tower IAM user (the one specified in the Tower credentials).</p> </li> </ol>","title":"AWS Secrets Manager Integration"},{"location":"supported_software/dragen/overview/","text":"","title":"Illumina DRAGEN"},{"location":"supported_software/dragen/overview/#illumina-dragen","text":"<p>DRAGEN is a platform provided by Illumina that offers accurate, comprehensive, and efficient secondary analysis of next-generation sequencing (NGS) data with a significant speed-up over tools that are commonly used for such tasks.</p> <p>The improved performance offered by DRAGEN is possible due to the use of Illumina proprietary algorithms in conjunction with a special type of hardware accelerator called field programmable gate arrays (FPGAs). For example, when using AWS, FPGAs are available via the F1 instance type.</p>","title":"Illumina DRAGEN"},{"location":"supported_software/dragen/overview/#running-dragen-on-nextflow-tower","text":"<p>We have extended the Tower Forge feature for AWS Batch to support DRAGEN. Tower Forge ensures that all of the appropriate components and settings are automatically provisioned when creating a Compute Environment for executing pipelines.</p> <p>When deploying data analysis workflows, some tasks will need to use normal instance types (e.g. for non-DRAGEN processing of samples) and others will need to be executed on F1 instances. If the DRAGEN feature is enabled, Tower Forge will create an additional AWS Batch compute queue which only uses F1 instances, to which DRAGEN tasks will be dispatched.</p>","title":"Running DRAGEN on Nextflow Tower"},{"location":"supported_software/dragen/overview/#getting-started","text":"<p>To showcase the capability of this integration, we have implemented a proof of concept pipeline called nf-dragen. To run it, sign-in into Tower, navigate to the Community Showcase and select the \u201cnf-dragen\u201d pipeline.</p> <p>You can run this pipeline at your convenience without any extra setup. Note however that it will be deployed in the Compute Environment owned by the Community Showcase.</p> <p>To deploy the pipeline on your own AWS cloud infrastructure, please follow the instructions in the next section.</p>","title":"Getting started"},{"location":"supported_software/dragen/overview/#deploy-dragen-in-your-own-workspace","text":"<p>DRAGEN is a commercial technology provided by Illumina, so you will need to purchase a license from them. To run on Tower, you will need to obtain the following information from Illumina:</p> <ol> <li>DRAGEN AWS private AMI ID</li> <li>DRAGEN license username</li> <li>DRAGEN license password</li> </ol> <p>Tower Forge automates most of the tasks required to set up an AWS Batch Compute Environment. Please follow our guide for more details.</p> <p>In order to enable support for DRAGEN acceleration, simply toggle the \u201cEnable DRAGEN\u201d option when setting up the Compute Environment via Tower Forge.</p> <p>In the \u201cDRAGEN AMI Id\u201d field, enter the AWS AMI ID provided to you by Illumina.</p> <p></p>   <p>Warning</p> <p>Please ensure that the Region you select contains DRAGEN F1 instances.</p>","title":"Deploy DRAGEN in your own workspace"},{"location":"supported_software/dragen/overview/#pipeline-implementation-deployment","text":"<p>Please see the dragen.nf module implemented in the nf-dragen pipeline for reference. Any Nextflow processes that run DRAGEN must:</p> <ol> <li>Define <code>label \u2018dragen\u2019</code></li> </ol> <p>The <code>label</code> directive allows you to annotate a process with mnemonic identifiers of your choice. Tower will use the <code>dragen</code> label to determine which processes need to be executed on DRAGEN F1 instances.</p> <pre>1\n2\n3\n4\n5</pre><pre><code>process DRAGEN {\n    label 'dragen'\n\n    &lt;truncated&gt;\n}\n</code></pre> <p>Please refer to the Nextflow label docs for more information.</p> <ol> <li>Define Secrets</li> </ol> <p>At Seqera, we use Secrets to safely encrypt sensitive information when running licensed software via Nextflow. This enables our team to use the DRAGEN software safely via the <code>nf-dragen</code> pipeline without having to worry about the setup or safe configuration of the license key. These Secrets will be provided securely to the <code>--lic-server</code> option when running DRAGEN on the CLI to validate the license.</p> <p>In the nf-dragen pipeline, we have defined two Secrets called <code>DRAGEN_USERNAME</code> and <code>DRAGEN_PASSWORD</code>, which you can add via the Tower UI by going to \u201cSecrets -&gt; Add Pipeline Secret\u201d:</p> <p></p> <p></p> <p>Please refer to the Secrets documentation for more information about this feature.</p>","title":"Pipeline implementation &amp; deployment"},{"location":"supported_software/dragen/overview/#limitations","text":"<p>DRAGEN integration with Tower is currently only available for use on AWS, however, we plan to extend the functionality to other supported platforms like Azure in the future.</p>","title":"Limitations"},{"location":"supported_software/fusion/fusion/","text":"","title":"Fusion file system"},{"location":"supported_software/fusion/fusion/#fusion-file-system","text":"<p>Tower 22.4 adds official support for the Fusion file system. Fusion is a lightweight client that enables containerized tasks to access data in Amazon S3 (and other object stores in future) using POSIX file access semantics. Depending on your data handling requirements, Fusion 2.0 improves pipeline throughput and/or reduces cloud computing costs. See here for more information on Fusion's features.</p>","title":"Fusion file system"},{"location":"supported_software/fusion/fusion/#fusion-requirements","text":"<p>Fusion file system is designed to work with containerised workloads. Therefore, it requires the use of a container-native platform for the execution of your pipeline. Currently, Fusion is only available in AWS Batch compute environments in Tower.</p> <p>To enable Fusion in Tower:</p> <ul> <li> <p>Use Nextflow version <code>22.10.0</code> or later. The latest version of Nextflow is used in Tower by default, but a particular version can be specified using <code>NXF_VER</code> in the Nextflow config file field (Advanced options -&gt; Nextflow config file under Pipeline settings on the launch page).</p> </li> <li> <p>Enable the Wave containers service during AWS Batch compute environment creation.</p> </li> <li> <p>Select Enable Fusion v2 during compute environment creation.</p> </li> <li> <p>(Optional) Select Enable fast instance storage to make use of NVMe instance storage to further increase performance.</p> </li> </ul> <p>See the AWS Batch compute environment page for detailed instructions.</p>","title":"Fusion requirements"}]}