{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"<p>Nextflow Tower is the centralized command post for the management of Nextflow data pipelines. It brings monitoring, logging &amp; observability, to distributed workflows and simplifies the deployment of pipelines on any cloud, cluster or laptop.</p> <p>Users can launch pre-configured pipelines with ease while the flexible API provides programmatic integration to meet the needs of organizations building on top of Nextflow Tower. Workflow developers can publish pipelines to shared workspaces and administrators can set up and manage the infrastructure required to run data analysis at scale.</p> <p></p>","title":"Home"},{"location":"#what-is-nextflow","text":"<p>Nextflow is a framework for the development of data workflows. It enables engineers and data scientists to create and securely deploy custom, parallel data applications in the cloud or on traditional, on-premise infrastructure. Nextflow is characterized by a powerful dataflow programming paradigm coupled with execution engines that allow for transparent deployment.</p> <p>Nextflow is both a programming workflow language and an execution runtime that supports a wide range of execution platforms including popular traditional grid scheduling systems such as Slurm and IBM LSF as well as cloud services such as AWS Batch and Google Cloud Life Sciences.</p>","title":"What is Nextflow?"},{"location":"#why-nextflow-tower","text":"<p>We created Nextflow in 2013 to deliver the most seamless experience for executing data workflows at scale. Tower is the continuation of that mission. Encompassing the latest technologies, we have built the solution to easily execute and monitor pipelines across every stage. Tower brings the cloud closer than ever before with automated resource provisioning and role-based access control.</p> <p>Tower has been designed from day one to be easily installable in any environment - data and compute never leave your organization's security boundary. It has been extensively tested with over 125 million jobs to date and zero downtime.</p> <p>As mandated by healthcare industries to ensure compliance, the Tower platform is regularly submitted to penetration tests and security scanning. These tests meet compliance standards set by ISO-27001, HIPAA, and HITRUST.</p>  <p>Tip</p> <p>Sign up to try Tower for free or request a demo for deployments in your own on-premise or cloud environment.</p>","title":"Why Nextflow Tower?"},{"location":"_todo/","text":"<p>FAQ TO DOs:</p>","title":"todo"},{"location":"_todo/#general","text":"<ul> <li>$TOWER_AGENT_WORKDIR</li> <li>What does <code>NXF_PLUGINS_DEFAULT</code> environment variable do?</li> <li>Where is the analysis running?</li> <li>What about security of my data?</li> <li>Identity via LDAP/Active Directory</li> <li>Difference between free and paid Tower?</li> <li>Can I have Service-Account-type and Agent-type credentials in the same Workspace?<ul> <li>Not right now. Must choose. https://github.com/seqeralabs/nf-tower-cloud/issues/2879#issuecomment-1072646557</li> </ul> </li> </ul>","title":"GENERAL"},{"location":"_todo/#amazon","text":"<ul> <li>Can I have Nextflow automatically retry Tasks that fail due to Spot instance reclamation?</li> <li> <p>Can I have Nextflow automatically retry Tasks that fail due to Spot instance reclamation? </p> <p>Yes. As of Tower version ?????, any Spot-based AWS Batch Compute Environment created by Tower Forge will be automatically configured to retry each process 3 times. ??? If a retry policy is not defined???</p> <p>Given that Spots can be reclaimed during the execution of a job, it is a recommended practice that pipeline authors always include retry logic in their logic. ???See HERE for examples??? https://github.com/seqeralabs/nf-tower-cloud/pull/2820/files</p> <ul> <li>Why won't Secrets work with my legacy Tower Forge-created AWS Batch Compute Environment?</li> <li>Why won't Secrets work with my legacy Tower Forge-created AWS Batch Compute Environment? </li> </ul> <p>The Secrets feature requires new permissions to be added to existing IAM Roles: * The User/Role used by your Tower implementation must have the <code>secretsmanager:CreateSecret</code>. * Your Batch EC2 Instance Role must have ??? execution role ??? * Added details from here: https://github.com/seqeralabs/nf-tower-cloud/pull/2820</p> <p>Add Tower Agent blurb re: Rijkzwaan as per https://git.seqera.io/rijkzwaan/nf-support/issues/15#issuecomment-8438</p> <p>Meeting summary for 31-03-2021</p> </li> </ul> <p>Adding quick summary for the meeting today, please feel free to add/correct anything I might have missed.</p> <pre>1\n2\n3\n4\n5\n6\n7</pre><pre><code>With Jordi's guidance, the $TW_USER_AGENT was succesfully used on an agent running in Kim's account to launch a pipeline from Daniel's user on Tower UI\n\nThe slight nuance on the RKZ cluster was that the home directories seem to be following a non-standard pattern i.e. with all-caps usernames (for example /home/DCR) and we had to append USER=DCR tw-agent ... to enable the agent.\n\nAn upgrade to the latest version of Tower would enable the use of $TW_AGENT_WORK variable with the agent\n\nWe also discussed the usage of pipeline reports feature\n</code></pre>  <p>Follow-ups</p> <pre>1\n2\n3</pre><pre><code>@daniel-cruz-rijkzwaan to follow up here with an independent experiment to get up and running with tw-agent\n\nAbhinav to request the addition of Daniel's account in the community/showcase workspace in tower.nf\n</code></pre>  <p>Warmly, Abhinav</p> <p>AZURE Batch - SSL problem as per https://git.seqera.io/eagle/nf-support/issues/10#issuecomment-8523</p>","title":"Amazon"},{"location":"_todo/#determine-if-this-is-relevant-to-google-faq-section","text":"<p>https://github.com/nf-core/configs/blob/master/conf/google.config as per this ticket: https://git.seqera.io/pluto/nf-support/issues/6</p> <p>TO DO: As per Ben, document profile injection behaviour into Tower docs (e.g. nf-core automagically injecting google profile if executing on GLS)</p>","title":"Determine if this is relevant to Google FAQ section:"},{"location":"cli/","text":"<p><code>tw</code> is Tower on the command line. It brings Tower concepts including Pipelines, Actions and Compute Environments to the terminal.</p> <p>Tower is a full-stack application for the management of data pipelines and compute resources. It enables collaborative data analysis at scale, on-premises or in any cloud.</p> <p>The Tower CLI interacts with Tower, providing an interface to launch pipelines, manage cloud resources and administer your analysis.</p> <p></p>","title":"Nextflow Tower CLI"},{"location":"cli/#key-features","text":"<ul> <li> <p>A Nextflow-like experience: Tower CLI provides a developer-friendly environment. Pipelines can be launched with the CLI similar to Nextflow but with the benefits of Tower such as monitoring, logging, resource provisioning, dataset management, and collaborative sharing.</p> </li> <li> <p>Infrastructure as Code: All Tower resources including Pipelines and Compute Environments can be described in a declarative manner. This allows a complete definition of an analysis environment that can be versioned and treated as code. It greatly simplifies sharing and re-use of configuration as well as routine administration.</p> </li> <li> <p>Built on OpenAPI: Tower CLI interacts with Tower via the Tower API which is created using the latest OpenAPI 3.0 specification. Tower CLI provides full control of the Tower application allowing users to get maximum insights into their pipeline submissions and execution environments.</p> </li> </ul>","title":"Key features"},{"location":"cli/#availability","text":"<p>Tower CLI can be installed on macOS, Windows, and Linux.</p> <p>Visit the Tower CLI page on GitHub for installation and configuration details.</p>","title":"Availability"},{"location":"faqs/","text":"","title":"Frequently asked questions"},{"location":"faqs/#general-questions","text":"","title":"General Questions"},{"location":"faqs/#administration-console","text":"<p><p>Q: How do I access the Administration Console?</p> <p>The Administration Console allows Tower instance administrators to interact with all users and organizations registered with the platform. Administrators must be identified in your Tower instance configuration files prior to instantiation of the application.</p> <ol> <li>Create a <code>TOWER_ROOT_USERS</code> environment variable (e.g. via tower.env).</li> <li>Populate the variable with a sequence of comma-delimited email addresses (no spaces).Example: <code>TOWER_ROOT_USERS=foo@foo.com,bar@bar.com</code></li> <li>If using a Tower version earlier than 21.12: <ol> <li>Add the following configuration to tower.yml: <pre>1\n2\n3</pre><pre><code>tower:\n  admin:\n    root-users: '${TOWER_ROOT_USERS:[]}'\n</code></pre> </li> </ol> </li> <li>Restart the application.</li> <li>The console will now be availabe via your Profile drop-down menu.</li> </ol>","title":"Administration Console"},{"location":"faqs/#common-errors","text":"<p><p>Q: After following the log-in link, why is my screen frozen at <code>/auth?success=true</code>?</p> <p>Starting with v22.1, Tower Enterprise implements stricter cookie security by default and will only send an auth cookie if the client is connected via HTTPS. The lack of an auth token will cause HTTP-only log-in attempts to fail (thereby causing the frozen screen).</p> <p>To remediate this problem, set the following environment variable <code>TOWER_ENABLE_UNSAFE_MODE=true</code>.</p> <p><p>Q: \"Unknown pipeline repository or missing credentials\" error when pulling from a public Github repository?</p> <p>Github imposes rate limits on repository pulls (including public repositories), where unauthenticated requests are capped at 60 requests/hour and authenticated requests are capped at 5000/hour. Tower users tend to encounter this error due to the 60 request/hour cap. </p> <p>To resolve the problem, please try the following:</p> <ol> <li>Ensure there is at least one Github credential in your Workspace's Credentials tab.</li> <li>Ensure that the Access token field of all Github Credential objects is populated with a Personal Access Token value, NOT a user password. (Github PATs are typically several dozen characters long and begin with a <code>ghp_</code> prefix; example: <code>ghp_IqIMNOZH6zOwIEB4T9A2g4EHMy8Ji42q4HA</code>)</li> <li>Confirm that your PAT is providing the elevated threshold and transactions are being charged against it: <pre>1</pre><pre><code>`curl -H \"Authorization: token ghp_LONG_ALPHANUMERIC_PAT\" -H \"Accept: application/vnd.github.v3+json\" https://api.github.com/rate_limit`\n</code></pre>  </li> </ol> <p><p>Q: \"Unexpected error sending mail ... TLS 1.0 and 1.1 are not supported. Please upgrade/update your client to support TLS 1.2\" error?</p> <p>Some mail services, including Microsoft, have phased out support for TLS 1.0 and 1.1. Tower Enterprise, however, is based on Java 11 (Amazon Coretto) and does not use TLSv1.2 by default. As a result, an encryption error will occur when Tower tries to send email even if you have configured your <code>mail.smtp.starttls</code> settings to be <code>true</code>.</p> <p>To fix the problem, use this JDK environment variable to force the usage of TLSv1.2 by default:</p> <pre>1</pre><pre><code>`_JAVA_OPTIONS=\"-Dmail.smtp.ssl.protocols=TLSv1.2\"`\n</code></pre>  <p><p>Q: \"Row was updated or deleted by another transaction (or unsaved-value mapping was incorrect)\" error.</p> <p>This error can occur if incorrect configuration values are assigned to the <code>backend</code> and <code>cron</code> containers' <code>MICRONAUT_ENVIRONMENTS</code> environment variable. You may see other unexpected system behaviour like two exact copies of the same Nextflow job be submitted to the Executor for scheduling. </p> <p>Please verify the following:</p> <ol> <li>The <code>MICRONAUT_ENVIRONMENTS</code> environment variable associated with the <code>backend</code> container:<ul> <li>Contains <code>prod,redis,ha</code></li> <li>Does not contain <code>cron</code></li> </ul> </li> <li>The <code>MICRONAUT_ENVIRONMENTS</code> environment variable associated with the <code>cron</code> container:<ul> <li>Contains <code>prod,redis,cron</code></li> <li>Does not contain <code>ha</code></li> </ul> </li> <li>You do not have another copy of the <code>MICRONAUT_ENVIRONMENTS</code> environment variable defined elsewhere in your application (e.g. a tower.env file or Kubernetes ConfigMap).</li> <li>If you are using a separate container/pod to execute migrate-db.sh, there is no <code>MICRONAUT_ENVIRONMENTS</code> environment variable assigned to it.</li> </ol> <p><p>Q: \"No such variable\" error.</p> <p>This error can occur if you execute a DSL 1-based Nextflow workflow using Nextflow 22.03.0-edge or later.</p>","title":"Common Errors"},{"location":"faqs/#compute-environments","text":"<p><p>Q: Can the name of a Compute Environment created in Tower contain special characters?</p> <p>No. Tower version 21.12 and later do not support the inclusion of special characters in the name of Compute Environment objects.</p> <p><p>Q: How do I set NXF_OPTS values for a Compute Environment?</p> <p>This depends on your Tower version:</p> <ul> <li>For v22.1.1+, specify the values via the Environment variables section of the \"Add Compute Environment\" screen.</li> <li> <p>For versions earlier than v22.1.1, specify the values via the Staging options &gt; Pre-run script textbox on the \"Add Compute Environment\" screen. Example: </p> <p><code>export NXF_OPTS=\"-Xms64m -Xmx512m\"</code></p> </li> </ul>","title":"Compute Environments"},{"location":"faqs/#configuration","text":"<p><p>Q: Can a custom path be specified for the <code>tower.yml</code> configuration file?</p> <p>Yes. Provide a POSIX-compliant path to the <code>TOWER_CONFIG_FILE</code> environment variable.</p> <p><p>Q: Why do parts of <code>tower.yml</code> not seem to work when I run my Tower implementation?</p> <p>There are two reasons why configurations specified in <code>tower.yml</code> are not being expressed by your Tower instance:</p> <ol> <li>There is a typo in one of the key value pairs.</li> <li>There is a duplicate key present in your file.      <pre> 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11</pre><pre><code># EXAMPLE\n# This block will not end up being enforced because there is another `tower` key below.\ntower:\n  trustedEmails:\n    - user@example.com\n\n# This block will end up being enforced because it is defined last.\ntower:\n  auth:\n    oidc:\n      - \"*@foo.com\"\n</code></pre> </li> </ol> <p><p>Q: Do you have guidance on how to create custom Nextflow containers?</p> <p>Yes. Please see https://github.com/seqeralabs/gatk4-germline-snps-indels/tree/master/containers.</p> <p><p>Q: What DSL version does Nextflow Tower set as default for Nextflow head jobs?</p> <p>As of Nextflow 22.03.0-edge, DSL2 is the default syntax.</p> <p>To minimize disruption on existing pipelines, Nextflow Tower version 22.1.x and later are configured to default Nextflow head jobs to DSL 1 for a transition period (ending TBD).</p> <p>You can force your Nextflow head job to use DSL2 syntax via any of the following techniques:</p> <ul> <li>Adding <code>export NXF_DEFAULT_DSL=2</code> in the Advanced Features &gt; Pre-run script field of Tower Launch UI.</li> <li>Specifying <code>nextflow.enable.dsl = 2</code> at the top of your Nextflow workflow file.</li> <li>Providing the <code>-dsl2</code> flag when invoking the Nextflow CLI (e.g. <code>nextflow run ... -dsl2</code>)</li> </ul> <p><p>Q: Can Tower to use a Nextflow workflow stored in a local git repository?</p> <p>Yes. As of v22.1, Nextflow Tower Enterprise can link to workflows stored in \"local\" git repositories. To do so:</p> <ol> <li>Volume mount your repository folder into the Tower Enterprise <code>backend</code> container.</li> <li>Update your <code>tower.yml</code> with the following configuration: <pre>1\n2\n3\n4</pre><pre><code>tower:\n  pipeline:\n    allow-local-repos:\n      - /path/to/repo\n</code></pre> </li> </ol> <p>Note: This feature is not available to Tower Cloud users.</p>","title":"Configuration"},{"location":"faqs/#logging","text":"<p><p>Q: Can Tower enable detailed logging related to sign-in activity?</p> <p>Yes. For more detailed logging related to login events, set the following environment variable: <code>TOWER_SECURITY_LOGLEVEL=DEBUG</code>.</p> <p><p>Q: Can Tower enable detailed logging related to application activites?</p> <p>Yes. For more detailed logging related to application activities, set the following environment variable: <code>TOWER_LOG_LEVEL=TRACE</code>.</p>","title":"Logging"},{"location":"faqs/#login","text":"<p><p>Q: Can I completely disable Tower's email login feature?</p> <p>The email login feature cannot be completely removed from the Tower login screen. </p> <p><p>Q: How can I restrict Tower access to only a subset of email addresses?</p> <p>You can restrict which emails are allowed to have automatic access to your Tower implementation via a configuration in tower.yml. </p> <p>Users without automatic access will receive an acknowledgment of their login request but be unable to access the platform until approved by a Tower administration via the Administrator Console. <pre>1\n2\n3\n4\n5</pre><pre><code># This any email address that matches a pattern here will have automatic access.\ntower:\n  trustedEmails:\n    - '*@seqera.io`\n    - 'named_user@example.com'\n</code></pre> </p> <p><p>Q: Why is my OIDC redirect_url set to http instead of https?</p> <p>This can occur for several reasons. Please verify the following:</p> <ol> <li>Your <code>TOWER_SERVER_URL</code> environment variable uses the <code>https://</code> prefix.</li> <li>Your <code>tower.yml</code> has <code>micronaut.ssl.enabled</code> set to <code>true</code>.</li> <li>Any Load Balancer instance that sends traffic to the Tower application is configured to use HTTPS as its backend protocol rather than TCP.</li> </ol> <p><p>Q: Why isn't my OIDC callback working?</p> <p>Callbacks could fail for many reasons. To more effectively investigate the problem: </p> <ol> <li>Set the Tower environment variable to <code>TOWER_SECURITY_LOGLEVEL=DEBUG</code>.</li> <li>Ensure your <code>TOWER_OIDC_CLIENT</code>, <code>TOWER_OIDC_SECRET</code>, and <code>TOWER_OIDC_ISSUER</code> environment variables all match the values specified in your OIDC provider's corresponding application.</li> <li>Ensure your network infrastructure allow necessary egress and ingress traffic.</li> </ol>","title":"Login"},{"location":"faqs/#miscellaneous","text":"<p><p>Q: Is my data safe?</p> <p>Yes, your data stays strictly within your infrastructure itself. When you launch a workflow through Tower, you need to connect your infrastructure (HPC/VMs/K8s) by creating the appropriate credentials and compute environment in a workspace.</p> <p>Tower then uses this configuration to trigger a Nextflow workflow within your infrastructure similar to what is done via the Nextflow CLI, therefore Tower does not manipulate any data itself and no data is transferred to the infrastructure where Tower is running.</p>","title":"Miscellaneous"},{"location":"faqs/#nextflow-configuration","text":"<p><p>Q: Can a repository's <code>nextflow_schema.json</code> support multiple input file mimetypes?</p> <p>No. As of April 2022, it is not possible to configure an input field (example) to support different mime types (e.g. a <code>text/csv</code>-type file during one execution, and a <code>text/tab-separated-values</code> file in a subsequent run).</p> <p><p>Q: Why are my <code>--outdir</code> artefacts not available when executing runs in a cloud environment?</p> <p>As of April 2022, Nextflow resolves relative paths against the current working directory. In a classic grid HPC, this normally corresponds to a subdirectory of the user's $HOME directory. In a cloud execution environment, however, the path will be resolved relative to the container file system meaning files will be lost when the container is termination. See here for more details.</p> <p>Tower Users can avoid this problem by specifying the following configuration in the Advanced options &gt; Nextflow config file configuration textbox: <code>params.outdir = workDir + '/results</code>. This will ensure the output files are written to your stateful storage rather than ephemeral container storage.</p> <p><p>Q: Can Nextflow be configured to ignore a Singularity cache?</p> <p>Yes. To ignore the Singularity cache, add the following configuration item to your workflow: <code>process.container = 'file:///some/singularity/image.sif'</code>.</p>","title":"Nextflow Configuration"},{"location":"faqs/#tw-cli","text":"<p><p>Q: Can a custom run name be specified when launch a pipeline via the <code>tw</code> CLI?</p> <p>Yes. As of <code>tw</code> v0.6.0, this is possible. Example: <code>tw launch --name CUSTOM_NAME ...</code></p>","title":"tw CLI"},{"location":"faqs/#amazon","text":"","title":"Amazon"},{"location":"faqs/#ec2-instances","text":"<p><p>Q: Can I run a Nextflow head job on AWS Gravitron instances?</p> <p>No. Nextflow does not yet run on ARM-based compute instances.</p>","title":"EC2 Instances"},{"location":"faqs/#ecs","text":"<p><p>Q:How often are docker images pulled by the ECS Agent?</p> <p>As part of the AWS Batch creation process, Tower Forge will set ECS Agent parameters in the EC2 Launch Template that is created for your cluster's EC2 instances:</p> <ul> <li>For clients using Tower Enterprise v22.01 or later:<ul> <li>Any AWS Batch environment created by Tower Forge will set the ECS Agent's <code>ECS_IMAGE_PULL_BEHAVIOUR</code> set to <code>once</code>. </li> </ul> </li> <li>For clients using Tower Enterprise v21.12 or earlier:<ul> <li>Any AWS Batch environment created by Tower Forge will set the ECS Agent's <code>ECS_IMAGE_PULL_BEHAVIOUR</code> set to <code>default</code>.</li> </ul> </li> </ul> <p>Please see the AWS ECS documentation for an in-depth explanation of this difference. </p> <p>Note:</p> This behaviour cannot be changed within the Tower Application.","title":"ECS"},{"location":"faqs/#queues","text":"<p><p>Q: Does Nextflow Tower support the use of multiple AWS Batch queues during a single job execution?</p></p> <p>Yes. Even though you can only create/identify a single work queue during the definition of your AWS Batch Compute Environment within Nextflow Tower, you can spread tasks across multiple queues when your job is sent to Batch for execution via your pipeline configuration.</p> <p>Adding the following snippet to either your nextflow.config or the Advanced Features &gt; Nextflow config gile field of Tower Launch UI, will cause processes to be distributed across two AWS Batch queues, depending on the assigned named.</p> <pre> 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13</pre><pre><code># nextflow.config \n\nprocess {\n  withName: foo {\n    queue: `TowerForge-1jJRSZmHyrrCvCVEOhmL3c-work`\n  }\n}\n\nprocess {\n  withName: bar {\n    queue: `custom-second-queue`\n  }\n}\n</code></pre>","title":"Queues"},{"location":"faqs/#security","text":"<p><p>Q: Can Tower connect to an RDS instance using IAM credentials instead of username/password?</p></p> <p>No. Nextflow Tower must be supplied with a username &amp; password to connect to its associated database.</p>","title":"Security"},{"location":"faqs/#storage","text":"<p><p>Q: Can I use EFS as my work directory?</p> <p>As of Nextflow Tower v21.12, you can specify an Amazon Elastic File System instance as your Nextflow work directory when creating your AWS Batch Compute Environment via Tower Forge. </p> <p><p>Q: Can I use FSX for Luster as my work directory?</p> <p>As of Nextflow Tower v21.12, you can specify an Amazon FSX for Lustre instance as your Nextflow work directory when creating your AWS Batch Compute Environment via Tower Forge.</p> <p><p>Q: How do I configure my Tower-invoked pipeline to be able to write to an S3 bucket that enforces AES256 server-side encryption?</p> <p>If you need to save files to an S3 bucket protected by a bucket policy which enforces AES256 server-side encryption, additional configuration settings must be provided to the nf-launcher script which invokes the Nextflow head job:</p> <ol> <li>Add the following configuration to the Advanced options &gt; Nextflow config file textbox of the Launch Pipeline screen:</li> </ol> <p><pre>1\n2\n3\n4\n5</pre><pre><code>aws {\n   client {\n      storageEncryption = 'AES256'\n    }\n}\n</code></pre>  2. Add the following configuration to the Advanced options &gt; Pre-run script textbox of the Launch Pipeline screen:</p> <p><code>export TOWER_AWS_SSE=AES256</code></p> <p>Note:</p> <ul> <li>This solution requires at least Tower v21.10.4 and Nextflow 21.10.6 build 5660. </li> <li>Please check https://github.com/nextflow-io/nextflow/issues/2808 to see if a bug related to the upload of task <code>.command.log</code> files has been fixed.</li> </ul>","title":"Storage"},{"location":"faqs/#azure","text":"","title":"Azure"},{"location":"faqs/#batch","text":"<p><p>Q: Why is my Azure Batch VM quota set to 0?</p></p> <p>In order to manage capacity during the global health pandemic, Microsoft has reduced core quotas for new Batch accounts. Depending on your region and subscription type, a newly-created account may not be entitled to any VMs without first making a service request to Azure. </p> <p>Please see Azure's Batch service quotas and limits page for further details. </p>","title":"Batch"},{"location":"faqs/#ssl","text":"<p><p>Q: \"Problem with the SSL CA cert (path? access rights?)\" error</p></p> <p>This can occur if a tool/library in your task container requires SSL certificates to validate the identity of an external data source.</p> <p>You may be able to solve the issue by:</p> <ol> <li>Mounting host certificates into the container (example).</li> </ol>","title":"SSL"},{"location":"faqs/#google","text":"","title":"Google"},{"location":"faqs/#retry","text":"<p><p>Q: How do I make my Nextflow pipelines more resilient to VM preemption?</p></p> <p>Running your pipelines on preemptible VMs provides significant cost savings but increases the likelihood that a task will be interrupted before completion. It is a recommended best practice to implement a retry strategy when you encounter exit codes that are commonly related to preemption. Example:</p> <pre>1\n2\n3\n4\n5</pre><pre><code>process {\n  errorStrategy = { task.exitStatus in [8,10,14] ? 'retry' : 'finish' }\n  maxRetries    = 3\n  maxErrors     = '-1'\n}\n</code></pre>","title":"Retry"},{"location":"faqs/#on-prem-hpc","text":"<p><p>Q: \"java: command not found\"</p></p> <p>When submitting jobs to your on-prem HPC (regardless of whether using SSH or Tower-Agent authentication), the following error may appear in your Nextflow logs even though you have Java on your $PATH environment variable: <pre>1\n2\n3\n4</pre><pre><code>java: command not found\nNextflow is trying to use the Java VM defined for the following environment variables:\n  JAVA_CMD: java\n  NXF_OPTS:\n</code></pre> </p> <p>Possible reasons for this error:</p> <ol> <li>The queue where the Nextflow head job runs in a different environment/node than your login node userspace.</li> <li>If your HPC cluster uses modules, the Java module may not be loaded by default.</li> </ol> <p>To troubleshoot:</p> <ol> <li>Open an interactive session with the head job queue.</li> <li>Launch the Nextflow job from the interactive session.</li> <li>If you cluster used modules:<ol> <li>Add <code>module load &lt;your_java_module&gt;</code> in the Advanced Features &gt; Pre-run script field when creating your HPC Compute Environment within Nextflow Tower.</li> </ol> </li> <li>If you cluster does not use modules:<ol> <li>Source an environment with java and Nextflow using the Advanced Features &gt; Pre-run script field when creating your HPC Compute Environment within Nextflow Tower.</li> </ol> </li> </ol>","title":"On-Prem HPC"},{"location":"functionality_matrix/","text":"","title":"Tower API Versions"},{"location":"functionality_matrix/#enterprise","text":"<p>Initial values determined from https://github.com/seqeralabs/nf-tower-cloud/blob/v22.1.0-dalambert_8dadb354/VERSION-API (looking at <code>-enterprise</code>-tagged branches).</p>    Tower Version Tower API Version CLI Minimum Version     v21.12.1 1.8.0 v0.4   v21.12.0 1.8.0 v0.4   v21.10.3 1.7.1 v0.4   v21.10.2 1.7.1 v0.4   v21.10.1 1.7.1 v0.4   v21.06.5 1.5.2 n/a   v21.06.5 1.5.2 n/a   v21.06.5 1.5.2 n/a   v21.06.5 1.5.2 n/a   v21.06.5 1.5.2 n/a   v21.06.5 1.5.2 n/a   v21.04.9 1.5.2 n/a   v21.04.8 1.5.2 n/a   v21.04.7 1.5.2 n/a   v21.04.6 1.5.2 n/a   v21.04.5 1.5.2 n/a   v21.04.4 1.5.2 n/a   v21.04.3 1.5.2 n/a   v21.04.2 1.5.2 n/a   v21.04.1 1.5.2 n/a   v21.04.0 1.5.2 n/a","title":"Enterprise"},{"location":"functionality_matrix/#tower-cloud","text":"Tower Version Tower API Version CLI Minimum Version     v22.1.0-edison_1537163d 1.9.0 v0.4   v22.1.0-dalambert_98791828 1.9.0 v0.4   v22.1.0-dalambert_8dadb354 1.9.0 v0.4    <p>CLI 0.5.1 needs 1.7 as per https://github.com/seqeralabs/tower-cli/blob/v0.5.1/VERSION-API CLI 0.5 and 0.4 also need 1.7 v0.3 / 0.2 / 01 needs 1.6 v</p>","title":"Tower Cloud"},{"location":"functionality_matrix/#tower-launcher-version","text":"<p>Based on documentation on at variations of this path: https://github.com/seqeralabs/nf-tower-cloud/blob/v21.12.3-enterprise/tower-services/src/main/groovy/io/seqera/tower/service/TowerServiceImpl.groovy </p>    Tower Version Launcher Version     v22.1.0-faggin_63f78620 quay.io/seqeralabs/nf-launcher:j11-22.03.0-edge   v21.12.3-enterprise quay.io/seqeralabs/nf-launcher:j17-21.10.6   v21.12.2-enterprise quay.io/seqeralabs/nf-launcher:j17-21.10.6   v21.12.1-enterprise quay.io/seqeralabs/nf-launcher:j17-21.10.4   v21.10.4-enterprise quay.io/seqeralabs/nf-launcher:j11-21.10.6   v21.10.3-enterprise quay.io/seqeralabs/nf-launcher:21.10.5   v21.10.2-enterprise quay.io/seqeralabs/nf-launcher:21.10.5   v21.10.1-enterprise quay.io/seqeralabs/nf-launcher:21.10.4   v21.10.0-enterprise quay.io/seqeralabs/nf-launcher:21.10.4","title":"Tower Launcher Version"},{"location":"functionality_matrix/#functionality-matrix","text":"<p>This page lists the features available in Nextflow Tower and the necessary related infrastructure.</p>    Feature Tower Version Tower API Version CLI Version Nextflow Version Nextflow Launcher Version Notes     EFS as work directory 21.12.x ??? ??? ??? ??? See Release Notes   FSX as work directory 21.12.x ??? ??? ??? ??? See Release Notes   Default Retry Policy for AWS Spot Instances ??? ??? ??? ??? ??? ???    <p>?? XPack ?? Nextflow Plugins Administration Panel ?? IARC ENABLE_ROOT_USERS *(behaviour changed in one of the versions- 21.12.x patch? ) https://github.com/seqeralabs/support-backlog/issues/46</p> <ul> <li>Secrets</li> <li>CloudWatch Unified Agent</li> <li>EBS Autoscaling permission</li> <li>Nextflow Tower Enterprise integration with local git repostiory (22.1.?) .</li> </ul> <p>To do: - add SecretsManager permissions to Tower permissions list. - add EBS Autoscaling (KMS) permissions to Tower permissions list. - Automatic retry for jobs runs against AWS Batch (due to spot reclamation). Waiting for confirmation whether only against Batch clusters created by Tower Forge or any pipeline invoked (https://github.com/seqeralabs/nf-tower-cloud/pull/2820) * NextRNA AES-256 encryption write to S3 https://git.seqera.io/nextrna/nf-support/issues/11#issuecomment-8508</p> <ul> <li>ECS pull behaviour - AWS Batch Forge created in v22.01+ will be configured to pull the image only once to each EC2 instance (as per https://github.com/seqeralabs/nf-tower-cloud/issues/2661)</li> </ul>","title":"Functionality Matrix"},{"location":"api/endpoints/","text":"<p>You can a detailed list of all Tower endpoints at this page. </p> <p>It also includes request and response payload examples, and the ability test each endpoint invocation interactively.</p>","title":"Endpoints"},{"location":"api/openapi/","text":"<p>The most updated OpenAPI schema for Tower API is available at this link.</p>","title":"OpenAPI schema"},{"location":"api/overview/","text":"<p>Tower is API centric, it exposes a public API with all necessary calls to manage and monitor Nextflow workflows programmatically.  This allows organizations to extend their existing solutions by leveraging the Tower API.</p>","title":"Overview"},{"location":"api/overview/#schema","text":"<p>All API access is over HTTPS, and accessed from <code>https://api.tower.nf</code>. All data is sent and received as JSON encoded objects.</p> <p>All timestamps use the ISO 8601 date-time standard format:</p>  <p>Hint</p> <p>YYYY-MM-DDTHH:MM:SSZ</p>","title":"Schema"},{"location":"api/overview/#authentication","text":"<p>Tower API requires an authentication token to be specified in each API request using the  Bearer HTTP header.</p> <p>Your personal authorization token can be found in your settings, at the top-right corner of the page under the  Your tokens section.</p> <p></p> <p>To create a new access token, just provide a name for the token. This will help to identify it later.</p> <p></p> <p>Once created, the token can only be seen once, when it is initially created. It is important you keep this token at a safe place.</p> <p></p> <p>Once created, use the token to authenticate via cURL, Postman, or within your code against the Nextflow API to perform the necessary calls for completing your tasks.  Please remember that, as any other Bearer token, this token must be included in every API call.</p>","title":"Authentication"},{"location":"api/overview/#example-call-using-the-curl-command","text":"<pre>1</pre><pre><code>curl -H \"Authorization: Bearer eyJ...YTk0\" https://tower.nf/api/workflow\n</code></pre>   <p>Use your token in every API call</p> <p>Please remember that, as any other Bearer token, this token must be included in every API call. You can find at the following link more details about the Bearer token authentication. scheme.</p>","title":"Example call using the cURL command"},{"location":"api/overview/#parameters","text":"<p>Some API <code>GET</code> methods will accept standard <code>query</code> parameters, which are defined in the documentation; <code>querystring</code> optional  parameters such as page size, number (when available) and file name; and body parameters, mostly used for <code>POST</code>, <code>PUT</code> and <code>DELETE</code> requests.</p> <p>Additionally, several head parameters are accepted such as <code>Authorization</code> for bearer access token or <code>Accept-Version</code> to indicate the desired API version to use (default to version 1)</p> <pre>1\n2\n3\n4</pre><pre><code>curl -H \"Authorization: Bearer QH..E5M=\" \n     -H \"Accept-Version:1\"\n     -X POST https://tower.nf/api/domain/{item_id}?queryString={value}\n     -d { params: { \"key\":\"value\" } }\n</code></pre>","title":"Parameters"},{"location":"api/overview/#client-errors","text":"<p>There exists two typical standard errors, or non <code>200</code> or <code>204</code> status responses, to expect from the API.</p>","title":"Client errors"},{"location":"api/overview/#bad-request","text":"<p>The request payload is not properly defined or the query parameters are invalid.</p> <pre>1\n2\n3</pre><pre><code>{\n    \"message\": \"Oops... Unable to process request - Error ID: 54apnFENQxbvCr23JaIjLb\"\n}\n</code></pre>","title":"Bad request"},{"location":"api/overview/#forbidden","text":"<p>Your access token is invalid or expired. This response may also imply that the entry point you are trying to access is not available;  in such a case, it is recommended you check your request syntax.</p> <pre>1</pre><pre><code>Status: 403 Forbidden\n</code></pre>","title":"Forbidden"},{"location":"api/overview/#rate-limiting","text":"<p>For all API requests, there is a threshold of 20 calls per second (72000 calls per hour) and access key. </p>","title":"Rate limiting"},{"location":"compute-envs/altair-grid-engine/","text":"","title":"Altair Grid Engine"},{"location":"compute-envs/altair-grid-engine/#overview","text":"<p>Altair Grid Engine is a workload manager maintained by Altair Engineering, Inc.</p> <p>Tower streamlines the deployment of Nextflow pipelines into both cloud-based and on-prem Grid Engine clusters.</p>","title":"Overview"},{"location":"compute-envs/altair-grid-engine/#requirements","text":"<p>To launch pipelines into a Grid Engine cluster from Tower, the following requirements must be satisfied:</p> <ul> <li>The cluster should be reachable via an SSH connection using an SSH key.</li> <li>The cluster should allow outbound connections to the Tower web service.</li> <li>The cluster queue used to run the Nextflow head job must be able to submit cluster jobs.</li> <li>The Nextflow runtime version 21.02.0-edge (or later) should be installed on the cluster.</li> </ul>","title":"Requirements"},{"location":"compute-envs/altair-grid-engine/#compute-environment","text":"<p>To create a new compute environment for Grid Engine in Tower:</p> <ol> <li> <p>In a workspace, select Compute Environments and then New Environment.</p> </li> <li> <p>Enter a descriptive name for this environment, e.g. \"Grid Engine\".</p> </li> <li> <p>Select Altair Grid Engine as the target platform.</p> </li> <li> <p>Select your credentials, or select + and SSH to add new credentials.</p> </li> <li> <p>Enter a name for the credentials.</p> </li> <li> <p>Enter your SSH private key and associated Passphrase (if required), then select Create.</p>  <p>Tip</p> <p>Your SSH key may not require a passphrase depending on how it was created. See here for detailed instructions for how to create a key.</p>  </li> <li> <p>Enter the absolute path of the Work directory to be used on the cluster.</p> </li> <li> <p>Enter the absolute path of the Launch directory to be used on the cluster. If omitted, it will be the same as the work directory.</p> </li> <li> <p>Enter the Login hostname, which is usually the hostname or public IP address of the cluster's login node.</p> </li> <li> <p>Enter the Head queue name, the cluster queue to which the Nextflow job will be submitted.</p> </li> <li> <p>Enter the Compute queue name, the cluster queue to which the Nextflow job will submit tasks.</p>  <p>Tip</p> <p>The compute queue can be overridden by the Nextflow pipeline configuration. See the Nextflow docs for more details.</p>  </li> <li> <p>You can use the Environment variables option to specify custom environment variables for the Head job and/or Compute jobs.</p> <p></p> </li> <li> <p>Configure any advanced options described below, as needed.</p> </li> <li> <p>Select Create to finalize the creation of the compute environment.</p> </li> </ol> <p>Jump to the documentation for Launching Pipelines.</p>","title":"Compute Environment"},{"location":"compute-envs/altair-grid-engine/#advanced-options","text":"<ul> <li> <p>You can use the Nextflow queue size to limit the number of jobs that Nextflow can submit to the scheduler at the same time.</p> </li> <li> <p>You can use the Head job submit options to specify Grid Engine options for the head job.</p> </li> </ul>","title":"Advanced options"},{"location":"compute-envs/altair-pbs-pro/","text":"","title":"Altair PBS Pro"},{"location":"compute-envs/altair-pbs-pro/#overview","text":"<p>Altair PBS Pro is a workload manager and job scheduler tool provided by Altair Engineering, Inc.</p> <p>Tower streamlines the deployment of Nextflow pipelines into both cloud-based and on-prem PBS Pro clusters.</p>","title":"Overview"},{"location":"compute-envs/altair-pbs-pro/#requirements","text":"<p>To launch pipelines into a PBS Pro cluster from Tower, the following requirements must be satisfied:</p> <ul> <li>The cluster should be reachable via an SSH connection using an SSH key.</li> <li>The cluster should allow outbound connections to the Tower web service.</li> <li>The cluster queue used to run the Nextflow head job must be able to submit cluster jobs.</li> <li>The Nextflow runtime version 21.02.0-edge (or later) should be installed on the cluster.</li> </ul>","title":"Requirements"},{"location":"compute-envs/altair-pbs-pro/#compute-environment","text":"<p>To create a new compute environment for PBS Pro in Tower:</p> <ol> <li> <p>In a workspace, select Compute Environments and then New Environment.</p> </li> <li> <p>Enter a descriptive name for this environment, e.g. \"PBS Pro cluster\".</p> </li> <li> <p>Select Altair PBS Pro as the target platform.</p> </li> <li> <p>Select your credentials, or select + and SSH to add new credentials.</p> </li> <li> <p>Enter a name for the credentials.</p> </li> <li> <p>Enter your SSH private key and associated Passphrase (if required), then select Create.</p>  <p>Tip</p> <p>Your SSH key may not require a passphrase depending on how it was created. See here for detailed instructions for how to create a key.</p>  </li> <li> <p>Enter the absolute path of the Work directory to be used on the cluster.</p> </li> <li> <p>Enter the absolute path of the Launch directory to be used on the cluster. If omitted, it will be the same as the work directory.</p> </li> <li> <p>Enter the Login hostname, which is usually the hostname or public IP address of the cluster's login node.</p> </li> <li> <p>Enter the Head queue name, the cluster queue to which the Nextflow job will be submitted.</p> </li> <li> <p>Enter the Compute queue name, the cluster queue to which the Nextflow job will submit tasks.</p>  <p>Tip</p> <p>The compute queue can be overridden by the Nextflow pipeline configuration. See the Nextflow docs for more details.</p>  </li> <li> <p>You can use the Environment variables option to specify custom environment variables for the Head job and/or Compute jobs.</p> <p></p> </li> <li> <p>Configure any advanced options described below, as needed.</p> </li> <li> <p>Select Create to finalize the creation of the compute environment.</p> </li> </ol> <p>Jump to the documentation for Launching Pipelines.</p>","title":"Compute Environment"},{"location":"compute-envs/altair-pbs-pro/#advanced-options","text":"<ul> <li> <p>You can use the Nextflow queue size to limit the number of jobs that Nextflow can submit to the scheduler at the same time.</p> </li> <li> <p>You can use the Head job submit options to specify PBS options for the head job.</p> </li> </ul>","title":"Advanced options"},{"location":"compute-envs/aws-batch/","text":"","title":"AWS Batch"},{"location":"compute-envs/aws-batch/#overview","text":"<p>Requirements</p> <p>This guide assumes you have an existing Amazon Web Service (AWS) account. Sign up for a free AWS account here.</p>  <p>There are two ways to create a Compute Environment for AWS Batch with Tower.</p> <ol> <li> <p>Tower Forge: This option automatically manages the AWS Batch resources in your AWS account.</p> </li> <li> <p>Manual: This option allows you to create a compute environment using existing AWS Batch resources.</p> </li> </ol> <p>If you don't have an AWS Batch environment fully set-up yet, it is suggested to follow the Tower Forge guide.</p> <p>If you have been provided an AWS Batch queue from your account administrator, or if you have set up AWS Batch previously, please follow the Manual guide.</p>","title":"Overview"},{"location":"compute-envs/aws-batch/#tower-forge","text":"<p>Warning</p> <p>Follow these instructions only if you have not pre-configured an AWS Batch environment. Note that this option will automatically create resources in your AWS account that you may be charged for by AWS.</p>  <p>Tower Forge automates the configuration of an AWS Batch compute environment and queues required for the deployment of Nextflow pipelines.</p>","title":"Tower Forge"},{"location":"compute-envs/aws-batch/#iam-user","text":"<p>To use the Tower Forge feature, Tower requires an Identity and Access Management (IAM) user with the permissions listed in the following policy file. These authorizations are more permissive than those required to only launch a pipeline, since Tower needs to manage AWS resources on your behalf.</p> <p>The steps below will guide you through the creation of a new IAM user for Tower, plus how to attach the required policy for the newly created user.</p> <ol> <li> <p>Open the AWS IAM console.</p> </li> <li> <p>Select Users in the left-hand menu and select Add User at the top.</p> <p></p> </li> <li> <p>Enter a name for your user (e.g. <code>tower</code>) and select the Programmatic access type.</p> </li> <li> <p>Select Next: Permissions.</p> </li> <li> <p>Select Next: Tags, then Next: Review and Create User.</p> <p></p>  <p>This user has no permissions</p> <p>For the time being, you can ignore the warning. It will be addressed through our team using an IAM Policy later on.</p>  </li> <li> <p>Save the Access key ID and Secret access key in a secure location as we will use these in the next section.</p> </li> <li> <p>Once you have saved the keys, select Close.</p> <p></p> </li> <li> <p>Back in the users table, select the newly created user and select + Add inline policy to add user permissions.</p> <p></p> </li> <li> <p>Copy the content of the policy linked above into the JSON tab.</p> <p></p> </li> <li> <p>Select Review policy, then name your policy (e.g. <code>tower-forge-policy</code>), and confirm the operation by selecting Create policy.</p>  <p>Which permissions are required?</p> <p>This policy includes the minimal permissions required to allow the user to submit jobs to AWS Batch, gather the container execution metadata, read CloudWatch logs and access data from the S3 bucket in your AWS account in read-only mode.</p>  </li> </ol>","title":"IAM User"},{"location":"compute-envs/aws-batch/#s3-bucket","text":"<p>S3 stands for \"Simple Storage Service\" and is a type of object storage. To access files and store the results for our pipelines, we have to create an S3 Bucket and grant our new Tower IAM user access to it.</p> <ol> <li> <p>Navigate to S3 service.</p> </li> <li> <p>Select Create New Bucket.</p> </li> <li> <p>Enter a unique name for your Bucket and select a region.</p> <p></p>  <p>Which AWS region should I use?</p> <p>The region of the bucket should be in the same region as the compute environment that we create in the next section. Typically users select a region closest to their physical location but Tower Forge supports creating resources in any available AWS region.</p>  </li> <li> <p>Select the default options for Configure options.</p> <p></p> </li> <li> <p>Select the default options for Set permissions.</p> <p></p> </li> <li> <p>Review and select Create bucket.</p> <p></p>  <p>S3 Storage Costs</p> <p>S3 is used by Nextflow for the storage of intermediate files. For production pipelines, this can amount to a large quantity of data. To reduce costs, when configuring a bucket, users should consider using a retention policy, such as automatically deleting intermediate files after 30 days. For more information on this process, see here.</p>  </li> </ol>  <p>Congratulations!</p> <p>You have completed the AWS environment setup for Tower.</p>","title":"S3 Bucket"},{"location":"compute-envs/aws-batch/#compute-environment","text":"<p>Tower Forge automates the configuration of an AWS Batch compute environment and queues required for the deployment of Nextflow pipelines.</p> <p>Once the AWS resources are set up, we can add a new AWS Batch environment in Tower. To create a new compute environment:</p> <ol> <li> <p>In a workspace, select Compute Environments and then New Environment.</p> </li> <li> <p>Enter a descriptive name for this environment, e.g. \"AWS Batch Spot (eu-west-1)\"</p> </li> <li> <p>Select Amazon Batch as the target platform.</p> <p></p> </li> <li> <p>Select your AWS credentials or add new credentials by selecting the + button.</p> </li> <li> <p>Enter a name, e.g. \"AWS Credentials\".</p> </li> <li> <p>Add the Access key and Secret key. These are the keys we saved previously when we created the AWS IAM user.</p> <p></p>  <p>Multiple credentials</p> <p>You can create multiple credentials in your Tower environment.</p>  </li> <li> <p>Select a Region, for example \"eu-west-1 - Europe (Ireland)\".</p> </li> <li> <p>Enter the Pipeline work directory as the S3 bucket we created in the previous section, e.g. <code>s3://unique-tower-bucket</code>.</p>  <p>Warning</p> <p>The bucket should be in the same Region from the previous step.</p>  </li> <li> <p>Set the Config mode to Batch Forge.</p> <p></p> </li> <li> <p>Select a Provisioning model. In most cases this will be Spot.</p>  <p>Spot or On-demand?</p> <p>You can choose to create a compute environment that launches either Spot or On-demand instances. Spot instances can cost as little as 20% of on-demand instances, and with Nextflow's ability to automatically relaunch failed tasks, Spot is almost always the recommended provisioning model.</p> <p>Note, however, that when choosing Spot instances, Tower will also create a dedicated queue for running the main Nextflow job using a single on-demand instance in order to prevent any execution interruptions.</p>  <p></p> </li> <li> <p>Enter the Max CPUs e.g. <code>64</code>. This is the maximum number of combined CPUs (the sum of all instances CPUs) AWS Batch will provision at any time.</p> </li> <li> <p>Select EBS Auto scale to allow the EC2 virtual machines to dynamically expand the amount of available disk space during task execution.</p> </li> <li> <p>With the optional Enable Fusion mounts feature enabled, S3 buckets specified in Pipeline work directory and Allowed S3 Buckets will be mounted as file system volumes in the EC2 instances carrying out the Batch job execution. These buckets will be accessible at <code>/fusion/s3/&lt;bucket-name&gt;</code>. For example, if the bucket name is <code>s3://imputation-gp2</code>, the Nextflow pipeline will access it using the file system path <code>/fusion/s3/imputation-gp2</code>.</p>  <p>Tip</p> <p>You are not required to modify your pipeline or files to take advantage of this feature. Nextflow is able to recognise these buckets automatically and will replace any reference to files prefixed with <code>s3://</code> with the corresponding Fusion mount paths.</p>  </li> <li> <p>Select Enable GPUs to allow the deployment of GPU-enabled EC2 instances if required.</p> </li> <li> <p>Enter any additional Allowed S3 buckets that your workflows require to read input data or write output data. The Pipeline work directory bucket above is added by default to the list of Allowed S3 buckets.</p> </li> <li> <p>To use EFS, you can either select Use existing EFS file system and specify an existing EFS instance or select Create new EFS file system to create one automatically.</p> </li> <li> <p>To use FSx, set the FSx mount path to <code>/fsx</code> and set the Pipeline work directory to <code>/fsx/work</code>.</p> <p></p> </li> <li> <p>Select Dispose resources if you want Tower to automatically delete these AWS resources if you delete the compute environment in Tower.</p> </li> <li> <p>You can use the Environment variables option to specify custom environment variables for the Head job and/or Compute jobs.</p> <p></p> </li> <li> <p>Configure any advanced options described below, as needed.</p> </li> <li> <p>Select Create to finalize the compute environment setup. It will take a few seconds for all the resources to be created, and then you will be ready to launch pipelines.</p> <p></p> </li> </ol> <p>Jump to the documentation for Launching Pipelines.</p>","title":"Compute Environment"},{"location":"compute-envs/aws-batch/#advanced-options","text":"<ul> <li> <p>You can specify the Allocation strategy and indicate the preferred Instance types to AWS Batch.</p> </li> <li> <p>You can configure your custom networking setup using the VPC, Subnets and Security groups fields.</p> </li> <li> <p>You can use your own AMI.</p>  <p>Requirements for custom AMI</p> <p>To use a custom AMI, make sure the AMI is based on an Amazon Linux-2 ECS optimized image that meets the Batch requirements. To learn more about approved versions of the Amazon ECS optimized AMI, visit this link</p>  </li> <li> <p>If you need to debug the EC2 instance provisioned by AWS Batch, specify a Key pair to login to the instance via SSH.</p> </li> <li> <p>You can set Min CPUs to be greater than <code>0</code>, in which case some EC2 instances will remain active. An advantage of this is that pipeline executions will initialize faster.</p>  <p>Increasing Min CPUs may increase AWS costs</p> <p>Keeping EC2 instances running may result in additional costs. You will be billed for these running EC2 instances regardless of whether you are executing pipelines or not.</p>  <p></p> </li> <li> <p>You can use Head Job CPUs and Head Job Memory to specify the hardware resources allocated for the Head Job.</p> </li> <li> <p>You can use Head Job role and Compute Job role to grant fine-grained IAM permissions to the Head Job and Compute Jobs</p> </li> <li> <p>If you're using Spot instances, then you can also specify the Cost percentage, which is the maximum allowed price of a Spot instance as a percentage of the On-Demand price for that instance type. Spot instances will not be launched until the current spot price is below the specified cost percentage.</p> <p></p> </li> <li> <p>You can use AWS CLI tool path to specify the location of the <code>aws</code> CLI.</p> </li> </ul>","title":"Advanced options"},{"location":"compute-envs/aws-batch/#manual","text":"<p>This section is for users with a pre-configured AWS environment. You will need a Batch queue, a Batch compute environment, an IAM user and an S3 bucket already set up.</p> <p>To enable Tower within your existing AWS configuration, you need to have an IAM user with the following IAM permissions:</p> <ul> <li><code>AmazonS3ReadOnlyAccess</code></li> <li><code>AmazonEC2ContainerRegistryReadOnly</code></li> <li><code>CloudWatchLogsReadOnlyAccess</code></li> <li>A custom policy to grant the ability to submit and control Batch jobs.</li> <li>Write access to any S3 bucket used by pipelines with the following policy template. See below for details</li> </ul> <p>With these permissions set, we can add a new AWS Batch compute environment in Tower.</p>","title":"Manual"},{"location":"compute-envs/aws-batch/#access-to-s3-buckets","text":"<p>Tower can use S3 to store intermediate and output data generated by pipelines. We need to create a policy for our Tower IAM user that grants access to specific buckets.</p> <ol> <li> <p>Go to the IAM User table in the IAM service</p> </li> <li> <p>Select the IAM user.</p> </li> <li> <p>Select Add inline policy.</p> <p></p> </li> <li> <p>Copy the contents of this policy into the JSON tab. Replace <code>YOUR-BUCKET-NAME</code> (lines 10 and 21) with your bucket name.</p> <p></p> </li> <li> <p>Name your policy and select Create policy.</p> </li> </ol>","title":"Access to S3 Buckets"},{"location":"compute-envs/aws-batch/#compute-environment_1","text":"<p>To create a new compute environment for AWS Batch (without Forge):</p> <ol> <li> <p>In a workspace, select Compute Environments and then New Environment.</p> </li> <li> <p>Enter a descriptive name for this environment, e.g. \"AWS Batch Manual (eu-west-1)\".</p> </li> <li> <p>Select Amazon Batch as the target platform.</p> <p></p> </li> <li> <p>Add new credentials by selecting the + button.</p> </li> <li> <p>Enter a name for the credentials, e.g. \"AWS Credentials\".</p> </li> <li> <p>Enter the Access key and Secret key for your IAM user.</p> <p></p>  <p>Multiple credentials</p> <p>You can create multiple credentials in your Tower environment. See the Credentials Management section.</p>  </li> <li> <p>Select a Region, e.g. \"eu-west-1 - Europe (Ireland)\"</p> </li> <li> <p>Enter an S3 bucket path for the Pipeline work directory, for example <code>s3://tower-bucket</code></p> </li> <li> <p>Set the Config mode to Manual.</p> </li> <li> <p>Enter the Head queue, which is the name of the AWS Batch queue that the Nextflow driver job will run.</p> </li> <li> <p>Enter the Compute queue, which is the name of the AWS Batch queue that tasks will be submitted to.</p> </li> <li> <p>You can use the Environment variables option to specify custom environment variables for the Head job and/or Compute jobs.</p> <p></p> </li> <li> <p>Configure any advanced options described below, as needed.</p> </li> <li> <p>Select Create to finalize the compute environment setup.</p> <p></p> </li> </ol> <p>Jump to the documentation for Launching Pipelines.</p>","title":"Compute Environment"},{"location":"compute-envs/aws-batch/#advanced-options_1","text":"<ul> <li> <p>You can use Head Job CPUs and Head Job Memory to specify the hardware resources allocated for the Head Job.</p> </li> <li> <p>You can use Head Job role and Compute Job role to grant fine-grained IAM permissions to the Head Job and Compute Jobs</p> </li> <li> <p>You can use AWS CLI tool path to specify the location of the <code>aws</code> CLI.</p> </li> </ul>","title":"Advanced options"},{"location":"compute-envs/azure-batch/","text":"","title":"Azure Batch"},{"location":"compute-envs/azure-batch/#overview","text":"<p>Warning</p> <p>The Tower support for Azure Batch is currently in beta. Any feedback and suggestions are welcome.</p> <p>In order to manage capacity during the global health pandemic, Microsoft has reduced core quotas for new Batch accounts. Depending on your region and subscription type, a newly-created account may not be entitled to any VMs without first making a service request to Azure.</p> <p>Please see Azure's Batch service quotas and limits page for further details.</p>   <p>Requirements</p> <p>This guide assumes you have an existing Azure Account. Sign up for a free Azure account here.</p>  <p>There are two ways to create a Compute Environment for Azure Batch with Tower.</p> <ol> <li> <p>Tower Forge: This option automatically manages the Azure Batch resources in your Azure account.</p> </li> <li> <p>Manual: This option allows you to create a compute environment using existing Azure Batch resources.</p> </li> </ol> <p>If you don't yet have an Azure Batch environment fully set up, it is suggested that you follow the Tower Forge guide.</p> <p>If you have been provided an Azure Batch queue from your account administrator, or if you have set up Azure Batch previously, directly follow the Manual guide.</p>","title":"Overview"},{"location":"compute-envs/azure-batch/#tower-forge","text":"<p>Warning</p> <p>Follow these instructions only if you have not pre-configured an Azure Batch environment. Note that this option will create resources in your Azure account that you may be charged for by Azure.</p>","title":"Tower Forge"},{"location":"compute-envs/azure-batch/#resource-group","text":"<p>To create the necessary Azure Batch and Azure Storage accounts, we must first create a resource group in the region of your choice.</p> <p>When you open this link, you'll notice the Create new resource group dialogue as shown below.</p> <p></p> <ol> <li> <p>Enter a name for the resource group (e.g. <code>towerrg</code>).</p> </li> <li> <p>Select the preferred region for this resource group.</p> </li> <li> <p>Select Review and Create to proceed to the review screen.</p> </li> <li> <p>Select Create to create the resources.</p> </li> </ol>","title":"Resource group"},{"location":"compute-envs/azure-batch/#storage-account","text":"<p>The next step is to create the necessary Azure Storage.</p> <p>When you open this link, you'll notice the Create a storage account dialogue as shown below.</p> <p></p> <ol> <li> <p>Enter a name for the storage account (e.g. <code>towerrgstorage</code>).</p> </li> <li> <p>Select the preferred region for this resource group.</p> </li> <li> <p>Select Review and Create to proceed to the review screen.</p> </li> <li> <p>Select Create to create the Azure Storage account.</p> </li> <li> <p>Next, create a Blob container within this storage account by navigating to your new storage account and selecting Container as shown below.</p> <p></p> </li> <li> <p>Create a new Blob container by selecting + Container.</p> <p>A new container dialogue will open as shown below. Enter a suitable name (e.g. <code>towerrgstorage-container</code>).</p> <p></p> </li> <li> <p>Once the new Blob container is created, navigate to the Access Keys section of the storage account (<code>towerrgstorage</code> in this example).</p> </li> <li> <p>Store the access keys for the newly created Azure Storage account as shown below.</p> <p></p> </li> </ol>","title":"Storage account"},{"location":"compute-envs/azure-batch/#batch-account","text":"<p>The next step is to create the necessary Batch account.</p> <p>When you open this link, you'll notice the Create a batch account dialogue, as shown below.</p> <p></p> <ol> <li> <p>Enter a name for the storage account (e.g. <code>towerrgbatch</code>).</p> </li> <li> <p>Select the preferred region for this resource group.</p> </li> <li> <p>Select Review and Create to proceed to the review screen.</p> </li> <li> <p>Select Create to create the Azure Batch account.</p> </li> </ol>  <p>Congratulations!</p> <p>You have completed the Azure environment setup for Tower.</p>","title":"Batch account"},{"location":"compute-envs/azure-batch/#compute-environment","text":"<p>Tower Forge automates the configuration of an Azure Batch compute environment and queues required for the deployment of Nextflow pipelines.</p> <p>Once the Azure resources are set up, we can add a new Azure Batch environment in Tower. To create a new compute environment:</p> <ol> <li> <p>In a workspace, select Compute Environments and then New Environment.</p> </li> <li> <p>Enter a descriptive name for this environment, e.g. \"Azure Batch (east-us)\"</p> </li> <li> <p>Select Azure Batch as the target platform.</p> <p></p> </li> <li> <p>Select your Azure credentials or add new credentials by selecting the + button.</p> </li> <li> <p>Enter a name, e.g. \"Azure Credentials\".</p> </li> <li> <p>Add the Access key and Secret key. These are the keys we saved previously when creating the Azure resources.</p> <p></p>  <p>Multiple credentials</p> <p>You can create multiple credentials in your Tower environment.</p>  </li> <li> <p>Select a Region, for example \"eastus (East US)\".</p> </li> <li> <p>Enter the Pipeline work directory as the Azure blob container we created in the previous section, e.g. <code>az://towerrgstorage-container/work</code>.</p> <p></p>  <p>Warning</p> <p>The blob container should be in the same Region from the previous step.</p>  </li> <li> <p>Set the Config mode to Batch Forge.</p> <p></p> </li> <li> <p>Enter the default VM type depending on your quota limits. The default is <code>Standard_D4_v3</code>.</p> </li> <li> <p>Enter the VMs count, which is the number of VMs you'd like to deploy.</p> </li> <li> <p>Enable Autoscale if you'd like to automatically scale up and down based on the number of tasks. The number of VMs will vary from 0 to VMs count.</p> </li> <li> <p>Enable Dispose resources if you'd like Tower to automatically delete the Batch pool once the workflow is complete.</p> </li> <li> <p>Configure any advanced options described below, as needed.</p> </li> <li> <p>Select Create to finalize the compute environment setup. It will take a few seconds for all the resources to be created, and then you will be ready to launch pipelines.</p> <p></p> </li> </ol> <p>Jump to the documentation for Launching Pipelines.</p>","title":"Compute Environment"},{"location":"compute-envs/azure-batch/#advanced-options","text":"<ul> <li> <p>You can use the Jobs cleanup policy to control how jobs should be deleted on workflow completion.</p> <p></p> </li> <li> <p>You can use the Token duration to control the duration of the SAS token generated by Nextflow.</p> </li> </ul>","title":"Advanced options"},{"location":"compute-envs/azure-batch/#manual","text":"<p>This section is for users with a pre-configured Azure environment. You will need an Azure Batch account and Storage account already set up.</p> <p>To create a new compute environment for AWS Batch (without Forge):</p> <ol> <li> <p>In a workspace, select Compute Environments and then New Environment.</p> </li> <li> <p>Enter a descriptive name for this environment, e.g. \"Azure Batch (east-us)\"</p> </li> <li> <p>Select Azure Batch as the target platform.</p> <p></p> </li> <li> <p>Select your Azure credentials or add new credentials by selecting the + button.</p> </li> <li> <p>Enter a name, e.g. \"Azure Credentials\".</p> </li> <li> <p>Add the Access key and Secret key. These are the keys we saved previously when creating the Azure resources.</p> <p></p>  <p>Multiple credentials</p> <p>You can create multiple credentials in your Tower environment.</p>  </li> <li> <p>Select a Region, for example \"eastus (East US)\".</p> </li> <li> <p>Enter the Pipeline work directory as the Azure blob container we created in the previous section, e.g. <code>az://towerrgstorage-container/work</code>.</p> <p></p>  <p>Warning</p> <p>The blob container should be in the same Region from the previous step.</p>  </li> <li> <p>Set the Config mode to Manual.</p> </li> <li> <p>Enter the Compute Pool name, the name of the Azure Batch pool provided to you by your Azure administrator.</p> <p></p> </li> <li> <p>You can use the Environment variables option to specify custom environment variables for the Head job and/or Compute jobs.</p> <p></p> </li> <li> <p>Configure any advanced options described below, as needed.</p> </li> <li> <p>Select Create to finalize the compute environment setup. It will take a few seconds for all the resources to be created, and then you will be ready to launch pipelines.</p> <p></p> </li> </ol> <p>Jump to the documentation for Launching Pipelines.</p>","title":"Manual"},{"location":"compute-envs/azure-batch/#advanced-options_1","text":"<ul> <li> <p>You can use the Jobs cleanup policy to control how jobs should be deleted on workflow completion.</p> <p></p> </li> <li> <p>You can use the Token duration to control the duration of the SAS token generated by Nextflow.</p> </li> </ul>","title":"Advanced options"},{"location":"compute-envs/eks/","text":"","title":"Amazon EKS"},{"location":"compute-envs/eks/#overview","text":"<p>Amazon EKS is a managed Kubernetes cluster that allows the execution of containerized workloads in the AWS cloud at scale.</p> <p>Tower offers native support for AWS EKS clusters and streamlines the deployment of Nextflow pipelines in such environments.</p>","title":"Overview"},{"location":"compute-envs/eks/#requirements","text":"<p>You need to have an EKS cluster up and running. Make sure you have followed the cluster preparation instructions to create the cluster resources required by Tower. In addition to the generic Kubernetes instructions, you will need to make a few modifications specific to EKS.</p> <p>Assign service account role to IAM user. You will need to assign the service role with an AWS user that will be used by Tower to access the EKS cluster.</p> <p>First, use the following command to modify the EKS auth configuration: <pre>1</pre><pre><code>kubectl edit configmap -n kube-system aws-auth\n</code></pre> </p> <p>Once the editor is open, add the following entry: <pre>1\n2\n3\n4\n5</pre><pre><code>  mapUsers: |\n    - userarn: &lt;AWS USER ARN&gt;\n      username: tower-launcher-user\n      groups:\n        - tower-launcher-role\n</code></pre> </p> <p>Your user ARN can be retrieved from the AWS IAM console or from the AWS CLI: <pre>1</pre><pre><code>aws sts get-caller-identity\n</code></pre> </p>  <p>Note</p> <p>The same user needs to be used when specifying the AWS credentials in the configuration of the Tower compute environment for EKS.</p>  <p>The AWS user should have the following IAM policy:</p>  Click to view eks-iam-policy.json <pre>1</pre><pre><code>\n</code></pre>   <p>For more details, refer to the AWS documentation.</p>","title":"Requirements"},{"location":"compute-envs/eks/#compute-environment","text":"<ol> <li> <p>In a workspace, select Compute Environments and then New Environment.</p> </li> <li> <p>Enter a descriptive name for this environment, e.g. \"Amazon EKS (eu-west-1)\".</p> </li> <li> <p>Select Amazon EKS as the target platform.</p> <p> </p> </li> <li> <p>Select your AWS credentials or add new credentials by selecting the + button.</p>  <p>Note</p> <p>Make sure the user has the IAM permissions required to describe and list EKS clusters as explained here.</p>  </li> <li> <p>Select a Region, for example \"eu-west-1 - Europe (Ireland)\".</p> </li> <li> <p>Select a Cluster name from the list of available EKS clusters in the selected region.</p> </li> <li> <p>Specify the Namespace created in the cluster preparation instructions, which is <code>tower-nf</code> by default.</p> </li> <li> <p>Specify the Head service account created in the cluster preparation instructions, which is <code>tower-launcher-sa</code> by default.</p> </li> <li> <p>Specify the Storage claim created in the cluster preparation instructions, which serves as a scratch filesystem for Nextflow pipelines. In each of the provided examples, the storage claim is called <code>tower-scratch</code>.</p> </li> <li> <p>You can use the Environment variables option to specify custom environment variables for the Head job and/or Compute jobs.</p> <p></p> </li> <li> <p>Configure any advanced options described below, as needed.</p> </li> <li> <p>Select Create to finalize the compute environment setup.</p> <p> </p> </li> </ol> <p>Jump to the documentation for Launching Pipelines.</p>","title":"Compute Environment"},{"location":"compute-envs/eks/#advanced-options","text":"<ul> <li> <p>The Storage mount path is the file system path where the Storage claim is mounted (default: <code>/scratch</code>).</p> </li> <li> <p>The Work directory is the file system path used as a working directory by Nextflow pipelines. It must be the the storage mount path (default) or a subdirectory of it.</p> </li> <li> <p>The Compute service account is the service account used by Nextflow to submit tasks (default: the <code>default</code> account in the given namespace).</p> </li> <li> <p>The Pod cleanup policy determines when terminated pods should be deleted.</p> </li> <li> <p>You can use Custom head pod specs to provide custom options for the Nextflow workflow pod (<code>nodeSelector</code>, <code>affinity</code>, etc). For example:     <pre>1\n2\n3</pre><pre><code>spec:\n  nodeSelector:\n    disktype: ssd\n</code></pre> </p> </li> <li> <p>You can use Custom service pod specs to provide custom options for the compute environment pod. See above for an example.</p> </li> <li> <p>You can use Head Job CPUs and Head Job Memory to specify the hardware resources allocated for the Nextflow workflow pod.</p> </li> </ul>","title":"Advanced options"},{"location":"compute-envs/gke/","text":"","title":"Google GKE"},{"location":"compute-envs/gke/#overview","text":"<p>Google GKE is a managed Kubernetes cluster that allows the execution of containerized workloads in Google Cloud at scale.</p> <p>Tower offers native support for Google GKE clusters and streamlines the deployment of Nextflow pipelines in such environments.</p>","title":"Overview"},{"location":"compute-envs/gke/#requirements","text":"<p>You need to have a GKE cluster up and running. Make sure you have followed the cluster preparation instructions to create the cluster resources required by Tower. In addition to the generic Kubernetes instructions, you will need to make a few modifications specific to GKE.</p> <p>Assign service account role to IAM user. You will need to grant the cluster access to the service account used to authenticate the Tower compute environment. This can be done by updating the role binding as shown below:</p> <pre> 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16</pre><pre><code>cat &lt;&lt; EOF | kubectl apply -f -\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: tower-launcher-userbind\nsubjects:\n  - kind: User\n    name: &lt;IAM SERVICE ACCOUNT&gt;\n    apiGroup: rbac.authorization.k8s.io\nroleRef:\n  kind: Role\n  name: tower-launcher-role\n  apiGroup: rbac.authorization.k8s.io\n...\nEOF\n</code></pre>  <p>In the above snippet, replace <code>&lt;IAM SERVICE ACCOUNT&gt;</code> with the corresponding service account, e.g. <code>test-account@test-project-123456.google.com.iam.gserviceaccount.com</code>.</p> <p>For more details, refer to the Google documentation.</p>","title":"Requirements"},{"location":"compute-envs/gke/#compute-environment","text":"<ol> <li> <p>In a workspace, select Compute Environments and then New Environment.</p> </li> <li> <p>Enter a descriptive name for this environment, e.g. \"Google GKE (europe-west1)\".</p> </li> <li> <p>Select Google GKE as the target platform.</p> <p></p> </li> <li> <p>Select your Google Cloud credentials or add new credentials by selecting the + button.</p> </li> <li> <p>Select the Location of your GKE cluster.</p>  <p>Regional and zonal clusters</p> <p>GKE clusters can be either regional or zonal. For example, <code>us-west1</code> identifies the United States West-Coast region, which has three zones: <code>us-west1-a</code>, <code>us-west1-b</code>, and <code>us-west1-c</code>.</p> <p>Tower self-completion only shows regions. You should manually edit this field if you are using a zonal GKE cluster.</p>  <p></p> </li> <li> <p>Select or enter the Cluster name of your GKE cluster.</p> </li> <li> <p>Specify the Namespace created in the cluster preparation instructions, which is <code>tower-nf</code> by default.</p> </li> <li> <p>Specify the Head service account created in the cluster preparation instructions, which is <code>tower-launcher-sa</code> by default.</p> </li> <li> <p>Specify the Storage claim created in the cluster preparation instructions, which serves as a scratch filesystem for Nextflow pipelines. In each of the provided examples, the storage claim is called <code>tower-scratch</code>.</p> </li> <li> <p>You can use the Environment variables option to specify custom environment variables for the Head job and/or Compute jobs.</p> <p></p> </li> <li> <p>Configure any advanced options described below, as needed.</p> </li> <li> <p>Select Create to finalize the compute environment setup.</p> <p> </p> </li> </ol> <p>Jump to the documentation for Launching Pipelines.</p>","title":"Compute Environment"},{"location":"compute-envs/gke/#advanced-options","text":"<ul> <li> <p>The Storage mount path is the file system path where the Storage claim is mounted (default: <code>/scratch</code>).</p> </li> <li> <p>The Work directory is the file system path used as a working directory by Nextflow pipelines. It must be the the storage mount path (default) or a subdirectory of it.</p> </li> <li> <p>The Compute service account is the service account used by Nextflow to submit tasks (default: the <code>default</code> account in the given namespace).</p> </li> <li> <p>The Pod cleanup policy determines when terminated pods should be deleted.</p> </li> <li> <p>You can use Custom head pod specs to provide custom options for the Nextflow workflow pod (<code>nodeSelector</code>, <code>affinity</code>, etc). For example:     <pre>1\n2\n3</pre><pre><code>spec:\n  nodeSelector:\n    disktype: ssd\n</code></pre> </p> </li> <li> <p>You can use Custom service pod specs to provide custom options for the compute environment pod. See above for an example.</p> </li> <li> <p>You can use Head Job CPUs and Head Job Memory to specify the hardware resources allocated for the Nextflow workflow pod.</p> </li> </ul>","title":"Advanced options"},{"location":"compute-envs/google-cloud/","text":"","title":"Google Cloud Life Sciences"},{"location":"compute-envs/google-cloud/#overview","text":"<p>Requirements</p> <p>This guide assumes you have an existing Google Cloud Account. Sign-up for a free account here.</p>  <p>Tower provides integration to Google Cloud via the Cloud Life Sciences API.</p> <p>The guide is split into two parts:</p> <ol> <li> <p>How to configure your Google Cloud account to use the Google Life Sciences API.</p> </li> <li> <p>How to create a Google Cloud compute environment in Tower.</p> </li> </ol>","title":"Overview"},{"location":"compute-envs/google-cloud/#configure-google-cloud","text":"","title":"Configure Google Cloud"},{"location":"compute-envs/google-cloud/#create-a-project","text":"<p>Navigate to the Google Project Selector page and either select an existing project or select Create project.</p> <p></p> <p>Enter a name for your new project, e.g \"tower-nf\".</p> <p>If you are part of an organization, the location will default to your organization.</p> <p></p>","title":"Create a project"},{"location":"compute-envs/google-cloud/#enable-billing","text":"<p>In the navigation menu (\u2261), select Billing. You can follow these instructions to enable billing.</p> <p></p>","title":"Enable billing"},{"location":"compute-envs/google-cloud/#enable-apis","text":"<p>Use this link to enable the following APIs for your project:</p> <ul> <li>Cloud Life Sciences API</li> <li>Compute Engine API</li> <li>Cloud Storage API</li> </ul> <p>Select your project from the dropdown menu and select Enable.</p> <p>Alternatively, you can enable each API manually by selecting your project in the nav bar and visiting each API page:</p> <ul> <li> <p>Cloud Life Sciences API</p> </li> <li> <p>Compute Engine API</p> </li> <li> <p>Cloud Storage API</p> </li> </ul> <p></p>","title":"Enable APIs"},{"location":"compute-envs/google-cloud/#create-service-account-key","text":"<ol> <li> <p>In the navigation menu, select IAM &amp; Admin and then Service Accounts.</p> </li> <li> <p>Select the email address of the Compute Engine default service account.</p> </li> <li> <p>Select Keys, then Add key, then Create new key.</p> <p></p> </li> <li> <p>Select JSON as the key type.</p> </li> <li> <p>Select Create.</p> <p></p> </li> </ol> <p>A JSON file will be downloaded to your computer. This file contains the credential that will be used by Tower. You will need it to configure the Tower compute environment.</p> <p>You can manage your key from the Service Accounts page.</p> <p></p>","title":"Create service account key"},{"location":"compute-envs/google-cloud/#create-a-cloud-storage-bucket","text":"<ol> <li> <p>In the navigation menu (\u2261), select Cloud Storage and then Create bucket.</p> <p></p> </li> <li> <p>Enter a name for your bucket. You will reference this name when creating the Tower compute environment.</p>  <p>Warning</p> <p>Do not use underscores (_) in your bucket name. Use hyphens instead.</p>  </li> <li> <p>Select Region for the Location type and select the Location for your bucket. You will reference this location when creating the Tower compute environment.</p> </li> <li> <p>Select Standard for the default storage class.</p> </li> <li> <p>Select Uniform for the Access control.</p> <p></p>  <p>Note</p> <p>The Google Cloud Life Sciences API is available in a limited number of locations. However, these locations are only used to store metadata about the pipeline operations. The storage bucket and compute resources can be in any region.</p>  </li> <li> <p>Select Create.</p> </li> <li> <p>Once the bucket is created, you will be redirected to the Bucket details page.</p> </li> <li> <p>Select Permissions, then + Add.</p> </li> <li> <p>Copy the email address of the Compute Engine default service account into New principals.</p> </li> <li> <p>Select the following roles:</p> <ul> <li>Storage Admin</li> <li>Storage Legacy Bucket Owner</li> <li>Storage Legacy Object Owner</li> <li>Storage Object Creator</li> </ul> <p></p> </li> </ol>  <p>Congratulations!</p> <p>You have created a project, enabled the necessary Google APIs, created a bucket and a JSON file containing required credentials. You are now ready to set up a new compute environment in Tower.</p>","title":"Create a Cloud Storage bucket"},{"location":"compute-envs/google-cloud/#configure-tower","text":"<p>Requirements</p> <p>The following guide to configure Tower assumes you have (1) a service account key for a Google Cloud account and (2) the name and location of a Cloud Storage bucket.</p>  <p>To create a new compute environment for Google Cloud in Tower:</p> <ol> <li> <p>In a workspace, select Compute Environments and then New Environment.</p> </li> <li> <p>Enter a descriptive name for this environment, e.g. \"Google Life Sciences (europe-west2)\".</p> </li> <li> <p>Select Google Life Sciences as the target platform.</p> <p></p> </li> <li> <p>Add new credentials by selecting the + button.</p> </li> <li> <p>Enter a name for the credentials, e.g. \"Google Cloud Credentials\".</p> </li> <li> <p>Enter the Service account key for your Google Cloud account. This key was created in the previous section.</p> <p></p> </li> <li> <p>Select the Region and Zones where you'd like to execute pipelines.</p> <p></p> <p>You can leave the Location empty and Google Life Sciences API will use the closest available location.</p> </li> <li> <p>Enter your bucket URL for the Pipeline work directory. The URL is the name of your bucket with the <code>gs://</code> prefix, e.g. <code>gs://my-bucket</code>.</p> <p>This bucket should be accessible in the region selected in the previous step.</p> </li> <li> <p>You can enable Preemptible to use preemptible instances, which have significantly reduced cost compared to on-demand instances.</p> </li> <li> <p>You can use a Filestore file system to automatically mount a Google Filestore volume in your pipelines.</p> <p></p> </li> <li> <p>You can use the Environment variables option to specify custom environment variables for the Head job and/or Compute jobs.</p> <p></p> </li> <li> <p>Configure any advanced options described below, as needed.</p> </li> <li> <p>Select Create to finalize the compute environment setup.</p> <p></p> </li> </ol> <p>Jump to the documentation for Launching Pipelines.</p>","title":"Configure Tower"},{"location":"compute-envs/google-cloud/#advanced-options","text":"<ul> <li> <p>You can enable Use Private Address to ensure that your Google Cloud VMs aren't accessible to the public internet.</p> </li> <li> <p>You can use Boot disk size to control the boot disk size of head jobs.</p> </li> <li> <p>You can use Head Job CPUs and Head Job Memory to specify the CPUs and memory allocated for head jobs.</p> </li> </ul>","title":"Advanced options"},{"location":"compute-envs/k8s/","text":"","title":"Kubernetes"},{"location":"compute-envs/k8s/#overview","text":"<p>Kubernetes is the leading technology for deployment and orchestration of containerized workloads in cloud-native environments.</p> <p>Tower streamlines the deployment of Nextflow pipelines into Kubernetes both for cloud-based and on-prem clusters.</p> <p>The following instructions are for a generic Kubernetes distribution. If you are using Amazon EKS or Google GKE, see the corresponding documentation pages.</p>","title":"Overview"},{"location":"compute-envs/k8s/#cluster-preparation","text":"<p>This section describes the steps required to prepare your Kubernetes cluster for the deployment of Nextflow pipelines using Tower. It is assumed the cluster itself has already been created and you have administrative privileges.</p> <ol> <li> <p>Verify the connection to your Kubernetes cluster:     <pre>1</pre><pre><code>kubectl cluster-info\n</code></pre> </p> </li> <li> <p>Create the Tower launcher:     <pre>1</pre><pre><code>kubectl apply -f https://help.tower.nf/22.1/_templates/tower-launcher.yml\n</code></pre> </p> <p>This command creates a service account called <code>tower-launcher-sa</code>, and associated role bindings. Everything is contained in a namespace called <code>tower-nf</code>. The service account is used by Tower to launch Nextflow pipelines. Use this service account name when setting up the compute environment for this Kubernetes cluster in Tower.</p> </li> <li> <p>Create persistent storage. Tower requires a <code>ReadWriteMany</code> persistent volume claim (PVC) that is mounted by all nodes where workflow pods will be dispatched.</p> <p>You can use any storage solution that supports the <code>ReadWriteMany</code> access mode. The setup of this storage is beyond the scope of these instructions, because the right solution for you will depend on what is available for your infrastructure or cloud vendor (NFS, GlusterFS, CephFS, Amazon FSx, etc). Ask your cluster administrator for more information.</p> <ul> <li> <p>Example PVC backed by local storage: tower-scratch-local.yml</p> </li> <li> <p>Example PVC backed by NFS server: tower-scratch-nfs.yml</p> </li> </ul> </li> </ol>","title":"Cluster Preparation"},{"location":"compute-envs/k8s/#compute-environment","text":"<ol> <li> <p>In a workspace, select Compute Environments and then New Environment.</p> </li> <li> <p>Enter a descriptive name for this environment, e.g. \"K8s cluster\".</p> </li> <li> <p>Select Kubernetes as the target platform.</p> <p></p> </li> <li> <p>Select your Kubernetes credentials or add new credentials by selecting the + button.</p> </li> <li> <p>Enter a name, e.g. \"K8s Credentials\".</p> </li> <li> <p>Enter the Service account token.</p> <p></p> <p>The token can be obtained with the following command: <pre>1\n2</pre><pre><code>SECRET=$(kubectl get secrets | grep &lt;SERVICE-ACCOUNT-NAME&gt; | cut -f1 -d ' ')\nkubectl describe secret $SECRET | grep -E '^token' | cut -f2 -d':' | tr -d '\\t'\n</code></pre> </p> <p>Replace <code>&lt;SERVICE-ACCOUNT-NAME&gt;</code> with the name of the service account created in the cluster preparation instructions, which is <code>tower-launcher-sa</code> by default.</p> </li> <li> <p>Enter the Master server URL.</p> <p>The master server URL can be obtained with the following command: <pre>1</pre><pre><code>kubectl cluster-info\n</code></pre> </p> <p>It can also be found in your <code>~/.kube/config</code> file under the <code>server</code> field corresponding to your cluster.</p> </li> <li> <p>Specify the SSL Certificate to authenticate your connection.</p> <p>The certificate data can be found in your <code>~/.kube/config</code> file. It is the <code>certificate-authority-data</code> field corresponding to your cluster.</p> </li> <li> <p>Specify the Namespace created in the cluster preparation instructions, which is <code>tower-nf</code> by default.</p> </li> <li> <p>Specify the Head service account created in the cluster preparation instructions, which is <code>tower-launcher-sa</code> by default.</p> </li> <li> <p>Specify the Storage claim created in the cluster preparation instructions, which serves as a scratch filesystem for Nextflow pipelines. In each of the provided examples, the storage claim is called <code>tower-scratch</code>.</p> </li> <li> <p>You can use the Environment variables option to specify custom environment variables for the Head job and/or Compute jobs.</p> <p></p> </li> <li> <p>Configure any advanced options described below, as needed.</p> </li> <li> <p>Select Create to finalize the compute environment setup.</p> <p> </p> </li> </ol> <p>Jump to the documentation for Launching Pipelines.</p>","title":"Compute Environment"},{"location":"compute-envs/k8s/#advanced-options","text":"<ul> <li> <p>The Storage mount path is the file system path where the Storage claim is mounted (default: <code>/scratch</code>).</p> </li> <li> <p>The Work directory is the file system path used as a working directory by Nextflow pipelines. It must be the the storage mount path (default) or a subdirectory of it.</p> </li> <li> <p>The Compute service account is the service account used by Nextflow to submit tasks (default: the <code>default</code> account in the given namespace).</p> </li> <li> <p>The Pod cleanup policy determines when terminated pods should be deleted.</p> </li> <li> <p>You can use Custom head pod specs to provide custom options for the Nextflow workflow pod (<code>nodeSelector</code>, <code>affinity</code>, etc). For example:     <pre>1\n2\n3</pre><pre><code>spec:\n  nodeSelector:\n    disktype: ssd\n</code></pre> </p> </li> <li> <p>You can use Custom service pod specs to provide custom options for the compute environment pod. See above for an example.</p> </li> <li> <p>You can use Head Job CPUs and Head Job Memory to specify the hardware resources allocated for the Nextflow workflow pod.</p> </li> </ul>","title":"Advanced options"},{"location":"compute-envs/lsf/","text":"","title":"IBM LSF"},{"location":"compute-envs/lsf/#overview","text":"<p>IBM Spectrum LSF is an IBM workload management solution for HPC. LSF aims to enhance user and administrator experience, reliability and performance at scale.</p> <p>Tower streamlines the deployment of Nextflow pipelines into both cloud-based and on-prem LSF clusters.</p>","title":"Overview"},{"location":"compute-envs/lsf/#requirements","text":"<p>To launch pipelines into an LSF cluster from Tower, the following requirements must be satisfied:</p> <ul> <li>The cluster should be reachable via an SSH connection using an SSH key.</li> <li>The cluster should allow outbound connections to the Tower web service.</li> <li>The cluster queue used to run the Nextflow head job must be able to submit cluster jobs.</li> <li>The Nextflow runtime version 21.02.0-edge (or later) should be installed on the cluster.</li> </ul>","title":"Requirements"},{"location":"compute-envs/lsf/#compute-environment","text":"<p>To create a new compute environment for LSF in Tower:</p> <ol> <li> <p>In a workspace, select Compute Environments and then New Environment.</p> </li> <li> <p>Enter a descriptive name for this environment, e.g. \"LSF\".</p> </li> <li> <p>Select IBM LSF as the target platform.</p> </li> <li> <p>Select your credentials, or select + and SSH to add new credentials.</p> </li> <li> <p>Enter a name for the credentials.</p> </li> <li> <p>Enter your SSH private key and associated Passphrase (if required), then select Create.</p>  <p>Tip</p> <p>Your SSH key may not require a passphrase depending on how it was created. See here for detailed instructions for how to create a key.</p>  </li> <li> <p>Enter the absolute path of the Work directory to be used on the cluster.</p> </li> <li> <p>Enter the absolute path of the Launch directory to be used on the cluster. If omitted, it will be the same as the work directory.</p> </li> <li> <p>Enter the Login hostname, which is usually the hostname or public IP address of the cluster's login node.</p> </li> <li> <p>Enter the Head queue name, the cluster queue to which the Nextflow job will be submitted.</p> </li> <li> <p>Enter the Compute queue name, the cluster queue to which the Nextflow job will submit tasks.</p>  <p>Tip</p> <p>The compute queue can be overridden by the Nextflow pipeline configuration. See the Nextflow docs for more details.</p>  </li> <li> <p>You can use the Environment variables option to specify custom environment variables for the Head job and/or Compute jobs.</p> <p></p> </li> <li> <p>Configure any advanced options described below, as needed.</p> </li> <li> <p>Select Create to finalize the creation of the compute environment.</p> </li> </ol> <p>Jump to the documentation for Launching Pipelines.</p>","title":"Compute Environment"},{"location":"compute-envs/lsf/#advanced-options","text":"<ul> <li> <p>You can use the Nextflow queue size to limit the number of jobs that Nextflow can submit to the scheduler at the same time.</p> </li> <li> <p>You can use the Head job submit options to specify LSF options for the head job.</p> </li> <li> <p>You can use Unit for memory limits, Per job memory limits, and Per task reserve to control how memory is requested for Nextflow jobs.</p> </li> </ul>","title":"Advanced options"},{"location":"compute-envs/overview/","text":"","title":"Overview"},{"location":"compute-envs/overview/#introduction","text":"<p>Tower uses the concept of Compute Environments to define the execution platform where a pipeline will run. </p> <p>It supports launching pipelines into a growing number of cloud and on-premise infrastructures.</p> <p></p> <p>Each compute environment must be pre-configured to enable Tower to submit tasks. You can read more on how to set up each environment using the links below.</p>","title":"Introduction"},{"location":"compute-envs/overview/#platforms","text":"<p>The following pages describe how to set up a compute environment for each of the available platforms.</p> <ul> <li>AWS Batch</li> <li>Azure Batch</li> <li>Google Cloud</li> <li>Altair Grid Engine</li> <li>Altair PBS Pro</li> <li>IBM LSF</li> <li>Slurm</li> <li>Kubernetes</li> <li>Amazon EKS</li> <li>Google GKE</li> </ul>","title":"Platforms"},{"location":"compute-envs/overview/#select-a-default-compute-environment","text":"<p>If you have more than one compute environment, you can select which one will be used by default when launching a pipeline.</p> <ol> <li> <p>In a workspace, select Compute Environments.</p> </li> <li> <p>Select Make primary for a particular compute environment to make it your default.   </p> </li> </ol>  <p>Congratulations!</p> <p>You are now ready to launch pipelines with your primary compute environment.</p>","title":"Select a default compute environment"},{"location":"compute-envs/slurm/","text":"","title":"Slurm"},{"location":"compute-envs/slurm/#overview","text":"<p>Slurm is an open source, fault-tolerant, and highly scalable cluster management and job scheduling system for large and small Linux clusters.</p> <p>Tower streamlines the deployment of Nextflow pipelines into both cloud-based and on-prem Slurm clusters.</p>","title":"Overview"},{"location":"compute-envs/slurm/#requirements","text":"<p>To launch pipelines into a Slurm cluster from Tower, the following requirements must be satisfied:</p> <ul> <li>The cluster should be reachable via an SSH connection using an SSH key.</li> <li>The cluster should allow outbound connections to the Tower web service.</li> <li>The cluster queue used to run the Nextflow head job must be able to submit cluster jobs.</li> <li>The Nextflow runtime version 21.02.0-edge (or later) should be installed on the cluster.</li> </ul>","title":"Requirements"},{"location":"compute-envs/slurm/#compute-environment","text":"<p>To create a new compute environment for Slurm in Tower:</p> <ol> <li> <p>In a workspace, select Compute Environments and then New Environment.</p> </li> <li> <p>Enter a descriptive name for this environment, e.g. \"Slurm cluster\".</p> </li> <li> <p>Select Slurm Workload Manager as the target platform.</p> </li> <li> <p>Select your credentials, or select + and SSH to add new credentials.</p> </li> <li> <p>Enter a name for the credentials.</p> </li> <li> <p>Enter your SSH private key and associated Passphrase (if required), then select Create.</p>  <p>Tip</p> <p>Your SSH key may not require a passphrase depending on how it was created. See here for detailed instructions for how to create a key.</p>  </li> <li> <p>Enter the absolute path of the Work directory to be used on the cluster.</p> </li> <li> <p>Enter the absolute path of the Launch directory to be used on the cluster. If omitted, it will be the same as the work directory.</p> </li> <li> <p>Enter the Login hostname, which is usually the hostname or public IP address of the cluster's login node.</p> </li> <li> <p>Enter the Head queue name, the cluster queue to which the Nextflow job will be submitted.</p> </li> <li> <p>Enter the Compute queue name, the cluster queue to which the Nextflow job will submit tasks.</p>  <p>Tip</p> <p>The compute queue can be overridden by the Nextflow pipeline configuration. See the Nextflow docs for more details.</p>  </li> <li> <p>You can use the Environment variables option to specify custom environment variables for the Head job and/or Compute jobs.</p> <p></p> </li> <li> <p>Configure any advanced options described below, as needed.</p> </li> <li> <p>Select Create to finalize the creation of the compute environment.</p> </li> </ol> <p>Jump to the documentation for Launching Pipelines.</p>","title":"Compute Environment"},{"location":"compute-envs/slurm/#advanced-options","text":"<ul> <li> <p>You can use the Nextflow queue size to limit the number of jobs that Nextflow can submit to the scheduler at the same time.</p> </li> <li> <p>You can use the Head job submit options to specify Slurm options for the head job.</p> </li> </ul>","title":"Advanced options"},{"location":"core-concepts/definitions/","text":"","title":"Core Concepts"},{"location":"core-concepts/definitions/#pipelines","text":"<p>A Pipeline is composed of a workflow repository, launch parameters, and a Compute Environment. Pipelines are used to define frequently used pre-configured workflows in a Workspace.</p>","title":"Pipelines"},{"location":"core-concepts/definitions/#launchpad","text":"<p>The Launchpad contains the collection of available Pipelines that can be run in a Workspace.</p>","title":"Launchpad"},{"location":"core-concepts/definitions/#workflow-runs","text":"<p>Workflow Runs are the collection executions in a Workspace. Runs display the collection of executions in a Workspace and is used to monitor and inspect details from workflow executions.</p>","title":"Workflow Runs"},{"location":"core-concepts/definitions/#datasets","text":"<p>Datasets are collections of versioned structured data such as TSV and CSV files. They are used for managing sample sheets and metadata. Datasets can be validated and used as inputs for workflow executions.</p>","title":"Datasets"},{"location":"core-concepts/definitions/#actions","text":"<p>Actions automate the execution of pre-configured workflows based on event triggers such as code commits and webhooks. They are used to automate workflow executions.</p>","title":"Actions"},{"location":"core-concepts/definitions/#compute-environments","text":"<p>A Compute Environment is composed of credentials, configuration settings, and storage options related to a computing platform. They are used to configure and manage computing platforms where workflows are executed.</p>","title":"Compute Environments"},{"location":"core-concepts/definitions/#credentials","text":"<p>Credentials are access keys stored by Tower in an encrypted manner using AES-256. They allow safe storage of authentication keys for Compute Environments, private code repositories, and external services. Credentials cannot be accessed once stored.</p>","title":"Credentials"},{"location":"core-concepts/definitions/#pipeline-secrets","text":"<p>Secrets are keys used by workflow tasks to interact with external systems e.g. a password to connect to an external database or an API token. Secrets are stored within the Tower using AES-256 encryption. Currently, there are two types of Secrets:</p> <ul> <li> <p>Pipeline Secrets defined in a Workspace are available to workflows launched within that Workspace.</p> </li> <li> <p>Secrets defined by a user that are available workflows launched by that user in any Workspace. </p> </li> </ul>","title":"Pipeline Secrets"},{"location":"core-concepts/definitions/#workspace","text":"<p>Workspaces provide the context in which a user operates, i.e. launch workflow executions, and defines what resources are available/accessible and who can access/operate on those resources. They are are composed of Pipelines, Runs, Actions, Datasets, Compute Environments and Credentials. Access permissions are controlled through Participants, Collaborators, and Teams.</p>","title":"Workspace"},{"location":"core-concepts/definitions/#organizations","text":"<p>Organizations is the top-level entity where businesses, institutions, and groups can collaborate. Organizations can contain multiple Workspaces.</p>","title":"Organizations"},{"location":"core-concepts/definitions/#members","text":"<p>A user, internal to the organization. A Member has an Organization role and can operate in one or more Organisation Workspaces. In each Workspace, Members can have a Participant role that defines the permissions granted to that user within that Workspace.</p>","title":"Members"},{"location":"core-concepts/definitions/#team","text":"<p>A group of Members in the same organization. A Team can operate in one more organisation workspaces with a specific Workspace role (one role per Workspace).</p>","title":"Team"},{"location":"core-concepts/definitions/#participant","text":"<p>A user operating with a specific Role within a Workspace</p>","title":"Participant"},{"location":"core-concepts/definitions/#participant-role","text":"<p>The Participant Role defines the permissions granted to a user to operate within a Workspace.</p>","title":"Participant Role"},{"location":"credentials/overview/","text":"","title":"Overview"},{"location":"credentials/overview/#introduction","text":"<p>Tower uses the concept of Credentials to store the keys and tokens necessary to access the Compute Environments as well as Git hosting services. The instructions for adding the credentials are mentioned in the documentation for respective compute environment or git hosting section of this documentation. </p> <p></p>  <p>Note</p> <p>All credentials are securely stored using advanced encryption (AES-256) and never exposed by any Tower API.</p>","title":"Introduction"},{"location":"datasets/overview/","text":"","title":"Datasets"},{"location":"datasets/overview/#overview","text":"<p>The Datasets functionality in Nextflow Tower allows the users to store CSV and TSV formatted files within a workspace and use those as an input one or more pipelines.</p> <p></p>  <p>Note</p> <p>This feature is available only in the organization workspaces..</p>","title":"Overview"},{"location":"datasets/overview/#creating-a-new-dataset","text":"<p>To create a new dataset, please follow these steps </p> <ol> <li> <p>Open the <code>Datasets</code> tab in your organization workspace.</p> </li> <li> <p>Click on <code>New dataset</code> button to open the dataset creation dialog as shown below.</p> </li> </ol> <p></p> <ol> <li> <p>You can enter the Name and Description fields as per the nature of your dataset.</p> </li> <li> <p>You can add the dataset file to your workspace using either drag and drop or by using the system file explorer dialog.</p> </li> <li> <p>It is possible to customize the subsequent views for the dataset using <code>First row as header</code> option, to accomodate the situations where the first row contains the column names.</p> </li> </ol>  <p>Warning</p> <p>The size of the dataset file cannot exceed 10MB.</p>","title":"Creating a new Dataset"},{"location":"datasets/overview/#dataset-versions","text":"<p>The Datasets functionality can accommodate multiple versions of a dataset. To add a new version for a dataset, please follow these steps </p> <ol> <li> <p>Click on the Edit option for the intended dataset.</p> </li> <li> <p>In the Edit dialog, click on the Add a new version button.</p> </li> <li> <p>Upload the newer version of the dataset and click on Update.</p> </li> </ol>  <p>Warning</p> <p>All subsequent versions of a dataset must be in the same data format as the initial version of the dataset.</p>","title":"Dataset versions"},{"location":"datasets/overview/#using-a-dataset","text":"<p>To use a dataset with the saved pipelines in your workspace, please follow these steps </p> <ol> <li> <p>Open any pipeline from the Launchpad containing a pipeline-schema.</p> </li> <li> <p>Click on the input field for the pipeline, removing any default value. </p> </li> <li> <p>Pick the right dataset for your pipeline</p> </li> </ol> <p></p>  <p>Warning</p> <p>The Datasets shown in the dropdown menu depends upon the validation specified in your pipeline-schema. Hence, if the schema specifies only <code>CSV</code> format, no <code>TSV</code> dataset would appear in the dropdown.</p>","title":"Using a Dataset"},{"location":"getting-started/deployments/","text":"<p>Tower can be accessed and/or deployed in three ways:</p> <ul> <li> <p>Hosted: The hosted version of Tower is available free of charge at tower.nf. This version is for individuals and organizations that want to get setup fast. It is the recommended way for users to become familiar with Tower. The service is hosted by Seqera Labs.</p> </li> <li> <p>Community deployment: Installation of the Tower community edition can be performed on a user's own system. The community edition has basic features for the monitoring of pipelines by an individual user.</p> </li> <li> <p>Enterprise deployment: Deployment of the fully-featured Tower application in an organization's own cloud or on-premise environment. This deployment option is supported by Seqera Labs and is recommended for production environments.</p> </li> </ul>","title":"Deployments"},{"location":"getting-started/deployments/#hosted","text":"<p>To try Tower, visit tower.nf and log in with GitHub or Google credentials. The Launching Pipelines documentation section provides step-by-step instructions to start your first pipeline. The hosted version of Tower has a limit of five concurrent workflow executions per user.</p> <p></p>","title":"Hosted"},{"location":"getting-started/deployments/#enterprise","text":"<p>Tower Enterprise is installed within an organization's own cloud or on-premise environment. It includes:</p> <ul> <li>Monitoring, logging, &amp; observability</li> <li>Pipeline execution launchpad</li> <li>Cloud resource provisioning</li> <li>Pipeline actions and event-based execution</li> <li>LDAP &amp; OpenID Authentication</li> <li>Enterprise role-based access control</li> <li>Fully featured API</li> <li>Support for Nextflow &amp; Tower</li> </ul> <p>To install the Tower in your organization, contact Seqera Labs for a demo and to discuss your requirements.</p> <p></p>","title":"Enterprise"},{"location":"getting-started/deployments/#community","text":"<p>For more information on installing the Community version of Tower visit our GitHub repository and follow our deployment guide.</p> <p></p>  <p>Warning</p> <p>The community version of Tower on Github does not have the <code>Tower Launch</code> or <code>Organization and Workspaces</code> functionality.</p>","title":"Community"},{"location":"getting-started/usage/","text":"<p>You can use Tower via either the online GUI, using the <code>-with-tower</code> option with the Nextflow run command, or through the API.</p>","title":"Usage"},{"location":"getting-started/usage/#via-tower-gui","text":"<p>1. Create an account and login into Tower, available free of charge, at tower.nf.</p> <p>2. Create and configure a new compute environment.</p> <p>3. Start launching pipelines.</p>","title":"Via Tower GUI"},{"location":"getting-started/usage/#via-tower-api","text":"<p>To learn more about using the Tower API, visit to the API section in this documentation.</p>","title":"Via Tower API"},{"location":"getting-started/usage/#via-nextflow-run-command","text":"<p>Create an account and login into Tower.</p> <p>1. Create a new token</p> <p>You can access your tokens from the Settings drop-down menu:</p> <p></p> <p>2. Name your token</p> <p></p> <p>3. Save your token safely</p> <p>Copy and keep your new token in a safe place.</p> <p></p> <p>4. Export your token</p> <p>Once your token has been created, open a terminal and type:</p> <pre>1\n2</pre><pre><code>export TOWER_ACCESS_TOKEN=eyxxxxxxxxxxxxxxxQ1ZTE=\nexport NXF_VER=20.10.0\n</code></pre>  <p>Where <code>eyxxxxxxxxxxxxxxxQ1ZTE=</code> is the token you have just created.</p>  <p>Nextflow version</p> <p>Bearer token requires Nextflow version 20.10.0 or later, set with the second command above.</p>  <p>To submit a pipeline to a Workspace using the Nextflow command line tool, add the workspace ID to your environment. For example</p> <pre>1</pre><pre><code>export TOWER_WORKSPACE_ID=000000000000000\n</code></pre>  <p>The workspace ID can be found on the organisation's Workspaces overview page.</p> <p>5. Run Nextflow with tower</p> <p>Run your Nextflow workflows as usual with the addition of the <code>-with-tower</code> command:</p> <pre>1</pre><pre><code>nextflow run hello.nf -with-tower\n</code></pre>  <p>You will see and be able to monitor your Nextflow jobs in Tower.</p> <p>To configure and execute Nextflow jobs in Cloud environments, visit the Compute environments section.</p>  <p>Tip</p> <p>See also the Nextflow documentation for further run configuration via Nextflow configuration files.</p>","title":"Via Nextflow run command"},{"location":"getting-started/workspace/","text":"<p>Each user has a unique workspace where they can interact and manage all resources such as workflows, compute environments and credentials.</p>  <p>Tip</p> <p>It is also possible to create multiple workspaces within an organization context and associate each of these workspaces with dedicated teams of users, while providing a fine-grained access control model for each of the teams. Please refer to the Orgs and Teams section.</p>  <p>The core components of a workspace are described below.</p>","title":"Overview"},{"location":"getting-started/workspace/#launchpad","text":"<p>The Launchpad offers a streamlined UI for launching and managing workflows along with their associated compute environments and credentials. Using Launchpad, it is possible to create a curated set of workflows (including variations of the same workflow) which are ready to be executed on the associated compute environments, while allowing the user the option to customize the workflow level parameters if needed.</p>","title":"Launchpad"},{"location":"getting-started/workspace/#runs","text":"<p>The Runs section is used for monitoring a launched workflow with real-time execution metrics such as number of pending or completed processes. For more information please refer to the Launch section.</p>","title":"Runs"},{"location":"getting-started/workspace/#actions","text":"<p>It is possible to trigger pipelines based on specific events such as version release on Github or general Tower webhook. For further information please refer to the Pipeline Actions section.</p>","title":"Actions"},{"location":"getting-started/workspace/#compute-environments","text":"<p>Tower uses the concept of Compute Environments to define the execution platform for pipelines. Tower supports launching of pipelines into a growing number of cloud (Azure, AWS and GCP) and on-premise infrastructures (Slurm, IBM LSF and Grid engine etc). For further information please refer to the Compute Environments section.</p>","title":"Compute Environments"},{"location":"getting-started/workspace/#credentials","text":"<p>The Credentials section allows users to set up the access credentials for various platforms (Github, Gitlab and BitBucket) as well as various compute environments such as cloud, Slurm  or Kubernetes, etc. Please refer to the Compute Environment and Git Integration sections for instructions regarding your infrastructure. For further information, please refer the Credentials section.</p>","title":"Credentials"},{"location":"git/overview/","text":"<p>Nextflow has built-in support for Git and integration with several Git-hosting platforms.</p> <p>A data pipelines may be composed by many assets (source code scripts, deployment settings, dependency descriptors such as Conda or Docker files, documentation etc.).</p> <p>By managing complex data pipelines as Git projects, all assets can be precisely tracked and deployed specifying a Git tag, release or commit id. This, combined with containerization, is key for enabling replicable pipeline executions. It also provides the ability to continuously test and validate pipelines as code evolves over time.</p> <p>The following sections detail how to connect to public and private Git-hosting platforms to Tower:</p> <ul> <li>Public Git repositories</li> <li>Private Git repositories</li> </ul>","title":"Overview"},{"location":"git/private_repositories/","text":"<p>Access to private Git repositories can be managed from the Credentials section, accessible from the Credentials tab.</p> <p>Tower provides support to connect to private repositories from the popular Git hosting platforms GitHub, GitLab, and BitBucket.</p> <p></p>  <p>Note</p> <p>All credentials are securely stored using advanced encryption (AES-256) and never exposed by any Tower API.</p>","title":"Private Git repositories"},{"location":"git/private_repositories/#github","text":"<p>To connect a private GitHub repository you need to enter a Name for the credentials, a Username and a Password or Access token. </p>  <p>Hint</p> <p>It is recommended to use an access token instead of a using your password. Personal access tokens (PATs) are an alternative to using passwords for authentication to GitHub when using APIs. Step-by-step instructions to create a personal access token can be found here.</p>","title":"GitHub"},{"location":"git/private_repositories/#gitlab","text":"<p>To connect a private GitLab repository you need to enter a Name for the credentials, a Username, Password and Access token.</p> <p>A GitLab API access token that can be found in your GitLab account page. Make sure to select the <code>api</code>, <code>read_api</code>, and  <code>read_repository</code> options.</p> <p></p>","title":"GitLab"},{"location":"git/private_repositories/#bitbucket","text":"<p>To connect a private BitBucket repository you need to enter a Name for the credentials, a Username and a BitBucket App password. </p> <p>This step-by-step example shows how to create a BitBucket App password.</p>","title":"Bitbucket"},{"location":"git/private_repositories/#self-hosted-git","text":"<p>It is also possible to specify Git server endpoints for Tower Enterprise. For further information please refer this Tower Install Documentation page.</p>","title":"Self-hosted Git"},{"location":"git/public_repositories/","text":"<p>Nextflow data pipelines can pulled remotely from either a public or private Git-hosting solution, including the popular platforms: GitHub, GitLab, BitBucket and Gitea.</p> <p>Launching a publicly hosted Git pipeline simply requires adding the Git repo URL in the pipeline to launch field. </p> <p>Note the revision and version numbers for a given repository are automatically pulled using the Git API. By default, the default <code>main/master</code> branch will be executed.</p>  <p>Tip</p> <p>nf-core is a great resource for public nextflow pipelines.</p>","title":"Public Git repositories"},{"location":"installation/system-deployment/","text":"<p>Tip</p> <p>It is highly recommended to first Sign up and try the hosted version of Tower for free or request a demo for a deployment in your own on-premise or cloud environment.</p>  <p>Nextflow Tower is a web application server based on a microservice oriented architecture and designed to maximize the portability, scalability and security of the application.</p> <p>The application is composed of a variety of modules that can be configured and deployed depending on organization's requirements.</p> <p>All components for the Enterprise release are packaged as Docker container images which are hosted and security validated by the Amazon ECR service. The community version can be accessed via GitHub.</p>","title":"System deployment"},{"location":"installation/system-deployment/#deployment-configurations","text":"<p>Warning</p> <p>To install Nextflow Tower on private infrastructure, you'd need a license key. Please contact us at sales@seqera.io to get your license key.</p>","title":"Deployment configurations"},{"location":"installation/system-deployment/#basic-deployment","text":"<p>The minimal Tower configuration only requires the front-end, backend and database modules.</p> <p>These can be executed as Docker containers or as native services running in the hosting environment. Such a minimal configuration is only suggested for evaluation purposes or for a small number of users.</p>","title":"Basic deployment"},{"location":"installation/system-deployment/#kubernetes-deployment","text":"<p>Kubernetes cluster management is emerging as the technology of choice for the deployment of applications requiring high-availability, scalability and security.</p> <p>Nextflow Tower Enterprise includes configuration manifests for the deployment in the Kubernetes environment.</p> <p>This diagram shows the system architecture for the reference deployment on AWS.</p> <p></p>","title":"Kubernetes deployment"},{"location":"installation/system-deployment/#tower-modules","text":"<p>The application is composed of a number of modules that can be configured and deployed depending on user requirements.</p> <p>All components are packaged as Docker container images which are hosted and security validated by the Amazon ECR service.</p>","title":"Tower Modules"},{"location":"installation/system-deployment/#backend-module","text":"<p>The backend is implemented as a JVM-based application server based on the Micronaut framework which provides a modern and secure backbone for the application server.</p> <p>The backend module requires OpenJDK 8 or later.</p> <p>The backend layer implements the main application logic organised in a service layer, which is then exposed via a REST API and defined via an OpenAPI schema.</p> <p>The backend module uses JPA/Hibernate/JDBC API industry standards to connect the underlying relational database.</p> <p>The backend is designed to run standalone or as multiple replicas for scalability when deployed in high-availability mode.  </p>","title":"Backend module"},{"location":"installation/system-deployment/#frontend-module","text":"<p>The frontend module is composed by Angular 8 application which is served by an Nginx web server.</p> <p>The frontend can be configured to expose the application directly to the user/DMZ via an HTTPS connection or through a load balancer.</p>","title":"Frontend module"},{"location":"installation/system-deployment/#storage","text":"<p>Nextflow Tower requires a relational database as its primary storage.</p> <p>It is suggested to use MySQL 5.6, however, any SQL database compatible with JPA/JDBC industry-standards is supported.</p>","title":"Storage"},{"location":"installation/system-deployment/#caching","text":"<p>Tower provides an optional caching module for configurations requiring high availability.</p> <p>This module requires a Redis 5.0 in-memory database.</p>","title":"Caching"},{"location":"installation/system-deployment/#authentication-module","text":"<p>Nextflow Tower supports enterprise authentication mechanisms such as OAuth and LDAP.</p> <p>Third-party authority providers and custom single-sign-on flow can be developed depending on exact customer requirements.</p>","title":"Authentication module"},{"location":"installation/system-deployment/#cron-scheduler","text":"<p>Tower implements a cron service which takes care of executing periodical activities, such as sending e-mail notifications and cleaning up.</p> <p>The cron service can be configured to run as an embedded backend service or an independent service.</p>","title":"Cron scheduler"},{"location":"launch/advanced/","text":"<p>Advanced launch options allow users to modify the configuration and execution of the pipeline.</p>","title":"Advanced Options"},{"location":"launch/advanced/#nextflow-config-file","text":"<p>The Nextflow config field allows the addition of settings to the Nextflow configuration file.</p> <p>This text should follow the same syntax as the Nextflow configuration file.</p> <p>In the example below, we can modify the manifest section to give the pipeline a name and description which will show up in the Tower monitoring section.</p> <p></p>","title":"Nextflow config file"},{"location":"launch/advanced/#pre-post-run-scripts","text":"<p>It is possible to run custom code either before or after the execution of the Nextflow script. These fields allow users to enter shell commands.</p>","title":"Pre &amp; post-run scripts"},{"location":"launch/advanced/#pull-latest","text":"<p>Enabling this option ensures Nextflow pulls the latest version from the Git repository. This is equivalent to using the <code>-latest</code> flag.</p> <p></p>","title":"Pull latest"},{"location":"launch/advanced/#main-script","text":"<p>Nextflow will attempt to run the script named <code>main.nf</code> in the project repository by default. This can be changed via either the <code>manifest.mainScript</code> option or by providing the script filename to run in this field.</p>","title":"Main script"},{"location":"launch/advanced/#workflow-entry-name","text":"<p>Nextflow DSL2 provides the ability to launch specific-named workflows. Enter the name of the workflow to be executed in this field.</p>","title":"Workflow entry name"},{"location":"launch/launch/","text":"<p>The Launch Form can be used for launching pipelines and for creating pipelines for the Launchpad.</p> <p>Consider launching the nf-core/rnaseq workflow using a Google Cloud compute environment.</p> <p>To launch a pipeline:</p> <p>1. Select the Launch button in the navigation bar.</p> <p>The Launch Form view will appear.</p> <p>2. Select the drop-down menu to choose a Compute Environment.</p>  <p>Warning</p> <p>See the Compute Environment documentation to learn how to create an environment for your preferred executor environment.</p>  <p>3. Enter the repository of the Pipeline to launch. For example, https://github.com/nf-core/rnaseq.git.</p> <p>4. A Revision number can be used select different versions of pipeline. The Git default branch (main/master) or <code>manifest.defaultBranch</code> in the Nextflow configuration will be used by default.</p> <p>5. The Work directory specifies the location of the Nextflow work directory. The location associated with the compute environment will be selected by default.</p> <p>6. Enter the name(s) of each of the Nextflow Config profiles followed by the <code>Enter</code> key. See the Nextflow Config profiles documentation for more details.</p> <p>7. Enter any Pipeline parameters in YAML or JSON format. YAML example:</p> <pre>1\n2</pre><pre><code>    reads: 's3://nf-bucket/exome-data/ERR013140_{1,2}.fastq.bz2'  \n    paired_end: true\n</code></pre>  <p>8. Select Launch to begin the pipeline execution.</p>  <p>Tip</p> <p>Nextflow pipelines are simply Git repositories and the location can be any public or private Git-hosting platform. See Git Integration in the Tower docs and Pipeline Sharing in the Nextflow docs for more details.</p>   <p>Warning</p> <p>The credentials associated with the compute environment must be able to access the work directory.</p>   <p>Tip</p> <p>In the configuration, the full path to a bucket must be specified with single-quotes around strings - no quotes around Booleans or numbers.</p>","title":"Launch Form"},{"location":"launch/launchpad/","text":"<p>Launchpad makes it easy for any workspace user to launch a pre-configured pipeline.</p> <p></p> <p>A pipeline is a repository containing a Nextflow workflow, a compute environment, and pipeline parameters.</p>","title":"Launchpad"},{"location":"launch/launchpad/#pipeline-parameters-form","text":"<p>Launchpad automatically detects the presence of a <code>nextflow_schema.json</code> in the root of the repository and dynamically creates a form where users can easily update the parameters. </p>  <p>Tip</p> <p>The parameter forms view will appear if the workflow has a Nextflow schema file for the parameters. Please refer to the Nextflow Schema guide to learn more about the use cases and how to create them.</p>  <p>This makes it trivial for users without any expertise in Nextflow to enter their pipeline parameters and launch.</p> <p></p>","title":"Pipeline Parameters Form"},{"location":"launch/launchpad/#adding-a-new-pipeline","text":"<p>Adding a pipeline to the workspace launchpad is similar to the Launch except, instead of launching the pipeline, it gets added to the list of pipelines with the pre-saved values of fields, such as the pipeline parameters and the revision number.</p>  <p>Tip</p> <p>To create your own customized Nextflow Schema for your pipeline, see the examples from the increasing number of <code>nf-core</code> workflows that have adopted this.  nf-core/eager and nf-core/rnaseq are excellent examples. </p>","title":"Adding a New Pipeline"},{"location":"launch/notifications/","text":"","title":"Notifications"},{"location":"launch/notifications/#email-notifications","text":"<p>You can receive email notifications at the completion or a failure of a workflow execution.</p> <p>Navigate to your profile page using dropdown on your avatar in the top-right of the page. Select the Send notification email on workflow completion toggle option at the bottom of the profile settings page.</p> <p></p>","title":"Email Notifications"},{"location":"launch/relaunch/","text":"<p>Re-launching pipelines is a great way to quickly troubleshoot or make use of Nextflow's resume functionality and re-launch the same pipeline with different parameters.</p> <p>The Resume option is selected by default when re-launching a new pipeline from the Runs monitoring screen. In short, This option allows for the continuation of a workflow execution using Nextflow resume.</p>  <p>Nextflow resume</p> <p>For a detailed explanation of how the resume option works, please visit Part 1 and Part 2 of the Demystifying Nextflow resume description in the Nextflow blog.</p>","title":"Relaunch"},{"location":"monitoring/aggregate_stats/","text":"","title":"Aggregate stats & load"},{"location":"monitoring/aggregate_stats/#aggregate-stats","text":"<p>The Aggregate stats panel displays a real-time summary of the resources used by the workflow. These include total running time ('wall time'), aggregated CPU time (CPU hours), memory usage (GB hours), data i/o and cost.</p> <p></p> <p>The cost is only based on estimated computation usage and does not currently take into account storage or associated network costs. Tower has a database of costs for all cloud instances of AWS and Google Cloud in all regions and zones.</p>","title":"Aggregate Stats"},{"location":"monitoring/aggregate_stats/#load-and-utilization","text":"<p>As processes are being submitted to the compute environment, the Load monitors how many cores and tasks are currently being used. </p> <p>Utilization is calculated for memory and CPUs. This is the average value across all tasks and is calculated by dividing the memory (or CPUs) usage by the memory (or CPUs) requested.</p> <p></p>","title":"Load and Utilization"},{"location":"monitoring/execution/","text":"<p>Selecting a pipeline on the navigation bar will display the workflow details in the main monitoring panel. The main window contains:</p> <ul> <li>Execution section with command-line, parameters, configuration, and execution logs in real-time.</li> <li>Summary and status section.</li> <li>List of pipeline processes.</li> <li>Aggregated stats and load.</li> <li>Detailed list of individual tasks and metrics.</li> </ul>","title":"Execution details & logs"},{"location":"monitoring/execution/#run-information","text":"<p>This top section is composed of 4 tabs containing details about the Nextflow execution:</p> <p>1. The Nextflow Command line to execute the job.</p> <p>2. Parameters including all parameters given in the arguments and arguments taken from the configuration <code>profiles</code> in the <code>params</code> scope.</p> <p>3. Configuration contains all the information included in the configuration file including parameters.</p> <p>4. The Execution log tab is updated in real time with the logs from the main Nextflow process.</p> <p></p>","title":"Run information"},{"location":"monitoring/overview/","text":"","title":"Overview"},{"location":"monitoring/overview/#runs","text":"<p>Jobs that have been submitted with Tower can be monitored wherever you have an internet connection. </p> <p>The Runs tab contains all previous jobs executions. Each new or resumed job will be given a random name e.g: <code>grave_williams</code>.</p> <p></p> <p>The colors signify the completion status:</p> <ul> <li>Blue are running.</li> <li>Green are successfully executed.</li> <li>Yellow are successfully executed where some tasks failed.</li> <li>Red are jobs where at least one task fully failed.</li> <li>Grey are jobs that where forced to stop during execution.</li> </ul> <p>Selecting any particular run from the panel will display that run execution details.</p>","title":"Runs"},{"location":"monitoring/overview/#search","text":"<p>The search box allows searching for workflows by <code>project name</code>, <code>run name</code>, <code>session id</code> or <code>manifest name</code>. Moreover, wildcards can be used to filter the desired workflows such as using asterisks <code>*</code> before and after keyword to filter results.</p> <p></p>","title":"Search"},{"location":"monitoring/processes/","text":"<p>In Nextflow, a process is the basic primitive to execute a block of code. The Processes section shows all processes and the status of the tasks. </p> <p>In the example below, there are four tasks of the fastqc process.</p> <p></p> <p>By selecting a process, the Tasks table is filtered below.</p>","title":"Processes"},{"location":"monitoring/sharing/","text":"<p>To share a pipeline execution with a collaborator, select the Sharing icon from the main monitoring panel.</p> <p></p> <p>Select the Add Collaborator button, add your collaborator's email or Tower login and click Confirm.</p> <p></p> <p>An email with the pipeline URL will be sent to the collaborator.</p> <p></p>  <p>Warning</p> <p>Your collaborator's Tower account email must match the email where you sent the invite.</p>  <p>Once shared, the pipeline execution is visible in the user's navigation panel with the launchers name shown.</p> <p>It is important to ensure your collaborators have permissions to your compute resources to make the most of this feature. For example, information in a cloud bucket such as task logs will only be visible if the collaborator also has access to that bucket.</p>","title":"Sharing pipelines"},{"location":"monitoring/summary/","text":"","title":"Summary & status"},{"location":"monitoring/summary/#general","text":"<p>The General summary displays information on the environment and the job being executed:</p> <ul> <li>Unique workflow run ID</li> <li>Workflow run name</li> <li>Date and time of job submission timestamp</li> <li>Project revision and Git commit ID</li> <li>Nextflow session ID</li> <li>Username of the launcher</li> <li>Work directory path</li> <li>Container image</li> <li>Executor</li> <li>Compute environment details</li> <li>Nextflow version</li> </ul>  <p>Tip</p> <p>Hover over with the mouse to get full details on the compute environment.</p>  <p></p>","title":"General"},{"location":"monitoring/summary/#task-status","text":"<p>The Task status section shows in real time the statuses of your workflow tasks. The panel uses the same colour code as the pipelines in the navigation bar.</p> <p>The exact meaning of each status is dependant on the execution platform. </p> <p></p>","title":"Task status"},{"location":"monitoring/tasks/","text":"","title":"Tasks & metrics"},{"location":"monitoring/tasks/#task-table","text":"<p>The Tasks section shows all the tasks from an execution.</p> <p>You can use the <code>Search</code> bar to filter tasks by process name, tag, hash, status, etc. </p> <p>Selecting a status in status section filters the task table.  E.g. clicking in the CACHED card in the status column.</p> <p></p> <p>Selecting a <code>process</code> in the Processes section above will filter all tasks for that specific process.</p> <p></p> <p>Selecting a task in the task table provides specific information about the task in the Task details dialog. </p> <p></p> <p>The task details dialog has the task information tab and the task Execution log tab.</p>","title":"Task table"},{"location":"monitoring/tasks/#task-information","text":"<p>The task information tab contains the process name and task tag in the title. The tab includes:</p> <ul> <li>Command </li> <li>Status</li> <li>Work directory</li> <li>Environment</li> <li>Execution time</li> <li>Resources requested</li> <li>Resources used</li> </ul> <p></p>","title":"Task information"},{"location":"monitoring/tasks/#execution-log","text":"<p>The Execution log provides a realtime log of the individual task of a Nextflow execution. </p> <p>This can be very helpful for troubleshooting. It is possible to download the log files including <code>stdout</code> and <code>stderr</code> from your compute environment.</p> <p></p>","title":"Execution log"},{"location":"monitoring/tasks/#resource-metrics","text":"<p>This section displays plots with CPU, memory, task duration and I/O usage, grouped by process.</p> <p>These metrics can be used to profile an execution to ensure that the correct amount or resources are being requested for each process.</p> <p></p>  <p>Tip</p> <p>Hover the mouse over the box plots to display more details.</p>","title":"Resource metrics"},{"location":"orgs-and-teams/organizations/","text":"<p>Organizations are the top-level structure and contain Workspaces, Members, Teams, and Collaborators. </p>","title":"Organizations"},{"location":"orgs-and-teams/organizations/#new-organization","text":"<p>To create a new Organization:</p> <p>1. Click on the dropdown next to your name and select New organization to open the creation dialog.</p> <p>2. On the dialog, fill in the fields as per your organization. The Name and Full name fields are compulsory.</p>  <p>Warning</p> <p>A valid name for the organization must follow specific pattern. Please refer to the UI for further instructions.</p>  <p>3. The rest of the fields such as Description, Location, Website URL and Logo Url are optional.</p> <p>4. Once the details are filled in, you can access the newly created organization using the organizations page, which lists all of your organizations.</p>  <p>Tip</p> <p>It is possible to change the values of the optional fields either using the Edit option on the organizations page or using the Settings tab within the organization page, provided that you are the Owner of the organization .</p>   <p>Note</p> <p>A list of all the included Members, Teams, and Collaborators can be found on the organization page.</p>","title":"New Organization"},{"location":"orgs-and-teams/organizations/#members","text":"<p>Once an organization is created, the user who created the organization is the default owner of that organization. It is also possible to invite or add other members as well.</p> <p>Tower provides access control for members of an organization by classifying them either as an Owner or a Member. Each organization can have multiple owners and members.</p>  <p>Note</p> <p>Owners have full read/write access to modify members, teams, collaborators, and settings within a organization. Members are limited in their actions.</p>","title":"Members"},{"location":"orgs-and-teams/organizations/#create-a-new-member","text":"<p>To add a new member to an organization:</p> <ol> <li>Go to the Members tab of the organization menu</li> <li>Click on Invite member</li> <li>Enter the email ID of user you'd like to add to the organization</li> </ol> <p>An e-mail invitiation will be sent which needs to be accepted by the user. Once they accept the invitation, they can switch to the organization (or organization workspace) using their workspace dropdown.</p>","title":"Create a new member"},{"location":"orgs-and-teams/organizations/#collaborators","text":"<p>Collaborators are users who are invited to an organization's workspace, but are not members of that organization. As a result, their access is limited to only within that workspace.</p> <p>New collaborators to an organization's workspace can be added using Participants. To learn more about the various available access levels for Participants, please refer to the participant roles section.</p>  <p>Note</p> <p>Collaborator can only be added from a workspace. For more information, please refer to the workspace management section. </p>","title":"Collaborators"},{"location":"orgs-and-teams/organizations/#teams","text":"<p>Teams allows the organization owners to group members and collaborators together into a single unit and to manage them as a whole.</p>","title":"Teams"},{"location":"orgs-and-teams/organizations/#create-a-new-team","text":"<p>To create a new team within an organization:</p> <ol> <li>Go to the Teams tab of the organization menu</li> <li>Click on New team</li> <li>Enter the Name of team </li> <li>Optionally, add the Description and the team's Avatar</li> <li>For the newly created team, click on View</li> <li>Click on Add team member and type in the name of the organization members or collaborators</li> </ol>","title":"Create a new team"},{"location":"orgs-and-teams/overview/","text":"<p>Nextflow Tower simplifies the development and execution of workflows by providing a centralized interface to manage users and resources while providing ready-to-launch workflows for users. This is achieved through the context of Workspaces. </p>","title":"Overview"},{"location":"orgs-and-teams/overview/#organization-resources","text":"<p>Tower allows the creation of multiple organizations, each of which can contain multiple workspaces with shared users and resources. This allows any organization to customize and organize the usage of resources while maintaining an access control layer for users associated with a workspace.</p> <ul> <li> <p>For further information on organizations, please refer to the Organizations section. </p> </li> <li> <p>For further information on organization workspaces, please refer to the Workspace Management section.</p> </li> </ul>","title":"Organization resources"},{"location":"orgs-and-teams/overview/#organization-users","text":"<p>Any user can be added or removed from a particular organization or a workspace, and can be allocated a specific access role within that workspace. </p> <p>The Teams feature provides a way for the organizations to group various users and participants together into teams, for example <code>workflow-developers</code> or <code>analysts</code>, and apply access control to all the users within this team as a whole.</p> <ul> <li>For further information on user and team creation, please refer to the User Management  section.</li> </ul>","title":"Organization users"},{"location":"orgs-and-teams/shared-workspaces/","text":"<p>We introduced the concept of shared workspaces as a solution to synchronization and resource sharing within an organization in Tower.</p> <p>With a shared workspace, it is now possible to create and set up pipelines in a single place (i.e. the shared workspace) which will become accessible to all members of an organization to be used.</p> <p>The benefits that a shared workspace brings to an organization are:</p> <ul> <li> <p>Define once and share everywhere: The shared resources need only to be set up once, and then they are automatically shared across the organization.  </p> </li> <li> <p>Centralize the management of key resources: Organization administrator who need to ensure that the right pipeline configuration is used in all areas of an organization no longer need to copy and replicate a pipeline across multiple workspaces. </p> </li> <li> <p>Immediate updates adoption: Updated parameters for a shared pipeline are immediately available everywhere across the organizations, reducing the risk of partial updates across an organization.</p> </li> <li> <p>Computational resource provision: Shared pipelines in shared workflows can be shared together with the needed computational resources. This avoids the need to duplicate resource setup in all individual workspaces across the organization. Shared workspaces can be used to centralize and simplify the resource sharing across an organization in Tower</p> </li> </ul>","title":"Overview"},{"location":"orgs-and-teams/shared-workspaces/#how-to-create-a-shared-workspace","text":"<p>Creating a shared workspace is similar to the creation of a private workspace, with the difference of Visibility option, which is set to Shared.</p> <p></p>","title":"How to create a shared workspace"},{"location":"orgs-and-teams/shared-workspaces/#creating-a-shared-pipeline","text":"<p>To create a pipeline within a shared workspace, the choice of an associated compute environment is optional. </p> <p>In case a compute environment from the shared workspace is associated with the pipeline, it will be available to users in other workspace who can launch that shared pipeline using it by default.</p>","title":"Creating a shared pipeline"},{"location":"orgs-and-teams/shared-workspaces/#using-shared-pipelines-from-a-private-workspace","text":"<p>Once a pipeline is set up in a shared workspace and associated to a compute environment within the shared workspace, it is possible for any user to launch that pipeline from a private workspace using the shared workspace compute environment.</p>  <p>Note</p> <p>The shared compute environment would not be available to launch other pipelines which are only limited to that particular private workspace.</p>  <p>If a pipeline from a shared workspace is shared without an associated compute environment, users from other workspaces can run it using local workspaces. By default, the primary compute environment of the local workspace will be selected.</p>","title":"Using shared pipelines from a private workspace"},{"location":"orgs-and-teams/shared-workspaces/#make-shared-pipelines-visible-in-a-private-workspace","text":"<p>To make a shared pipeline visible from any shared workspace, you can use the visibility option on the Launchpad.</p>  <p>Note</p> <p>Currently, the pipelines from all shared workspaces are visible when the visibility is set to \"Shared workspaces\".</p>  <p></p>","title":"Make shared pipelines visible in a private workspace"},{"location":"orgs-and-teams/workspace-management/","text":"<p>Organization Workspaces builds upon the functionality of a User Workspace section and adds the ability to fine-tune the access level for any particular member, collaborator, or team. This is achieved by managing Participants in the Organization Workspaces. </p>  <p>Note</p> <p>A participant may be a member of the parent organization of that workspace or may be a collaborator only for that workspace within that organization.</p>","title":"Workspace Management"},{"location":"orgs-and-teams/workspace-management/#create-a-new-workspace","text":"<p>To create a new workspace within an organization:</p> <ol> <li>Go to the Workspaces tab of the organization menu.</li> <li>Select Create workspace.</li> <li>Enter the Name and Full name of the workspace.</li> <li>Optionally, add the Description of the workspace.</li> <li>Click on Open for the newly created workspace.</li> </ol>  <p>Tip</p> <p>It is possible to change the values of the optional fields either using the Edit option on the workspace listing for an organization or using the Settings tab within the workspace page, provided that you are the Owner of the workspace. </p>  <p>Apart from the Participants tab, the organization workspace is similar to the user workspace. Therefore, the concepts of Runs, Pipeline Actions, Compute Environments and Credentials are applicable.</p>","title":"Create a new workspace"},{"location":"orgs-and-teams/workspace-management/#add-a-new-participant","text":"<p>To create a new Participant within an organization:</p> <ol> <li>Go to the Participants tab of the organization menu.</li> <li>Click on Add participant.</li> <li>Enter the Name of the new participant. </li> <li>Optionally, update the role associated with the participant of the organization members or collaborators. For more information on roles, please refer to the participant roles section.</li> </ol>  <p>Tip</p> <p>A new workspace participant could be either an existing organization member, collaborator, team, or a new user.</p>","title":"Add a new Participant"},{"location":"orgs-and-teams/workspace-management/#participant-roles","text":"<p>Organization owners can assign a role-based access level within an organization workspace to any of the participants in the workspace.</p>  <p>Hint</p> <p>It is also possible to group members and collaborators into teams and apply a role to that team.</p>  <p>There are five roles available for every workspace participant.</p> <ol> <li> <p>Owner: The participant has full permissions on any resources within the workspace, including the workspace settings.</p> </li> <li> <p>Admin: The participant has full permissions on the resources associated with the workspace. Therefore they can create/modify/delete Pipelines, Compute environments, Actions and Credentials. They can add/remove users to the workspace, but cannot access the workspace settings.</p> </li> <li> <p>Maintain: The participant can launch pipelines and modify pipeline executions (e.g. they can change the pipeline launch compute environments, parameters, pre/post-run scripts, and nextflow configuration) and create new pipelines in the Launchpad. The users cannot modify Compute Environments and Credentials.</p> </li> <li> <p>Launch: The participant can launch pipelines and modify the pipeline input/output parameters in the Launchpad. They cannot modify the launch configuration or other resources.</p> </li> <li> <p>View: The participant can view the team pipelines and runs in read-only mode.</p> </li> </ol>","title":"Participant roles"},{"location":"orgs-and-teams/workspace-management/#sharing-monitoring-with-workspace","text":"<p>To allow users executing pipelines from the command-line to share their runs with a given workspace, follow the instructions under Getting Started</p>","title":"Sharing monitoring with workspace"},{"location":"pipeline-actions/pipeline-actions/","text":"<p>Pipeline actions allow launching of pipelines based on events. </p> <p>Tower currently offers support for native GitHub webhooks and a general Tower webhook that can be invoked programmatically. Support for Bitbucket and GitLab are coming soon.</p>","title":"Pipeline Actions"},{"location":"pipeline-actions/pipeline-actions/#github-webhooks","text":"<p>This Pipeline action listens for any changes made in the pipeline repository. When a change occurs, Tower triggers the launch of the pipeline in response.</p> <p>To create a new Pipeline action, select the Actions tab and create a new action.</p> <p>1. Enter a name for your Action.</p> <p>2. Choose GitHub webhook as the event source.</p> <p></p> <p>3. Choose the environment where the pipeline will be executed.</p> <p>4. Choose the pipeline to launch and optionally the revision.</p> <p>5. Choose the working directory, the config profiles, and parameters. Select Create.</p> <p></p>  <p>Note</p> <p>The pipeline action is now setup. When a new commit occurs for the selected repository and revision, an event will be triggered in Tower and the pipeline will be launched.</p>  <p></p>  <p>Awesome!</p> <p>You now have an active Pipeline action always listening to the latest changes in your repository.</p>","title":"Github webhooks"},{"location":"pipeline-actions/pipeline-actions/#tower-launch-hooks","text":"<p>A Tower launch hook creates a custom endpoint URL which can be used to trigger the execution of your pipeline programmatically from any script web service.</p> <p>This Pipeline action listens for any changes made in the pipeline repository. When a change occurs, Tower triggers the launch of the pipeline in response.</p> <p>To create a new Pipeline action, select the Actions tab and create a new action.</p> <p>1. After naming your pipeline action, select Tower launch hook as the event source.</p> <p></p> <p>2. Select the environment to execute your pipeline, the pipeline repository URL, the Revision number, the Work directory, the Config profiles, and the Pipeline parameters, and click Create.</p> <p></p> <p>A Tower launch hook has been created at that endpoint that can be used to programmatically launch the corresponding pipeline. The snippet below shows an example <code>cURL</code> command with the authentication token.  </p> <p></p>  <p>Awesome!</p> <p>You now have created an endpoint to programmatically launch a pipeline.</p>   <p>Tip</p> <p>When you create a Tower launch hook, you also create an access Token to allow submitting executions to Tower.</p>  <p>Access Tokens are accessible on the tokens page and can also be accessed from the navigation menu.</p> <p></p>","title":"Tower launch hooks"},{"location":"pipeline-schema/overview/","text":"","title":"Pipeline Schema"},{"location":"pipeline-schema/overview/#overview","text":"<p>This page will give you a detailed description of what pipeline schema files are, why they are used and to give you an in-depth description of how to build and customize your own Pipeline JSON schema file. </p> <p></p>","title":"Overview"},{"location":"pipeline-schema/overview/#what-is-a-pipeline-schema","text":"<p>In short, the main use of pipeline schema is to describe the structure and validation constraints of your workflow parameters. Schemas in general are used to validate parameters before use to prevent software/pipelines failing in unexpected ways at runtime. </p> <p>You can create a UI for your pipeline parameters using the pipeline schema.</p>","title":"What is a Pipeline schema?"},{"location":"pipeline-schema/overview/#why-do-you-need-a-schema-file-for-your-pipelines-or-software-applications","text":"<p>Pipeline schema file is used to describe the different paraments used by the Nextflow workflow and the input parameters that the pipeline accepts.</p> <p>Nextflow Tower uses this file to automatically generate the pipeline inputs form and validate the user provided parameters in a user friendly way.</p>  <p>Tip</p> <p>You can populate the parameters in the pipeline, by uploading a YAML or a JSON file, in addition to filling it on the UI itself.</p>","title":"Why do you need a schema file for your pipelines or software applications?"},{"location":"pipeline-schema/overview/#how-can-i-build-my-own-pipeline-schema-file-for-my-nextflow-pipelines","text":"<p>The pipeline schema is based on json-schema.org syntax,  therefore it can be written with a simple text editior, even though can difficult for complex pipelines.</p> <p>The nf-core project provides an handy tool that helps writing the schema  file by running the <code>nf-core schema build</code> command in the pipeline root directoty.</p> <p>It collects your pipeline parameters and gives you interactive prompts about any missing or unexpected parameters. If no existing schema is found, it will automatically create a JSON schema file for you.</p> <p>For more information, please follow this link.</p>","title":"How can I build my own Pipeline schema file for my Nextflow pipelines?"},{"location":"pipeline-schema/overview/#how-can-i-individualize-or-edit-the-automatically-created-schema-file","text":"<p>Once your pipeline schema file has been built with the <code>nf-core schema build</code>, the tool can send the schema to the nf-core website so that you can use a graphical interface to organize and fill in the schema. </p> <p></p> <p>The tool also checks the status of your schema on the website and once complete, it saves your changes to the file locally. </p> <p>Furthermore, you will get a Build ID/Schema cache ID as can be seen above, so if for any reason you already ran the <code>nf-core schema build</code> command and forgot to save your changes, you can resume editing your JSON schema file by using [our schema builder] (https://nf-co.re/pipeline_schema_builder). </p> <p>If the tool does not automatically take you to the nf-core website to customize your JSON schema file, please click on [the following link] (https://nf-co.re/pipeline_schema_builder). </p> <p>1. Open the link above.</p> <p>2. Copy the schema code you have received into the box below \"Paste your JSON Schema\" in the \"New Schema\" section. </p> <p>3. Click on \"Submit\". </p> <p></p> <p>You will be automatically redirected to the JSON schema builder website, where you can then add parameters, groups and much more. </p> <p>Once you are done editing the schema file, you can click on \"Finished\". </p> <p></p>","title":"How can I individualize or edit the automatically created schema file?"},{"location":"pipeline-schema/overview/#can-i-use-the-pipeline-schema-builder-for-pipelines-outside-of-nf-core","text":"<p>Yes. The schema builder is a tool created by the nf-core community to make the creation and editing of Pipeline schema files easier for developers. Thus, it can be used to create any kind of pipeline. </p>","title":"Can I use the pipeline schema builder for pipelines outside of nf-core?"},{"location":"pipeline-schema/overview/#what-changes-can-i-make-to-my-schema-file-with-the-pipeline-schema-builder","text":"<p>You can add parameters such as identifiers (e.g. <code>productId</code>), a product name (e.g. <code>productName</code>), a selling cost and tags. Additionally, you can define the properties of the identifiers and add groups. </p> <p>For a more in depth guide on schema files, please follow this and this link.</p> <p>If you click on the \"Help\" button in the pipeline schema builder website, you will also be able to get an in-depth explanation of the possible parameters and tips on how to create a schema that fits your needs. </p>","title":"What changes can I make to my schema file with the pipeline schema builder?"},{"location":"reports/overview/","text":"","title":"Pipeline Reports"},{"location":"reports/overview/#overview","text":"<p>Most Nextflow pipelines will generate reports or output files which are useful to inspect at the end of the pipeline execution. Reports may be in various formats (e.g. HTML, PDF, TXT) and would typically contain quality control (QC) metrics that would be important to assess the integrity of the results. Tower has a Reports feature that allows you to directly visualise supported file types or to download them directly via the user interface (see Limitations). This saves users the time and effort from having to retrieve and visualise output files from their local storage.</p>","title":"Overview"},{"location":"reports/overview/#visualising-reports","text":"<p>If available, Reports will be displayed in a separate tab within the Runs page for a given pipeline execution. By clicking on the drop-down box in the Reports tab, users can select the appropriate report and either visualise or download them (see Limitations for supported file types).</p> <p></p>","title":"Visualising Reports"},{"location":"reports/overview/#providing-reports","text":"<p>In order to render the Reports tab in the Tower UI, users will need to create a Tower config file that defines the paths to a selection of output files published by the pipeline. There a 2 ways you can provide the Tower config file both of which have to be in YAML format:</p> <ol> <li>Pipeline repository: If a file called tower.yml exists in the root of the pipeline repository then this will be fetched automatically before the pipeline execution.,</li> <li>Tower UI: Providing the YAML definition within the Advanced options &gt; Tower config file box when:   1.Creating a Pipeline in the Launchpad   2.Amending the Launch settings when launching a Pipeline. Users with Maintain role only.</li> </ol>  <p>Warning</p> <p>Any configuration provided in the Tower UI will completely override that which is supplied via the pipeline repository.</p>  <p></p>","title":"Providing Reports"},{"location":"reports/overview/#reports-implementation","text":"<p>Pipeline Reports need to be specified via YAML syntax</p> <pre>1\n2\n3\n4</pre><pre><code>reports:\n    &lt;path pattern&gt;:\n        display: text to display (required)\n        mimeType: file mime type (optional) \n</code></pre>","title":"Reports implementation"},{"location":"reports/overview/#path-pattern","text":"<p>Only the published files (using the Nextflow <code>publishDir</code> directive) are possible report candidates files. The path pattern is used to match published files to a report entry. It can be a partial path, a glob expression or just a file name. </p> <p>Examples of valid path patterns are: </p> <ul> <li><code>multiqc.html</code>: This will match all the published files with this name.</li> <li><code>**/multiqc.html</code>: This is a glob expression that matches any subfolder. It is equivalent to the previous expression.</li> <li><code>results/output.txt</code>: This will match all the <code>output.txt</code> files inside any results folder. </li> <li><code>*_output.tsv</code>: This will match any file that ends with \u201c_output.tsv\u201d</li> </ul>  <p>Warning</p> <p>When you use <code>*</code> it is important to also use double quotes, otherwise it is not a valid YAML.</p>","title":"Path pattern"},{"location":"reports/overview/#display","text":"<p>Display defines the title that will be shown on the website. If there are multiple files that match the same pattern an automatic suffix will be added. The suffix is the minimum difference between all the matching paths. For example given this report definition:</p> <pre>1\n2\n3</pre><pre><code>reports:\n    \"**/out/sheet.tsv\":\n        display: \"Data sheet\"\n</code></pre>  <p>If you have these two paths <code>/workdir/sample1/out/sheet.tsv</code> and <code>/workdir/sample2/out/sheet.tsv</code> both of them will match the path pattern and their final display name will be Data sheet (sample1) and Data sheet (sample2).</p>","title":"Display"},{"location":"reports/overview/#mimetype","text":"<p>By default the mime type is deduced from the file extension, so in general you don\u2019t need to explicitly define it. Optionally, you can define it to force a viewer, for example showing a <code>txt</code> file as a <code>tsv</code>. It is important that it is a valid mime type text, otherwise it will be ignored and the extension will be used instead.</p>","title":"mimeType"},{"location":"reports/overview/#limitations","text":"<p>The current reports implementation limits the rendering to the following formats (html, csv, tsv, pdf, and txt).  In-page rendering is restricted to files smaller than 10MB to reduce the UI overload. Larger files need to be downloaded first. Currently, there is a YAML formatting validation in place checking both the <code>tower.yml</code> file inside the repository, and the UI configuration box. The validation phase will emit an error message when users try to launch a pipeline with non-compliant YAML definitions.</p>","title":"Limitations"},{"location":"secrets/overview/","text":"","title":"Pipeline Secrets"},{"location":"secrets/overview/#introduction","text":"<p>Tower uses the concept of Secrets to store the keys and tokens used by workflow tasks to interact with external systems e.g. a password to connect to an external database or an API token. Tower relies on third-party secret manager services in order to maintain security between the workflow execution context and the secret container. This means that no secure data is transmitted from Tower to the Compute Environment. </p>  <p>Note</p> <p>Currently only AWS Batch or HPC batch schedulers are supported. Please read more about the AWS Secret Manager here</p>","title":"Introduction"},{"location":"secrets/overview/#pipeline-secrets","text":"<p>To create a Pipeline Secret navigate to a Workspace (private or shared) and click on the Secrets tab in the top navigation pane to gain access to the Secrets management interface.</p> <p></p> <p>All of the available Secrets will be listed here and users with the appropriate permissions (Workspace admin or owner) will be able to create or update Secret values.</p> <p></p> <p>The form for creating or updating a Secret is very similar to the one used for Credentials.</p> <p></p>","title":"Pipeline Secrets"},{"location":"secrets/overview/#pipeline-secrets-for-users","text":"<p>Secrets can be defined for users by clicking on your avatar in the top right corner of the Tower interface and selecting \"Your Secrets\". Listing, creating and updating Secrets for users is the same as Secrets in a Workspace. However, Secrets defined by a user have a higher priority and will override any Secrets defined in a Workspace with the same name.</p> <p></p>  <p>Warning</p> <p>Secrets defined by a user have higher priority and will override any Secrets defined in a Workspace with the same name.</p>","title":"Pipeline Secrets for users"},{"location":"secrets/overview/#using-secrets-in-workflows","text":"<p>When a new workflow is launched, all Secrets are sent to the corresponding secret manager for the Compute Environment. Nextflow will download these Secrets internally and use them when they are referenced in the pipeline code as described in the Nextflow Secrets documentation. </p> <p>Secrets will be automatically deleted from the secret manager when the Pipeline completes (successful or unsuccessful).</p>","title":"Using Secrets in workflows"},{"location":"secrets/overview/#aws-secrets-manager-integration","text":"<p>If you are planning to use the Pipeline Secrets feature provided by Tower with the AWS Secrets Manager, the following IAM permissions should be provided:</p> <ol> <li> <p>Create the AWS Batch IAM Execution role as specified in the AWS documentation.</p> </li> <li> <p>Add the <code>AmazonECSTaskExecutionRolePolicy</code> policy and this custom policy to the execution role created above.</p> </li> <li> <p>Specify the execution role ARN in the Batch execution role option (under Advanced options) when creating your Compute Environment in Tower.</p> </li> <li> <p>Add this custom policy to the ECS Instance role associated with the Batch compute environment that will be used to deploy your pipelines. Replace <code>YOUR-ACCOUNT</code> and <code>YOUR-EXECUTION-ROLE-NAME</code> with the appropriate values. See here for more details about the Instance role.</p> </li> <li> <p>Add this custom policy to your Tower IAM user (the one specified in the Tower credentials).</p> </li> </ol>","title":"AWS Secrets Manager Integration"}]}